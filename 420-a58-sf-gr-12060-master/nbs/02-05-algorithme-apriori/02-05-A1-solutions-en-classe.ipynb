{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**420-A58-SF - Algorithmes d'apprentissage non supervisé - Hiver 2023 - Spécialisation technique en Intelligence Artificielle**<br/>\n",
    "MIT License - Copyright (c) 2023 Mikaël Swawola\n",
    "<br/>\n",
    "![Travaux Pratiques - Algorithme Apriori](static/02-05-A1-banner.png)\n",
    "<br/>\n",
    "**Objectif: Cette séance de travaux pratiques consiste en l'implémentation de l'algorithme Apriori pour l'apprentissage des règles d'association sur le mini jeu de données PanierEpicerie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Lecture du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from helpers import print_itemsets, print_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 1-1 - À l'aide de la librairie Pandas, lire le fichier de données `PanierEpicerie.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 1-2 lignes de code\n",
    "data = pd.read_csv('../../data/PanierEpicerie.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 1-2 - Combien d'items et de baskets sont contenus dans ce jeu de données ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre réponse ici\n",
    "# 20 baskets et 11 items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 1-3 - Convertissez le jeu de données en liste de transactions (ou baskets). Chaque basket est une liste d'items (ou article)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 1-2 lignes de code\n",
    "\n",
    "transactions = list(data[\"basket\"].apply(lambda x:x.split(',')))\n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for transaction in transactions for item in transaction]\n",
    "len(set(flat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Librarie Mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie [Mlxtend](http://rasbt.github.io/mlxtend/) (machine learning extensions) propose une implémentation de l'algorithme Apriori. Nous allons donc mettre en oeuvre différentes fonctionnalités de cette librairie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-1 - À l'aide de la classe [TransactionEncoder](http://rasbt.github.io/mlxtend/user_guide/preprocessing/TransactionEncoder/), encodez la liste des transactions au format requis par Mlxtend**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 3-4 lignes de code\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(transactions).transform(transactions)\n",
    "te_data\n",
    "df = pd.DataFrame(te_data,columns=te.columns_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-2 - Identifier les itemsets fréquents pour un support de 20%. Référez vous à la documentation de Mlxtend pour trouver la classe requise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 2-3 lignes de code\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "freq = apriori(df, min_support=0.2, use_colnames=True).sort_values(by=\"support\", ascending=False)\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-3 - De la même manière, identifier maintenant les règles d'association ayant un indice de confiance au moins de 0.3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 2-3 lignes de code\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "df_ar = association_rules(freq, metric = \"confidence\", min_threshold = 0.3).sort_values(by=\"confidence\", ascending=False)\n",
    "df_ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Implémentation de l'algorithme Apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code ci-dessous représente une implémentation simple et de base (persque naïve) de l'algorihtme Apriori. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 3-1 - À l'aide des éléments vus en cours, compléter les différentes méthodes de la classe `Apriori` et retrouvez les résultats de l'exercice 2. Seule la méthode `generate_L` vous est donnée. Des fonctions helpers aidant à l'affichage `print_itemsets`, `print_rules` sont importées**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Apriori:\n",
    "    \n",
    "    def __init__(self, transactions, min_support, min_confidence):\n",
    "        self.transactions = transactions # Baskets\n",
    "        self.min_support = min_support # Le seuil de support\n",
    "        self.min_confidence = min_confidence # La confiance minimale\n",
    "        self.support_data = {}   \n",
    "        \n",
    "    def create_C1(self):\n",
    "                \n",
    "        # Completer le code ci-dessous ~ 1 ligne de code !\n",
    "        \n",
    "        # C1: set de frozenset\n",
    "        \n",
    "        #C1 = set([frozenset([item]) for transaction in transactions for item in transaction])\n",
    "        \n",
    "        C1 = set()\n",
    "        for trans in self.transactions:\n",
    "            for item in trans:\n",
    "                C1.add(frozenset([item]))    \n",
    "        \n",
    "        return C1\n",
    "    \n",
    "    \n",
    "    def generate_Lk_from_Ck(self, Ck):\n",
    "        \n",
    "        # Completer le code ci-dessous ~ 15-20 lignes de code\n",
    "        \n",
    "        Lk = set()\n",
    "        items_count = {}\n",
    "        \n",
    "        for transaction in self.transactions:\n",
    "            for items in Ck:\n",
    "                if items.issubset(transaction):\n",
    "                    if items not in items_count:\n",
    "                        items_count[items] = 1\n",
    "                    else:\n",
    "                        items_count[items] += 1\n",
    "        \n",
    "        t_num = len(self.transactions)\n",
    "        \n",
    "        for items in items_count:\n",
    "            support = items_count[items] / float(t_num)\n",
    "            if support >= self.min_support:\n",
    "                Lk.add(items)\n",
    "                self.support_data[items] = support\n",
    "        return Lk\n",
    "    \n",
    "        #Lk = set()\n",
    "        \n",
    "        # Trouver les fréquences des item(pair)\n",
    "        #for r in Ck:                               # Chaque item(item set) a rechercher\n",
    "        #    freq = 0\n",
    "        #    for b in self.transactions:            # Chaque basket\n",
    "        #        trouve = 0                         # Compteur pour identifier nb d'item trouvé\n",
    "        #        for i in b:                        # Chaque item du basket\n",
    "        #            if (i in r):\n",
    "        #                trouve+=1\n",
    "        #        if (trouve == len(r)):\n",
    "        #            freq += 1\n",
    "                    \n",
    "        #    if (freq / len(self.transactions) >= self.min_support):\n",
    "        #        Lk.add(r)\n",
    "        #        self.support_data[r] = freq\n",
    "                \n",
    "        #return Lk\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def create_Ck(self, L1, Lksub1):\n",
    "              \n",
    "        # Completer le code ci-dessous ~ 6 lignes de code\n",
    "        Ck = set()\n",
    "        \n",
    "        for item in L1:\n",
    "            for itemset in Lksub1:\n",
    "                union = item.union(itemset)\n",
    "                if len(union) != len(itemset):\n",
    "                    Ck.add(union)\n",
    "                    \n",
    "        #for itemset in Lksub1:\n",
    "        #    for item in L1:\n",
    "        #        union = itemset.union(item)\n",
    "        #        if len(union) != len(itemset):\n",
    "        #            Ck.add(union)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return Ck\n",
    "        \n",
    "        \n",
    "    def generate_L(self):\n",
    "        \"\"\"\n",
    "        Génère tous les ensembles d'items fréquents\n",
    "        Input:\n",
    "            None\n",
    "        Output:\n",
    "            L: Liste des Lk.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.support_data = {}\n",
    "        \n",
    "        C1 = self.create_C1()\n",
    "        L1 = self.generate_Lk_from_Ck(C1)\n",
    "        Lksub1 = L1.copy()\n",
    "        L = []\n",
    "        L.append(Lksub1)\n",
    "        i = 2\n",
    "        while True:\n",
    "            Ci = self.create_Ck(L1, Lksub1)\n",
    "            Li = self.generate_Lk_from_Ck(Ci)\n",
    "            if Li:\n",
    "                Lksub1 = Li.copy()\n",
    "                L.append(Lksub1)\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "        return L\n",
    "        \n",
    "        \n",
    "    def generate_rules(self):\n",
    "               \n",
    "        L = self.generate_L()\n",
    "        \n",
    "        big_rule_list = []\n",
    "        sub_set_list = []\n",
    "        for i in range(0, len(L)):\n",
    "            for freq_set in L[i]:\n",
    "                for sub_set in sub_set_list:\n",
    "                    if sub_set.issubset(freq_set):\n",
    "                        # Compute the confidence\n",
    "                        conf = self.support_data[freq_set] / self.support_data[freq_set - sub_set]\n",
    "                        big_rule = (freq_set - sub_set, sub_set, conf)\n",
    "                        if conf >= self.min_confidence and big_rule not in big_rule_list:\n",
    "                            big_rule_list.append(big_rule)\n",
    "                sub_set_list.append(freq_set)\n",
    "        \n",
    "        return big_rule_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Apriori(transactions, min_support=0.2, min_confidence=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## POUR DEBUGGER ############################\n",
    "C1 = model.create_C1()\n",
    "C1\n",
    "L1 = model.generate_Lk_from_Ck(C1)\n",
    "L1\n",
    "C2 = model.create_Ck(L1,L1)\n",
    "L2 = model.generate_Lk_from_Ck(C2)\n",
    "L2\n",
    "C3 = model.create_Ck(L1,L2)\n",
    "C3\n",
    "L3 = model.generate_Lk_from_Ck(C3)\n",
    "L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = model.generate_L()\n",
    "\n",
    "print_itemsets(L, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_list = model.generate_rules()\n",
    "print_rules(rule_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du TP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
