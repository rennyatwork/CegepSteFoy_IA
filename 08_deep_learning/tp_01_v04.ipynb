{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcVM8Ec68cqUI8b1XGc8OJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rennyatwork/CegepSteFoy_IA/blob/main/08_deep_learning/tp_01_v04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "-nNNWGeBjaTU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#import tensorflow.keras.optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import keras as keras\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import seaborn as sns\n",
        "from sklearn import linear_model\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow"
      ],
      "metadata": {
        "id": "cHIhn2w5j_tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## column to predict\n",
        "y_col = 'TotalScore'"
      ],
      "metadata": {
        "id": "p786NNFLx_sZ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_df_from_csv(p_path, p_sep=',', p_print=True):\n",
        "  df= pd.read_csv(p_path, sep= p_sep)\n",
        "  if (p_print):\n",
        "    print('---Head---')\n",
        "    print(df.head())\n",
        "    print('-- How many nulls? --')\n",
        "    print(df.isna().sum())\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "SbY3CQeq2GHy"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Augmented df\n",
        "def get_augmented_df():\n",
        "  ## head 400001\n",
        "  path_csv = \"https://raw.githubusercontent.com/rennyatwork/CegepSteFoy_IA/main/08_deep_learning/data/AugmentedData_reduced.csv\"\n",
        "  augmented_df_1 = get_df_from_csv(path_csv, p_sep =\",\")\n",
        "  ## tail 284000\n",
        "  path_csv = \"https://raw.githubusercontent.com/rennyatwork/CegepSteFoy_IA/main/08_deep_learning/data/AugemntedData_reduced_tail.csv\"\n",
        "  augmented_df_2 = get_df_from_csv(path_csv, p_sep =\",\")\n",
        "\n",
        "  return pd.concat([augmented_df_1, augmented_df_2])"
      ],
      "metadata": {
        "id": "YwmzYC1wkP_2"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## augmented_df (full augmented_df)\n",
        "augmented_df = get_augmented_df()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C7HxmObut6s",
        "outputId": "9d549471-965e-4727-982f-a73b9fe203d8"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Head---\n",
            "   GameID  ScenarioID  HolesCompletedCount  Hole1  Hole2  Hole3  Hole4  Hole5  \\\n",
            "0       1           1                    0      0      0      0      0      0   \n",
            "1       2           1                    0      0      0      0      0      0   \n",
            "2       3           1                    0      0      0      0      0      0   \n",
            "3       4           1                    0      0      0      0      0      0   \n",
            "4       5           1                    0      0      0      0      0      0   \n",
            "\n",
            "   Hole6  Hole7  ...  Hole10  Hole11  Hole12  Hole13  Hole14  Hole15  Hole16  \\\n",
            "0      0      0  ...       0       0       0       0       0       0       0   \n",
            "1      0      0  ...       0       0       0       0       0       0       0   \n",
            "2      0      0  ...       0       0       0       0       0       0       0   \n",
            "3      0      0  ...       0       0       0       0       0       0       0   \n",
            "4      0      0  ...       0       0       0       0       0       0       0   \n",
            "\n",
            "   Hole17  Hole18  TotalScore  \n",
            "0       0       0          85  \n",
            "1       0       0          77  \n",
            "2       0       0          83  \n",
            "3       0       0          86  \n",
            "4       0       0          87  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "-- How many nulls? --\n",
            "GameID                 0\n",
            "ScenarioID             0\n",
            "HolesCompletedCount    0\n",
            "Hole1                  0\n",
            "Hole2                  0\n",
            "Hole3                  0\n",
            "Hole4                  0\n",
            "Hole5                  0\n",
            "Hole6                  0\n",
            "Hole7                  0\n",
            "Hole8                  0\n",
            "Hole9                  0\n",
            "Hole10                 0\n",
            "Hole11                 0\n",
            "Hole12                 0\n",
            "Hole13                 0\n",
            "Hole14                 0\n",
            "Hole15                 0\n",
            "Hole16                 0\n",
            "Hole17                 0\n",
            "Hole18                 0\n",
            "TotalScore             0\n",
            "dtype: int64\n",
            "---Head---\n",
            "   1  201  10  4  6  0  0.1  0.2  0.3  0.4  ...  0.7  5  4.1  4.2  6.1  4.3  \\\n",
            "0  2  201  10  3  5  0    0    0    0    0  ...    0  5    5    4    5    3   \n",
            "1  3  201  10  5  4  0    0    0    0    0  ...    0  6    5    4    5    3   \n",
            "2  4  201  10  4  4  0    0    0    0    0  ...    0  5    7    4    6    3   \n",
            "3  5  201  10  4  7  0    0    0    0    0  ...    0  9    6    3    5    4   \n",
            "4  6  201  10  4  5  0    0    0    0    0  ...    0  5    4    3    5    4   \n",
            "\n",
            "   5.1  4.4  6.2  85  \n",
            "0    4    3    4  77  \n",
            "1    5    3    3  83  \n",
            "2    6    3    4  86  \n",
            "3    5    3    4  87  \n",
            "4    4    6    5  83  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "-- How many nulls? --\n",
            "1      0\n",
            "201    0\n",
            "10     0\n",
            "4      0\n",
            "6      0\n",
            "0      0\n",
            "0.1    0\n",
            "0.2    0\n",
            "0.3    0\n",
            "0.4    0\n",
            "0.5    0\n",
            "0.6    0\n",
            "0.7    0\n",
            "5      0\n",
            "4.1    0\n",
            "4.2    0\n",
            "6.1    0\n",
            "4.3    0\n",
            "5.1    0\n",
            "4.4    0\n",
            "6.2    0\n",
            "85     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## nulls?\n",
        "print(augmented_df.isnull().sum())\n",
        "print(augmented_df[y_col].mode())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIgBf_Mevsul",
        "outputId": "3e83ce3d-d274-43ca-e040-f6f1ac8f93f9"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GameID                 283999\n",
            "ScenarioID             283999\n",
            "HolesCompletedCount    283999\n",
            "Hole1                  283999\n",
            "Hole2                  283999\n",
            "Hole3                  283999\n",
            "Hole4                  283999\n",
            "Hole5                  283999\n",
            "Hole6                  283999\n",
            "Hole7                  283999\n",
            "Hole8                  283999\n",
            "Hole9                  283999\n",
            "Hole10                 283999\n",
            "Hole11                 283999\n",
            "Hole12                 283999\n",
            "Hole13                 283999\n",
            "Hole14                 283999\n",
            "Hole15                 283999\n",
            "Hole16                 283999\n",
            "Hole17                 283999\n",
            "Hole18                 283999\n",
            "TotalScore             283999\n",
            "1                      400000\n",
            "201                    400000\n",
            "10                     400000\n",
            "4                      400000\n",
            "6                      400000\n",
            "0                      400000\n",
            "0.1                    400000\n",
            "0.2                    400000\n",
            "0.3                    400000\n",
            "0.4                    400000\n",
            "0.5                    400000\n",
            "0.6                    400000\n",
            "0.7                    400000\n",
            "5                      400000\n",
            "4.1                    400000\n",
            "4.2                    400000\n",
            "6.1                    400000\n",
            "4.3                    400000\n",
            "5.1                    400000\n",
            "4.4                    400000\n",
            "6.2                    400000\n",
            "85                     400000\n",
            "dtype: int64\n",
            "0    83.0\n",
            "Name: TotalScore, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### several nulls...\n",
        "### Let's create a function to replace nulls with most frequent values\n",
        "\n",
        "def get_df_without_nulls(p_df):\n",
        "  for col in p_df.columns:\n",
        "    most_frequent_value = p_df[col].mode()[0]\n",
        "    p_df[col].fillna(most_frequent_value, inplace=True)\n",
        "  return p_df\n"
      ],
      "metadata": {
        "id": "rKV2_gdu03bt"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### still any nulls?\n",
        "augmented_df2 = get_df_without_nulls(augmented_df)\n",
        "\n",
        "print(augmented_df2.isnull().sum())\n",
        "print(augmented_df2[y_col].mode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGK8uzcw1p9S",
        "outputId": "3b7ebc1e-a02d-4913-a360-fa01952fca8c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GameID                 0\n",
            "ScenarioID             0\n",
            "HolesCompletedCount    0\n",
            "Hole1                  0\n",
            "Hole2                  0\n",
            "Hole3                  0\n",
            "Hole4                  0\n",
            "Hole5                  0\n",
            "Hole6                  0\n",
            "Hole7                  0\n",
            "Hole8                  0\n",
            "Hole9                  0\n",
            "Hole10                 0\n",
            "Hole11                 0\n",
            "Hole12                 0\n",
            "Hole13                 0\n",
            "Hole14                 0\n",
            "Hole15                 0\n",
            "Hole16                 0\n",
            "Hole17                 0\n",
            "Hole18                 0\n",
            "TotalScore             0\n",
            "1                      0\n",
            "201                    0\n",
            "10                     0\n",
            "4                      0\n",
            "6                      0\n",
            "0                      0\n",
            "0.1                    0\n",
            "0.2                    0\n",
            "0.3                    0\n",
            "0.4                    0\n",
            "0.5                    0\n",
            "0.6                    0\n",
            "0.7                    0\n",
            "5                      0\n",
            "4.1                    0\n",
            "4.2                    0\n",
            "6.1                    0\n",
            "4.3                    0\n",
            "5.1                    0\n",
            "4.4                    0\n",
            "6.2                    0\n",
            "85                     0\n",
            "dtype: int64\n",
            "0    83.0\n",
            "Name: TotalScore, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Original df\n",
        "path_csv = \"https://raw.githubusercontent.com/rennyatwork/CegepSteFoy_IA/main/08_deep_learning/data/OriginalData.csv\"\n",
        "original_df = get_df_from_csv(path_csv, p_sep =\",\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QumhWLveknb8",
        "outputId": "61de9ed5-63a4-4efe-8cd2-663194dc43ec"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Head---\n",
            "   GameID  Hole1  Hole2  Hole3  Hole4  Hole5  Hole6  Hole7  Hole8  Hole9  \\\n",
            "0       1      4      6      5      4      6      5      5      3      5   \n",
            "1       2      3      5      4      4      5      5      6      3      4   \n",
            "2       3      5      4      6      4      7      4      5      3      5   \n",
            "3       4      4      4      7      3      6      4      4      4      5   \n",
            "4       5      4      7      6      4      5      4      5      3      4   \n",
            "\n",
            "   Hole10  Hole11  Hole12  Hole13  Hole14  Hole15  Hole16  Hole17  Hole18  \\\n",
            "0       4       5       4       4       6       4       5       4       6   \n",
            "1       5       5       5       4       5       3       4       3       4   \n",
            "2       6       6       5       4       5       3       5       3       3   \n",
            "3       7       5       7       4       6       3       6       3       4   \n",
            "4       6       9       6       3       5       4       5       3       4   \n",
            "\n",
            "   TotalScore  \n",
            "0          85  \n",
            "1          77  \n",
            "2          83  \n",
            "3          86  \n",
            "4          87  \n",
            "-- How many nulls? --\n",
            "GameID        0\n",
            "Hole1         0\n",
            "Hole2         0\n",
            "Hole3         0\n",
            "Hole4         0\n",
            "Hole5         0\n",
            "Hole6         0\n",
            "Hole7         0\n",
            "Hole8         0\n",
            "Hole9         0\n",
            "Hole10        0\n",
            "Hole11        0\n",
            "Hole12        0\n",
            "Hole13        0\n",
            "Hole14        0\n",
            "Hole15        0\n",
            "Hole16        0\n",
            "Hole17        0\n",
            "Hole18        0\n",
            "TotalScore    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## nulls?\n",
        "original_df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6RjTivzwTMb",
        "outputId": "35a16f01-7ab7-4e06-90c0-d483fa3bf713"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GameID        0\n",
              "Hole1         0\n",
              "Hole2         0\n",
              "Hole3         0\n",
              "Hole4         0\n",
              "Hole5         0\n",
              "Hole6         0\n",
              "Hole7         0\n",
              "Hole8         0\n",
              "Hole9         0\n",
              "Hole10        0\n",
              "Hole11        0\n",
              "Hole12        0\n",
              "Hole13        0\n",
              "Hole14        0\n",
              "Hole15        0\n",
              "Hole16        0\n",
              "Hole17        0\n",
              "Hole18        0\n",
              "TotalScore    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## most frequent value?\n",
        "print(original_df[y_col].mode())\n",
        "print(original_df[y_col].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vljJ2IE1xzRW",
        "outputId": "b91d92b0-c86d-47c2-fb07-ac7dfe97d457"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    83\n",
            "Name: TotalScore, dtype: int64\n",
            "83.0655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## naïve prediction (baseline) can be original_df[y_col].mode(), original_df[y_col].mean()"
      ],
      "metadata": {
        "id": "4opXeclzzkqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train test split\n",
        "## we apply the scaler\n",
        "def get_train_test(pDf=original_df, p_var_y=y_col, p_test_size=0.2, p_random_state=25):\n",
        "  dfX = pDf.drop(p_var_y, axis=1).values\n",
        "  dfY = pDf[p_var_y]\n",
        "\n",
        "  # Apply standardization to feature values\n",
        "  scaler = StandardScaler()\n",
        "  dfX_standardized = scaler.fit_transform(dfX)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(dfX, dfY, test_size=p_test_size, random_state=p_random_state)\n",
        "  X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=p_test_size, random_state=p_random_state)\n",
        "\n",
        "  return X_train, X_valid, X_test, y_train, y_valid, y_test\n"
      ],
      "metadata": {
        "id": "8DPZWAKFkqeb"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3x_z5OH2vHdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "########## Establishing a baseline #########"
      ],
      "metadata": {
        "id": "4Pk6Qjfq3Xim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_dummy(p_df, p_X_train, p_X_valid, p_y_train ,p_y_valid):\n",
        "  baseline_reg = DummyRegressor()\n",
        "  baseline_reg.fit(p_X_train, p_y_train)\n",
        "  print(\"[score train]\", baseline_reg.score(p_X_train, p_y_train))\n",
        "  print(\"[score valid]\", baseline_reg.score(p_X_valid, p_y_valid))\n",
        "\n",
        "  y_pred = baseline_reg.predict(p_y_valid)\n",
        "\n",
        "  print('Root Mean Squared Error - [RMSE]:', round(np.sqrt(metrics.mean_squared_error(p_y_valid, y_pred)),3) )\n",
        "  print('Mean Squared Error - [MSE]:', round(metrics.mean_squared_error(p_y_valid, y_pred),3) )\n",
        "\n"
      ],
      "metadata": {
        "id": "-SuoLH0c3Dv4"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## augmented_df\n",
        "X_train, X_valid, X_test, y_train, y_valid, y_test = get_train_test(augmented_df2)\n",
        "analyze_dummy(augmented_df2, X_train, X_valid, y_train, y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n3zcNFQ3DlL",
        "outputId": "697a629d-e940-493b-8e4d-5fa562f7d3be"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[score train] 0.0\n",
            "[score valid] -2.5220723929519906e-05\n",
            "Root Mean Squared Error - [RMSE]: 5.351\n",
            "Mean Squared Error - [MSE]: 28.635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## original df\n",
        "X_train, X_valid, X_test, y_train, y_valid, y_test = get_train_test(original_df)\n",
        "analyze_dummy(original_df, X_train, X_valid, y_train, y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRPa4S_IONrD",
        "outputId": "f69d6f83-763a-433a-e1f4-c39248bbe8fb"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[score train] 0.0\n",
            "[score valid] -0.000796875625000304\n",
            "Root Mean Squared Error - [RMSE]: 7.06\n",
            "Mean Squared Error - [MSE]: 49.844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#############################\n",
        "\n",
        "Our model must perform better than\n",
        "\n",
        "Root Mean Squared Error - [RMSE]: 5.351\n",
        "\n",
        "#############################\n"
      ],
      "metadata": {
        "id": "L2FaYWxU3er_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####### Simple regression ######\n"
      ],
      "metadata": {
        "id": "CWpEL0BqVbtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge, RidgeCV\n",
        "from sklearn.linear_model import Lasso, LassoCV\n",
        "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "WfVhyDznWX0U"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### affiche les metriques\n",
        "def print_metrics(pY, pYpred, nbDecimal=3 ):\n",
        "    #print('Mean Absolute Error - [MAE]:', round(metrics.mean_absolute_error(pY, pYpred), nbDecimal) )\n",
        "    print('Mean Squared Error - [MSE]:', round(metrics.mean_squared_error(pY, pYpred),nbDecimal ) )\n",
        "    #print('Score - [accuracy]: ', round(pRegressor.score(pY, pYpred), nbDecimal))\n",
        "    print('Root Mean Squared Error - [RMSE]:', round(np.sqrt(metrics.mean_squared_error(pY, pYpred)),nbDecimal) )\n",
        "    #print('[Classification report]')\n",
        "    #print(classification_report(pYtest, pYpred, labels = donnee['ozone'].unique()))\n",
        ""
      ],
      "metadata": {
        "id": "htEGWYCbXicZ"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "def analyze_regression(p_X_train,\n",
        "                       p_X_test,\n",
        "                       p_y_train,\n",
        "                       p_y_test,\n",
        "                       pCv=4,\n",
        "                       pMaxIter=1000\n",
        "                       ):\n",
        "\n",
        "\n",
        "\n",
        "    print(\"-----[Linear Regression]-----\")\n",
        "    regr = linear_model.LinearRegression(fit_intercept=True)\n",
        "    regr.fit(p_X_train, p_y_train)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    #print(loo.get_n_splits(X))\n",
        "    #crossvalidation = KFold(n_splits=392, random_state=None, shuffle=False)\n",
        "\n",
        "    ##http://www.science.smith.edu/~jcrouser/SDS293/labs/lab7-py.html\n",
        "    scores_train = cross_val_score(regr, p_X_train, p_y_train, cv=loo, scoring=\"neg_mean_squared_error\")\n",
        "    mse_train = np.mean(np.abs(scores_train))\n",
        "    print(\"---[train]---\")\n",
        "    #print(\"[train] -   MSE: \" + str(mse_train) + \", STD: \" + str(np.std(scores_train)))\n",
        "    print(\"RMSE \", round(np.sqrt(mse_train),3) )\n",
        "    print(\"MSE \", round(mse_train,3))\n",
        "    #print(\"score \", round(np.std(scores_train),3) )\n",
        "\n",
        "\n",
        "    scores_test = cross_val_score(regr, p_X_test, p_y_test, cv=loo, scoring=\"neg_mean_squared_error\")\n",
        "    mse_test = np.mean(np.abs(scores_test))\n",
        "    print(\"---[test]---\")\n",
        "    #print(\"[test] -   MSE: \" + str(mse_test) + \", STD: \" + str(np.std(scores_test)))\n",
        "    print(\"RMSE \", round(np.sqrt(mse_test),5 ))\n",
        "    print(\"MSE \", round(mse_test,5))\n",
        "    #print(\"score \", round(np.std(scores_test),3) )\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "rwtEnEM_Y8JE"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## regression\n",
        "analyze_regression(p_X_train = X_train,\n",
        "                       p_X_test = X_valid,\n",
        "                       p_y_train = y_train,\n",
        "                       p_y_test = y_valid)"
      ],
      "metadata": {
        "id": "V7mR-t9qaUPn",
        "outputId": "48cccb31-9816-433e-de1c-367498845af1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----[Linear Regression]-----\n",
            "---[train]---\n",
            "RMSE  0.0\n",
            "MSE  0.0\n",
            "---[test]---\n",
            "RMSE  0.0\n",
            "MSE  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### elasticnet, ridge, lasso\n",
        "def analyze_regularization(\n",
        "                    pAlphas\n",
        "                    , pRegressorName\n",
        "                    , pRegressorCVName\n",
        "                    , p_X_train\n",
        "                    , p_X_test\n",
        "                    , p_y_train\n",
        "                    , p_y_test\n",
        "                    , pCv=5\n",
        "                    , pMaxIter=1000\n",
        "                    ):\n",
        "\n",
        "\n",
        "\n",
        "    print(\"----[\"+pRegressorName+\"]----\")\n",
        "    regr = globals()[pRegressorCVName](alphas=pAlphas, cv=pCv).fit(p_X_train, p_y_train)\n",
        "    #regr = linear_model.ElasticNetCV(alphas=pAlphas, cv=pCv).fit(X_train, y_train)\n",
        "\n",
        "    print(\"[alpha]: \", regr.alpha_)\n",
        "\n",
        "    modele_final = globals()[pRegressorName](regr.alpha_, max_iter=pMaxIter).fit(p_X_train, p_y_train)\n",
        "\n",
        "    y_pred_train = regr.predict(p_X_train)\n",
        "    y_pred_test = regr.predict(p_X_test)\n",
        "\n",
        "\n",
        "    print(\"---[train]---\")\n",
        "    print_metrics(p_y_train, y_pred_train)\n",
        "\n",
        "    print(\"---[test]---\")\n",
        "    #print(\"[score]: \",  regr.score(X_test, y_test))\n",
        "    print_metrics(p_y_test, y_pred_test)"
      ],
      "metadata": {
        "id": "_EV1Wx_fVay0"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(original_df)"
      ],
      "metadata": {
        "id": "AiouGc-BYbFL",
        "outputId": "1170c66a-d056-49eb-b1d6-9ff2c26ee7f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Ridge avec var exponnentielles\n",
        "lstAlpha = [0.5, 0.8, 1, 1.2, 1.3]\n",
        "#analyze_ridge(powerDfX, dfY, lstAlpha)\n",
        "#lstAlpha = [  7, 8, 8.4, 8.5, 8.6,  10, 10.5]\n",
        "analyze_regularization( lstAlpha\n",
        "                       , pRegressorName = \"Ridge\"\n",
        "                       , pRegressorCVName = \"RidgeCV\"\n",
        "                       , p_X_train = X_train\n",
        "                       , p_X_test = X_valid\n",
        "                       , p_y_train = y_train\n",
        "                       , p_y_test = y_valid\n",
        "                      )"
      ],
      "metadata": {
        "id": "mXkKqSTaWvAZ",
        "outputId": "65a9bcee-0038-4d08-fed1-237c0a1e5896",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----[Ridge]----\n",
            "[alpha]:  0.5\n",
            "---[train]---\n",
            "Mean Squared Error - [MSE]: 0.0\n",
            "Root Mean Squared Error - [RMSE]: 0.001\n",
            "---[test]---\n",
            "Mean Squared Error - [MSE]: 0.0\n",
            "Root Mean Squared Error - [RMSE]: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###################\n"
      ],
      "metadata": {
        "id": "iHm4CzgPVdAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create model\n",
        "def create_model (p_learning_rate, p_dropout_rate, pDfX, p_nb_neuron_input=128, p_activation='relu'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(p_nb_neuron_input, input_dim=pDfX.shape[1], activation=p_activation))\n",
        "  model.add(Dropout(p_dropout_rate))\n",
        "  model.add(Dense(int(p_nb_neuron_input/2), activation=p_activation))\n",
        "  model.add(Dropout(p_dropout_rate))\n",
        "  model.add(Dense(int(p_nb_neuron_input/4), activation=p_activation))\n",
        "  model.add(Dropout(p_dropout_rate))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  adam = Adam(lr = p_learning_rate)\n",
        "\n",
        "  #model.compile( loss='mean_squared_error', optimizer=adam, metrics=['mae'])\n",
        "  model.compile( loss='mean_squared_error', optimizer=adam, metrics=['mse'])\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "b3lH-Pj-mRjw"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## build model (book HandsOn -on ML, Aurélien Géron)\n",
        "def build_model (p_input_shape,\n",
        "                 p_n_hidden=1,\n",
        "                 p_n_neurons=30,\n",
        "                 p_learning_rate=3e-3,\n",
        "                 p_activation='relu'):\n",
        "  model = Sequential()\n",
        "  model.add(keras.layers.InputLayer(input_shape=p_input_shape))\n",
        "  for layer in range(p_n_hidden):\n",
        "    model.add(keras.layers.Dense(p_n_neurons, activation=p_activation))\n",
        "    model.add(keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5))\n",
        "    #keras.layers.BatchNormalization()\n",
        "  model.add(keras.layers.Dense(1))\n",
        "  optimizer = keras.optimizers.SGD(lr=p_learning_rate)\n",
        "\n",
        "  #arr_metrics = ['mae', 'accuracy']\n",
        "  #arr_metrics = ['mae']\n",
        "  arr_metrics = ['mse']\n",
        "\n",
        "  model.compile(loss='mse', optimizer = optimizer, metrics=arr_metrics)\n",
        "  return model"
      ],
      "metadata": {
        "id": "a6LHGZSf2Ln4"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## augmented_df\n",
        "## getting train, test sets\n",
        "X_train, X_valid, X_test, y_train, y_valid,  y_test = get_train_test(augmented_df2)"
      ],
      "metadata": {
        "id": "GbpVj-dmmdZI"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## original_df\n",
        "## getting train, test sets\n",
        "X_train, X_valid, X_test, y_train, y_valid,  y_test = get_train_test(original_df)"
      ],
      "metadata": {
        "id": "pw5LMH4nOm8E"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(np.isnan(X_train)))\n",
        "print(np.sum(np.isnan(X_valid)))\n",
        "print(np.sum(np.isnan(X_test)))\n",
        "print(np.sum(np.isnan(y_train)))\n",
        "print(np.sum(np.isnan(y_valid)))\n",
        "print(np.sum(np.isnan(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Dy8krRvO7SG",
        "outputId": "91cdca74-608b-4b4f-e811-8ed6c432c7d4"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model (0.001, 0.3, X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AguEu36LooFH",
        "outputId": "29ac5068-1216-4c03-d26c-72b6b5da1f9b"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graph(p_model_history):\n",
        "    # Plot MAE\n",
        "    plt.plot(p_model_history['mae'])\n",
        "    plt.plot(p_model_history['val_mae'])\n",
        "\n",
        "    # Plot loss\n",
        "    plt.plot(p_model_history['loss'])\n",
        "    plt.plot(p_model_history['val_loss'])\n",
        "\n",
        "    # Add labels and legends for MAE and loss\n",
        "    plt.legend(['train MAE', 'test MAE', 'train loss', 'test loss'], loc='upper right')\n",
        "    plt.title('Model Metrics')\n",
        "    plt.ylabel('Metrics')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot accuracy (if applicable)\n",
        "    if 'accuracy' in p_model_history:\n",
        "        plt.plot(p_model_history['accuracy'])\n",
        "        plt.plot(p_model_history['val_accuracy'])\n",
        "\n",
        "        # Add labels and legends for accuracy\n",
        "        plt.legend(['train accuracy', 'test accuracy'], loc='upper right')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "WoX2qGjdxoTC"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graph_2(p_model_history, p_var_valid, p_var_test, p_arr_legend):\n",
        "    # Plot MAE\n",
        "    plt.plot(p_model_history[p_var_valid])\n",
        "    plt.plot(p_model_history[p_var_test])\n",
        "\n",
        "    ## Plot loss\n",
        "    #plt.plot(p_model_history['loss'])\n",
        "    #plt.plot(p_model_history['val_loss'])\n",
        "\n",
        "    ## Add labels and legends for MAE and loss\n",
        "    #plt.legend(['train MAE', 'test MAE', 'train loss', 'test loss'], loc='upper right')\n",
        "    plt.legend(p_arr_legend, loc='upper right')\n",
        "    plt.title('Model Metrics')\n",
        "    plt.ylabel('Metrics')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9ohTjvb85boS"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_analysis(pModel, pXTrain, pYTrain, pXTest, pYTest,\n",
        "                p_dropout_rate =0.3, p_learning_rate=0.01, p_epochs =30, p_batch_size=10,\n",
        "                p_validation_split=0.2, p_verbose=True, p_plot_graph=1):\n",
        "\n",
        "  ## we fit with train\n",
        "  model_history = pModel.fit(pXTrain, pYTrain, batch_size=p_batch_size, epochs=p_epochs, validation_split = p_validation_split, verbose=1)\n",
        "\n",
        "  ## we evaluate model's accuracy (use TEST vars, NOT TRAIN)\n",
        "  score = pModel.evaluate(pXTest, pYTest, verbose=p_verbose)\n",
        "\n",
        "  print(\"[Loss]: \", score[0])\n",
        "  print(\"[MSE]: \", score[1])\n",
        "\n",
        "  if(p_plot_graph):\n",
        "    #plot_graph(model_history.history)\n",
        "    #plot_graph_2(model_history.history, 'mae', 'val_mae', ['train MAE', 'test MAE'])\n",
        "    plot_graph_2(model_history.history, 'mse', 'val_mse', ['train MSE', 'test MSE'])\n",
        "    plot_graph_2(model_history.history, 'loss', 'val_loss', ['train LOSS', 'test LOSS'])\n"
      ],
      "metadata": {
        "id": "5w0Nddg9p0Tf"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Modele valuation\n",
        "model = create_model (0.001, 0.3, X_train)\n",
        "do_analysis(model, X_train, y_train, X_test, y_test, p_learning_rate =0.0001, p_epochs=50, p_verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fajV9jbsrp0A",
        "outputId": "54078343-a3c1-442b-bf18-caa997b47ded"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "103/103 [==============================] - 1s 4ms/step - loss: 6058.3442 - mse: 6058.3442 - val_loss: 2823.2405 - val_mse: 2823.2405\n",
            "Epoch 2/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 2838.4521 - mse: 2838.4521 - val_loss: 3082.2031 - val_mse: 3082.2031\n",
            "Epoch 3/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1674.1210 - mse: 1674.1210 - val_loss: 988.5646 - val_mse: 988.5646\n",
            "Epoch 4/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1164.3824 - mse: 1164.3824 - val_loss: 951.8929 - val_mse: 951.8929\n",
            "Epoch 5/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 1081.2546 - mse: 1081.2546 - val_loss: 739.3779 - val_mse: 739.3779\n",
            "Epoch 6/50\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 975.9260 - mse: 975.9260 - val_loss: 503.5330 - val_mse: 503.5330\n",
            "Epoch 7/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 928.3513 - mse: 928.3513 - val_loss: 789.5933 - val_mse: 789.5933\n",
            "Epoch 8/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 827.6080 - mse: 827.6081 - val_loss: 656.0024 - val_mse: 656.0024\n",
            "Epoch 9/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 885.7787 - mse: 885.7787 - val_loss: 512.8293 - val_mse: 512.8293\n",
            "Epoch 10/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 752.3591 - mse: 752.3591 - val_loss: 179.9425 - val_mse: 179.9425\n",
            "Epoch 11/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 674.5068 - mse: 674.5068 - val_loss: 430.8210 - val_mse: 430.8210\n",
            "Epoch 12/50\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 745.6705 - mse: 745.6706 - val_loss: 374.9118 - val_mse: 374.9118\n",
            "Epoch 13/50\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 644.3408 - mse: 644.3408 - val_loss: 431.2728 - val_mse: 431.2728\n",
            "Epoch 14/50\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 612.5511 - mse: 612.5511 - val_loss: 306.5273 - val_mse: 306.5273\n",
            "Epoch 15/50\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 604.4426 - mse: 604.4426 - val_loss: 302.9573 - val_mse: 302.9573\n",
            "Epoch 16/50\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 581.8030 - mse: 581.8030 - val_loss: 129.4473 - val_mse: 129.4473\n",
            "Epoch 17/50\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 590.3868 - mse: 590.3868 - val_loss: 327.3911 - val_mse: 327.3911\n",
            "Epoch 18/50\n",
            "103/103 [==============================] - 0s 4ms/step - loss: 547.2776 - mse: 547.2776 - val_loss: 231.9620 - val_mse: 231.9620\n",
            "Epoch 19/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 513.7600 - mse: 513.7600 - val_loss: 79.4604 - val_mse: 79.4604\n",
            "Epoch 20/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 560.9392 - mse: 560.9392 - val_loss: 218.4312 - val_mse: 218.4312\n",
            "Epoch 21/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 549.5837 - mse: 549.5837 - val_loss: 177.9230 - val_mse: 177.9230\n",
            "Epoch 22/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 540.5920 - mse: 540.5920 - val_loss: 186.5021 - val_mse: 186.5021\n",
            "Epoch 23/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 490.7772 - mse: 490.7772 - val_loss: 112.7234 - val_mse: 112.7234\n",
            "Epoch 24/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 494.5390 - mse: 494.5390 - val_loss: 182.4308 - val_mse: 182.4308\n",
            "Epoch 25/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 477.2547 - mse: 477.2547 - val_loss: 77.3863 - val_mse: 77.3863\n",
            "Epoch 26/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 491.0890 - mse: 491.0890 - val_loss: 199.9568 - val_mse: 199.9568\n",
            "Epoch 27/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 500.5045 - mse: 500.5045 - val_loss: 175.3414 - val_mse: 175.3414\n",
            "Epoch 28/50\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 481.9916 - mse: 481.9916 - val_loss: 269.1090 - val_mse: 269.1090\n",
            "Epoch 29/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 457.7791 - mse: 457.7791 - val_loss: 86.6936 - val_mse: 86.6936\n",
            "Epoch 30/50\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 504.5977 - mse: 504.5977 - val_loss: 359.6573 - val_mse: 359.6573\n",
            "Epoch 31/50\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 499.9494 - mse: 499.9494 - val_loss: 190.1703 - val_mse: 190.1703\n",
            "Epoch 32/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 443.2800 - mse: 443.2800 - val_loss: 156.4618 - val_mse: 156.4618\n",
            "Epoch 33/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 439.2672 - mse: 439.2672 - val_loss: 25.7926 - val_mse: 25.7926\n",
            "Epoch 34/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 449.2981 - mse: 449.2981 - val_loss: 249.3477 - val_mse: 249.3477\n",
            "Epoch 35/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 414.9092 - mse: 414.9093 - val_loss: 18.0976 - val_mse: 18.0976\n",
            "Epoch 36/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 415.8090 - mse: 415.8090 - val_loss: 68.4359 - val_mse: 68.4359\n",
            "Epoch 37/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 432.6888 - mse: 432.6888 - val_loss: 65.3019 - val_mse: 65.3019\n",
            "Epoch 38/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 435.2182 - mse: 435.2182 - val_loss: 157.0153 - val_mse: 157.0153\n",
            "Epoch 39/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 469.6877 - mse: 469.6877 - val_loss: 271.0243 - val_mse: 271.0243\n",
            "Epoch 40/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 412.7636 - mse: 412.7636 - val_loss: 28.0802 - val_mse: 28.0802\n",
            "Epoch 41/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 437.0855 - mse: 437.0855 - val_loss: 144.8983 - val_mse: 144.8983\n",
            "Epoch 42/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 447.6275 - mse: 447.6275 - val_loss: 84.6068 - val_mse: 84.6068\n",
            "Epoch 43/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 409.8120 - mse: 409.8120 - val_loss: 86.6647 - val_mse: 86.6647\n",
            "Epoch 44/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 400.3873 - mse: 400.3873 - val_loss: 87.9395 - val_mse: 87.9395\n",
            "Epoch 45/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 428.6820 - mse: 428.6820 - val_loss: 37.3567 - val_mse: 37.3567\n",
            "Epoch 46/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 392.8004 - mse: 392.8004 - val_loss: 92.6588 - val_mse: 92.6588\n",
            "Epoch 47/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 405.7159 - mse: 405.7159 - val_loss: 83.5324 - val_mse: 83.5324\n",
            "Epoch 48/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 404.7917 - mse: 404.7917 - val_loss: 12.8045 - val_mse: 12.8045\n",
            "Epoch 49/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 390.5866 - mse: 390.5866 - val_loss: 96.7375 - val_mse: 96.7375\n",
            "Epoch 50/50\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 399.2192 - mse: 399.2192 - val_loss: 17.9083 - val_mse: 17.9083\n",
            "[Loss]:  18.486255645751953\n",
            "[MSE]:  18.486255645751953\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data and define input_shape\n",
        "input_shape = X_train.shape[1]  # Number of features\n",
        "\n",
        "# Create the KerasRegressor with your build_model function\n",
        "keras_reg = KerasRegressor(build_fn=build_model, p_input_shape=input_shape, p_n_hidden=3, p_n_neurons=30, p_learning_rate=3e-4, p_activation='relu')\n"
      ],
      "metadata": {
        "id": "jyItKGvWsnHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce4e15a9-50ca-43d9-ea2f-834b8a468be8"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-146-bba7af904efa>:5: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  keras_reg = KerasRegressor(build_fn=build_model, p_input_shape=input_shape, p_n_hidden=3, p_n_neurons=30, p_learning_rate=3e-4, p_activation='relu')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras_reg.fit( X_train, y_train, epochs = 40,\n",
        "              validation_data=(X_valid, y_valid),\n",
        "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "\n",
        "msa_test = keras_reg.score(X_test, y_test)\n",
        "y_pred = keras_reg.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "print('y_test: ', y_test.isna().sum())\n",
        "dfYPred = pd.DataFrame(y_pred)\n",
        "print('y_pred: ', dfYPred.isna().sum())\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mse_test = -msa_test\n",
        "\n",
        "# Calculate R-squared (Coefficient of Determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"[MSE] Mean Squared Error:\", mse)\n",
        "print(\"[MSE] Mean Squared Error:\", mse_test)\n",
        "print(\"R-squared:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nwzjFVfzGFi",
        "outputId": "3d0095bd-bc42-46da-fa38-3380b821bcef"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 1s 9ms/step - loss: 6041.4800 - mse: 6041.4800 - val_loss: 4097.6475 - val_mse: 4097.6475\n",
            "Epoch 2/40\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1307.4932 - mse: 1307.4932 - val_loss: 91.2509 - val_mse: 91.2509\n",
            "Epoch 3/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 54.8493 - mse: 54.8493 - val_loss: 125.1270 - val_mse: 125.1270\n",
            "Epoch 4/40\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 50.2228 - mse: 50.2228 - val_loss: 54.0249 - val_mse: 54.0249\n",
            "Epoch 5/40\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 49.4882 - mse: 49.4882 - val_loss: 60.7082 - val_mse: 60.7082\n",
            "Epoch 6/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 49.2522 - mse: 49.2522 - val_loss: 78.8422 - val_mse: 78.8422\n",
            "Epoch 7/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 48.4606 - mse: 48.4606 - val_loss: 137.2689 - val_mse: 137.2689\n",
            "Epoch 8/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 50.6083 - mse: 50.6083 - val_loss: 391.6211 - val_mse: 391.6211\n",
            "Epoch 9/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 50.8432 - mse: 50.8432 - val_loss: 441.4124 - val_mse: 441.4124\n",
            "Epoch 10/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 48.5793 - mse: 48.5793 - val_loss: 82.6609 - val_mse: 82.6609\n",
            "Epoch 11/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 49.5794 - mse: 49.5794 - val_loss: 409.0453 - val_mse: 409.0453\n",
            "Epoch 12/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 50.2363 - mse: 50.2363 - val_loss: 142.1419 - val_mse: 142.1419\n",
            "Epoch 13/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 49.3875 - mse: 49.3875 - val_loss: 94.5237 - val_mse: 94.5237\n",
            "Epoch 14/40\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 49.9217 - mse: 49.9217 - val_loss: 98.3003 - val_mse: 98.3003\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 204.0043 - mse: 204.0043\n",
            "13/13 [==============================] - 0s 3ms/step\n",
            "y_test:  0\n",
            "y_pred:  0    0\n",
            "dtype: int64\n",
            "[MSE] Mean Squared Error: 204.00437250451694\n",
            "[MSE] Mean Squared Error: 204.00430297851562\n",
            "R-squared: -3.305908677740078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the checkpoint callback\n",
        "checkpoint_cb = ModelCheckpoint(filepath=\"best_model.h5\", save_best_only=True)\n",
        "\n",
        "# Other callbacks you might have (e.g., EarlyStopping)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
        "\n",
        "param_distribs = {\n",
        "    \"p_n_hidden\": [0,1,2,3],\n",
        "    \"p_n_neurons\": np.arange(1,500),\n",
        "    \"p_learning_rate\" : reciprocal(1e-5, 1e-2)\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=5, cv=3, scoring='neg_mean_squared_error')\n",
        "\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=50,\n",
        "                  validation_data=(X_valid, y_valid),\n",
        "                  callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "\n",
        "# Access the best model and print its summary\n",
        "best_model = rnd_search_cv.best_estimator_.model\n",
        "print('================================')\n",
        "print('-- Best Model Summary --')\n",
        "best_model.summary()\n",
        "print('-- Best params --')\n",
        "print(rnd_search_cv.best_params_)\n",
        "print('-- Best score --')\n",
        "print(rnd_search_cv.best_score_)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq-WlHeNBZle",
        "outputId": "f8489064-3620-4646-85b4-b3e6310ead01"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "27/27 [==============================] - 1s 15ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 12ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 14ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 13ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 10ms/step - loss: 6847.3135 - mse: 6847.3135 - val_loss: 6773.8555 - val_mse: 6773.8555\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6728.0166 - mse: 6728.0166 - val_loss: 6700.8306 - val_mse: 6700.8306\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6588.8364 - mse: 6588.8364 - val_loss: 6585.1162 - val_mse: 6585.1162\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6412.5957 - mse: 6412.5957 - val_loss: 6334.8608 - val_mse: 6334.8608\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6178.9287 - mse: 6178.9287 - val_loss: 5983.9492 - val_mse: 5983.9492\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5862.3545 - mse: 5862.3545 - val_loss: 5591.6821 - val_mse: 5591.6821\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5436.6025 - mse: 5436.6025 - val_loss: 1450.1942 - val_mse: 1450.1942\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4879.4683 - mse: 4879.4683 - val_loss: 4587.6670 - val_mse: 4587.6670\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4186.6919 - mse: 4186.6919 - val_loss: 3836.3774 - val_mse: 3836.3774\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3387.7153 - mse: 3387.7153 - val_loss: 3025.8606 - val_mse: 3025.8606\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2549.9717 - mse: 2549.9717 - val_loss: 2198.8110 - val_mse: 2198.8110\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1768.7054 - mse: 1768.7054 - val_loss: 1440.5940 - val_mse: 1440.5940\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1128.6906 - mse: 1128.6906 - val_loss: 938.1244 - val_mse: 938.1244\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 670.6133 - mse: 670.6133 - val_loss: 478.6750 - val_mse: 478.6750\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 380.2444 - mse: 380.2444 - val_loss: 272.8040 - val_mse: 272.8040\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 214.2562 - mse: 214.2562 - val_loss: 172.5919 - val_mse: 172.5919\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 127.8336 - mse: 127.8336 - val_loss: 110.6488 - val_mse: 110.6488\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 86.3227 - mse: 86.3227 - val_loss: 83.8522 - val_mse: 83.8522\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 66.5470 - mse: 66.5470 - val_loss: 79.3212 - val_mse: 79.3212\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 56.4911 - mse: 56.4911 - val_loss: 59.9131 - val_mse: 59.9131\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 52.4717 - mse: 52.4717 - val_loss: 54.2219 - val_mse: 54.2219\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.6315 - mse: 50.6315 - val_loss: 58.4500 - val_mse: 58.4500\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 51.0956 - mse: 51.0956 - val_loss: 54.6167 - val_mse: 54.6167\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.7749 - mse: 50.7749 - val_loss: 54.8498 - val_mse: 54.8498\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.0291 - mse: 50.0291 - val_loss: 55.8689 - val_mse: 55.8689\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.9056 - mse: 49.9056 - val_loss: 53.4334 - val_mse: 53.4334\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.6850 - mse: 49.6850 - val_loss: 59.1020 - val_mse: 59.1020\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.8297 - mse: 49.8297 - val_loss: 59.0378 - val_mse: 59.0378\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.8523 - mse: 49.8523 - val_loss: 53.0782 - val_mse: 53.0782\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.0754 - mse: 50.0754 - val_loss: 57.9608 - val_mse: 57.9608\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.5817 - mse: 49.5817 - val_loss: 54.2288 - val_mse: 54.2288\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 49.5820 - mse: 49.5820 - val_loss: 65.4811 - val_mse: 65.4811\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.3386 - mse: 49.3386 - val_loss: 51.2848 - val_mse: 51.2848\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.7044 - mse: 50.7044 - val_loss: 51.1142 - val_mse: 51.1142\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.9395 - mse: 49.9395 - val_loss: 51.6789 - val_mse: 51.6789\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.4313 - mse: 49.4313 - val_loss: 54.9795 - val_mse: 54.9795\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.6639 - mse: 49.6639 - val_loss: 52.3145 - val_mse: 52.3145\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.7234 - mse: 49.7234 - val_loss: 54.5298 - val_mse: 54.5298\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 49.4136 - mse: 49.4136 - val_loss: 51.5409 - val_mse: 51.5409\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.3899 - mse: 50.3899 - val_loss: 68.4492 - val_mse: 68.4492\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 53.2981 - mse: 53.2981 - val_loss: 51.6364 - val_mse: 51.6364\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 51.0034 - mse: 51.0034 - val_loss: 49.7504 - val_mse: 49.7504\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 51.8629 - mse: 51.8629 - val_loss: 53.3021 - val_mse: 53.3021\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.5460 - mse: 50.5460 - val_loss: 51.5327 - val_mse: 51.5327\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.4134 - mse: 49.4134 - val_loss: 55.1346 - val_mse: 55.1346\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.2271 - mse: 49.2271 - val_loss: 57.1368 - val_mse: 57.1368\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.5061 - mse: 49.5061 - val_loss: 54.9375 - val_mse: 54.9375\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 48.9554 - mse: 48.9554 - val_loss: 52.3619 - val_mse: 52.3619\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 49.2771 - mse: 49.2771 - val_loss: 53.1310 - val_mse: 53.1310\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 48.9860 - mse: 48.9860 - val_loss: 51.7402 - val_mse: 51.7402\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 10ms/step - loss: 6895.7935 - mse: 6895.7935 - val_loss: 6809.3257 - val_mse: 6809.3257\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6780.5229 - mse: 6780.5229 - val_loss: 6693.2295 - val_mse: 6693.2295\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6646.4961 - mse: 6646.4961 - val_loss: 6535.8472 - val_mse: 6535.8472\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6476.9365 - mse: 6476.9365 - val_loss: 6360.5088 - val_mse: 6360.5088\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6251.8516 - mse: 6251.8516 - val_loss: 6055.1748 - val_mse: 6055.1748\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5946.4087 - mse: 5946.4087 - val_loss: 5706.9800 - val_mse: 5706.9800\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5534.0752 - mse: 5534.0752 - val_loss: 5292.6753 - val_mse: 5292.6753\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4991.0493 - mse: 4991.0493 - val_loss: 4685.8472 - val_mse: 4685.8472\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 4308.4932 - mse: 4308.4932 - val_loss: 3936.0540 - val_mse: 3936.0540\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3512.2544 - mse: 3512.2544 - val_loss: 2948.8074 - val_mse: 2948.8074\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2666.6436 - mse: 2666.6436 - val_loss: 2267.6184 - val_mse: 2267.6184\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1866.3689 - mse: 1866.3689 - val_loss: 1551.4912 - val_mse: 1551.4912\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1200.2432 - mse: 1200.2432 - val_loss: 997.3685 - val_mse: 997.3685\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 716.8674 - mse: 716.8674 - val_loss: 638.3892 - val_mse: 638.3892\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 408.5690 - mse: 408.5690 - val_loss: 325.4119 - val_mse: 325.4119\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 227.9387 - mse: 227.9387 - val_loss: 239.5091 - val_mse: 239.5091\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 135.3511 - mse: 135.3511 - val_loss: 138.3916 - val_mse: 138.3916\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 89.0598 - mse: 89.0598 - val_loss: 90.1605 - val_mse: 90.1605\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 66.0831 - mse: 66.0831 - val_loss: 68.4387 - val_mse: 68.4387\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 57.5659 - mse: 57.5659 - val_loss: 63.4203 - val_mse: 63.4203\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 54.5764 - mse: 54.5764 - val_loss: 59.6283 - val_mse: 59.6283\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 50.9954 - mse: 50.9954 - val_loss: 60.3861 - val_mse: 60.3861\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 49.3400 - mse: 49.3400 - val_loss: 62.2624 - val_mse: 62.2624\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 48.6641 - mse: 48.6641 - val_loss: 61.6295 - val_mse: 61.6295\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 48.6376 - mse: 48.6376 - val_loss: 54.0859 - val_mse: 54.0859\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 48.4703 - mse: 48.4703 - val_loss: 57.4841 - val_mse: 57.4841\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 48.1483 - mse: 48.1483 - val_loss: 65.8469 - val_mse: 65.8469\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 48.1769 - mse: 48.1769 - val_loss: 79.5390 - val_mse: 79.5390\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 47.8336 - mse: 47.8336 - val_loss: 64.3765 - val_mse: 64.3765\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 47.3563 - mse: 47.3563 - val_loss: 58.2179 - val_mse: 58.2179\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 47.0974 - mse: 47.0974 - val_loss: 69.5598 - val_mse: 69.5598\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 47.1999 - mse: 47.1999 - val_loss: 73.6219 - val_mse: 73.6219\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 46.9159 - mse: 46.9159 - val_loss: 57.7965 - val_mse: 57.7965\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 47.4344 - mse: 47.4344 - val_loss: 63.3190 - val_mse: 63.3190\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 47.2828 - mse: 47.2828 - val_loss: 72.8443 - val_mse: 72.8443\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 9ms/step - loss: 6924.5063 - mse: 6924.5063 - val_loss: 6800.7002 - val_mse: 6800.7002\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6807.8188 - mse: 6807.8188 - val_loss: 6689.0142 - val_mse: 6689.0142\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6671.6729 - mse: 6671.6729 - val_loss: 6536.3071 - val_mse: 6536.3071\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6499.1157 - mse: 6499.1157 - val_loss: 6364.9561 - val_mse: 6364.9561\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6269.5962 - mse: 6269.5962 - val_loss: 6022.6455 - val_mse: 6022.6455\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5958.3745 - mse: 5958.3745 - val_loss: 5731.0962 - val_mse: 5731.0962\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5537.4443 - mse: 5537.4443 - val_loss: 5257.9326 - val_mse: 5257.9326\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4984.5537 - mse: 4984.5537 - val_loss: 4706.4873 - val_mse: 4706.4873\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4292.1289 - mse: 4292.1289 - val_loss: 3869.5156 - val_mse: 3869.5156\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3486.2642 - mse: 3486.2642 - val_loss: 3022.3638 - val_mse: 3022.3638\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2633.7144 - mse: 2633.7144 - val_loss: 2168.8386 - val_mse: 2168.8386\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1833.5583 - mse: 1833.5583 - val_loss: 1478.7078 - val_mse: 1478.7078\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1174.3611 - mse: 1174.3611 - val_loss: 899.1935 - val_mse: 899.1935\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 697.6603 - mse: 697.6603 - val_loss: 496.3861 - val_mse: 496.3861\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 393.8987 - mse: 393.8987 - val_loss: 272.0568 - val_mse: 272.0568\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 221.0236 - mse: 221.0236 - val_loss: 148.6296 - val_mse: 148.6296\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 130.6360 - mse: 130.6360 - val_loss: 92.7817 - val_mse: 92.7817\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 87.1026 - mse: 87.1026 - val_loss: 104.5821 - val_mse: 104.5821\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 66.6609 - mse: 66.6609 - val_loss: 63.9255 - val_mse: 63.9255\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 57.1541 - mse: 57.1541 - val_loss: 57.5038 - val_mse: 57.5038\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 53.5922 - mse: 53.5922 - val_loss: 58.4763 - val_mse: 58.4763\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 51.9272 - mse: 51.9272 - val_loss: 132.4056 - val_mse: 132.4056\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 51.0921 - mse: 51.0921 - val_loss: 59.5864 - val_mse: 59.5864\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 50.3671 - mse: 50.3671 - val_loss: 57.8004 - val_mse: 57.8004\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 51.7758 - mse: 51.7758 - val_loss: 56.8040 - val_mse: 56.8040\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.5851 - mse: 50.5851 - val_loss: 56.0222 - val_mse: 56.0222\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.9407 - mse: 49.9407 - val_loss: 60.0160 - val_mse: 60.0160\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 49.7403 - mse: 49.7403 - val_loss: 53.8196 - val_mse: 53.8196\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.3971 - mse: 50.3971 - val_loss: 56.9698 - val_mse: 56.9698\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.6544 - mse: 49.6544 - val_loss: 55.5166 - val_mse: 55.5166\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 50.8419 - mse: 50.8419 - val_loss: 110.4683 - val_mse: 110.4683\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.9030 - mse: 50.9030 - val_loss: 59.3129 - val_mse: 59.3129\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 51.9009 - mse: 51.9009 - val_loss: 62.9370 - val_mse: 62.9370\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.9116 - mse: 50.9116 - val_loss: 57.4707 - val_mse: 57.4707\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 51.1835 - mse: 51.1835 - val_loss: 61.6870 - val_mse: 61.6870\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.6124 - mse: 50.6124 - val_loss: 55.0311 - val_mse: 55.0311\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 50.2001 - mse: 50.2001 - val_loss: 54.2875 - val_mse: 54.2875\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 49.9780 - mse: 49.9780 - val_loss: 59.7047 - val_mse: 59.7047\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 0s 7ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 11ms/step - loss: 6889.2964 - mse: 6889.2964 - val_loss: 6885.4287 - val_mse: 6885.4287\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6865.7222 - mse: 6865.7222 - val_loss: 6766.6572 - val_mse: 6766.6572\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6841.2856 - mse: 6841.2856 - val_loss: 6830.1016 - val_mse: 6830.1016\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6817.5693 - mse: 6817.5693 - val_loss: 6762.3584 - val_mse: 6762.3584\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6793.4585 - mse: 6793.4585 - val_loss: 6822.1226 - val_mse: 6822.1226\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6768.0444 - mse: 6768.0444 - val_loss: 7010.8516 - val_mse: 7010.8516\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6741.7783 - mse: 6741.7783 - val_loss: 6971.6240 - val_mse: 6971.6240\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6716.5293 - mse: 6716.5293 - val_loss: 6599.4229 - val_mse: 6599.4229\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6688.4526 - mse: 6688.4526 - val_loss: 6801.5562 - val_mse: 6801.5562\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6660.3315 - mse: 6660.3315 - val_loss: 6504.1777 - val_mse: 6504.1777\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6629.8354 - mse: 6629.8354 - val_loss: 6557.1069 - val_mse: 6557.1069\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6598.6553 - mse: 6598.6553 - val_loss: 6624.1094 - val_mse: 6624.1094\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6564.3828 - mse: 6564.3828 - val_loss: 6456.5913 - val_mse: 6456.5913\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6529.8984 - mse: 6529.8984 - val_loss: 6563.3682 - val_mse: 6563.3682\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6491.4648 - mse: 6491.4648 - val_loss: 6459.4258 - val_mse: 6459.4258\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6452.7544 - mse: 6452.7544 - val_loss: 6504.0210 - val_mse: 6504.0210\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6409.9600 - mse: 6409.9600 - val_loss: 6387.3643 - val_mse: 6387.3643\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6363.4009 - mse: 6363.4009 - val_loss: 6275.6943 - val_mse: 6275.6943\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6315.9492 - mse: 6315.9492 - val_loss: 6397.3140 - val_mse: 6397.3140\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6264.6021 - mse: 6264.6021 - val_loss: 6244.1831 - val_mse: 6244.1831\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6208.8022 - mse: 6208.8022 - val_loss: 6125.3320 - val_mse: 6125.3320\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6150.4565 - mse: 6150.4565 - val_loss: 6028.7373 - val_mse: 6028.7373\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6086.8594 - mse: 6086.8594 - val_loss: 5969.8740 - val_mse: 5969.8740\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6018.5532 - mse: 6018.5532 - val_loss: 5968.6694 - val_mse: 5968.6694\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5945.2373 - mse: 5945.2373 - val_loss: 5937.7417 - val_mse: 5937.7417\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 5867.2075 - mse: 5867.2075 - val_loss: 5934.9038 - val_mse: 5934.9038\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5782.7432 - mse: 5782.7432 - val_loss: 5911.2485 - val_mse: 5911.2485\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 5694.0312 - mse: 5694.0312 - val_loss: 5777.4775 - val_mse: 5777.4775\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5598.0400 - mse: 5598.0400 - val_loss: 5655.6592 - val_mse: 5655.6592\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 5496.5620 - mse: 5496.5620 - val_loss: 5413.5054 - val_mse: 5413.5054\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5389.3159 - mse: 5389.3159 - val_loss: 5450.3330 - val_mse: 5450.3330\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5274.7812 - mse: 5274.7812 - val_loss: 5352.5420 - val_mse: 5352.5420\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 5151.4932 - mse: 5151.4932 - val_loss: 5157.8042 - val_mse: 5157.8042\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 5023.9761 - mse: 5023.9761 - val_loss: 5094.0146 - val_mse: 5094.0146\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 4888.6812 - mse: 4888.6812 - val_loss: 4934.8252 - val_mse: 4934.8252\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 4744.9131 - mse: 4744.9131 - val_loss: 4554.1699 - val_mse: 4554.1699\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4594.9155 - mse: 4594.9155 - val_loss: 5021.9585 - val_mse: 5021.9585\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 4441.8013 - mse: 4441.8013 - val_loss: 4485.4756 - val_mse: 4485.4756\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 4278.3018 - mse: 4278.3018 - val_loss: 4236.0400 - val_mse: 4236.0400\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 4110.2314 - mse: 4110.2314 - val_loss: 4119.3647 - val_mse: 4119.3647\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3937.2224 - mse: 3937.2224 - val_loss: 3920.9102 - val_mse: 3920.9102\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3758.2893 - mse: 3758.2893 - val_loss: 3764.0591 - val_mse: 3764.0591\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3574.0244 - mse: 3574.0244 - val_loss: 3369.6414 - val_mse: 3369.6414\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3390.8435 - mse: 3390.8435 - val_loss: 3319.3042 - val_mse: 3319.3042\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3200.2861 - mse: 3200.2861 - val_loss: 2951.8169 - val_mse: 2951.8169\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3012.0322 - mse: 3012.0322 - val_loss: 3115.4553 - val_mse: 3115.4553\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2823.7412 - mse: 2823.7412 - val_loss: 2661.1909 - val_mse: 2661.1909\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2639.1838 - mse: 2639.1838 - val_loss: 2475.7615 - val_mse: 2475.7615\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2454.3789 - mse: 2454.3789 - val_loss: 2431.8872 - val_mse: 2431.8872\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2274.6919 - mse: 2274.6919 - val_loss: 2371.9470 - val_mse: 2371.9470\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 11ms/step - loss: 6936.6426 - mse: 6936.6426 - val_loss: 6895.0352 - val_mse: 6895.0352\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6910.0713 - mse: 6910.0713 - val_loss: 6880.5518 - val_mse: 6880.5518\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6883.6665 - mse: 6883.6665 - val_loss: 6892.7329 - val_mse: 6892.7329\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6857.7524 - mse: 6857.7524 - val_loss: 6824.7383 - val_mse: 6824.7383\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6831.3271 - mse: 6831.3271 - val_loss: 6833.9385 - val_mse: 6833.9385\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6804.3452 - mse: 6804.3452 - val_loss: 6809.1821 - val_mse: 6809.1821\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6775.9536 - mse: 6775.9536 - val_loss: 6706.5210 - val_mse: 6706.5210\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6747.7026 - mse: 6747.7026 - val_loss: 6866.0850 - val_mse: 6866.0850\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6717.7188 - mse: 6717.7188 - val_loss: 6852.0884 - val_mse: 6852.0884\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 6686.0713 - mse: 6686.0713 - val_loss: 6666.0869 - val_mse: 6666.0869\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6653.3096 - mse: 6653.3096 - val_loss: 6557.2437 - val_mse: 6557.2437\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6619.1655 - mse: 6619.1655 - val_loss: 6600.0142 - val_mse: 6600.0142\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6583.3818 - mse: 6583.3818 - val_loss: 6454.0264 - val_mse: 6454.0264\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6543.9204 - mse: 6543.9204 - val_loss: 6533.3750 - val_mse: 6533.3750\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6503.9238 - mse: 6503.9238 - val_loss: 6699.0391 - val_mse: 6699.0391\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6460.3984 - mse: 6460.3984 - val_loss: 6666.1514 - val_mse: 6666.1514\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6413.5059 - mse: 6413.5059 - val_loss: 6434.7871 - val_mse: 6434.7871\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6363.8267 - mse: 6363.8267 - val_loss: 6316.4062 - val_mse: 6316.4062\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6310.3750 - mse: 6310.3750 - val_loss: 6482.4038 - val_mse: 6482.4038\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6254.6719 - mse: 6254.6719 - val_loss: 6100.4175 - val_mse: 6100.4175\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6193.2188 - mse: 6193.2188 - val_loss: 6303.1929 - val_mse: 6303.1929\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6126.2271 - mse: 6126.2271 - val_loss: 6707.3936 - val_mse: 6707.3936\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6058.9014 - mse: 6058.9014 - val_loss: 6235.1567 - val_mse: 6235.1567\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5983.9746 - mse: 5983.9746 - val_loss: 5993.8374 - val_mse: 5993.8374\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 5903.9087 - mse: 5903.9087 - val_loss: 5919.3115 - val_mse: 5919.3115\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5817.4053 - mse: 5817.4053 - val_loss: 5994.3379 - val_mse: 5994.3379\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5726.3516 - mse: 5726.3516 - val_loss: 5754.6235 - val_mse: 5754.6235\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 5628.9092 - mse: 5628.9092 - val_loss: 5602.3076 - val_mse: 5602.3076\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 5525.3394 - mse: 5525.3394 - val_loss: 5523.1602 - val_mse: 5523.1602\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5413.9556 - mse: 5413.9556 - val_loss: 5440.7393 - val_mse: 5440.7393\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 5295.5703 - mse: 5295.5703 - val_loss: 5487.8208 - val_mse: 5487.8208\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5171.7485 - mse: 5171.7485 - val_loss: 5292.2568 - val_mse: 5292.2568\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5040.3965 - mse: 5040.3965 - val_loss: 5034.1084 - val_mse: 5034.1084\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 4902.2373 - mse: 4902.2373 - val_loss: 4845.4009 - val_mse: 4845.4009\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4755.4175 - mse: 4755.4175 - val_loss: 4361.2031 - val_mse: 4361.2031\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4603.2026 - mse: 4603.2026 - val_loss: 4278.9497 - val_mse: 4278.9497\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 4443.5801 - mse: 4443.5801 - val_loss: 4547.9526 - val_mse: 4547.9526\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4277.6265 - mse: 4277.6265 - val_loss: 4258.5957 - val_mse: 4258.5957\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 4103.9585 - mse: 4103.9585 - val_loss: 3967.2371 - val_mse: 3967.2371\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3929.9067 - mse: 3929.9067 - val_loss: 3859.7278 - val_mse: 3859.7278\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3748.0071 - mse: 3748.0071 - val_loss: 3868.0383 - val_mse: 3868.0383\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3563.3767 - mse: 3563.3767 - val_loss: 3425.4688 - val_mse: 3425.4688\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 3375.7031 - mse: 3375.7031 - val_loss: 3283.3137 - val_mse: 3283.3137\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 3183.7166 - mse: 3183.7166 - val_loss: 2852.0464 - val_mse: 2852.0464\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2993.8804 - mse: 2993.8804 - val_loss: 2847.0684 - val_mse: 2847.0684\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2803.0405 - mse: 2803.0405 - val_loss: 2919.1821 - val_mse: 2919.1821\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2610.4507 - mse: 2610.4507 - val_loss: 3395.4570 - val_mse: 3395.4570\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2425.9023 - mse: 2425.9023 - val_loss: 2717.4619 - val_mse: 2717.4619\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2245.5994 - mse: 2245.5994 - val_loss: 2743.9792 - val_mse: 2743.9792\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2068.6897 - mse: 2068.6897 - val_loss: 2705.8481 - val_mse: 2705.8481\n",
            "14/14 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 11ms/step - loss: 6966.2378 - mse: 6966.2378 - val_loss: 6889.1953 - val_mse: 6889.1953\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6938.9053 - mse: 6938.9053 - val_loss: 6868.4111 - val_mse: 6868.4111\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6911.6919 - mse: 6911.6919 - val_loss: 6800.1694 - val_mse: 6800.1694\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 6884.7461 - mse: 6884.7461 - val_loss: 6813.8657 - val_mse: 6813.8657\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6856.8687 - mse: 6856.8687 - val_loss: 6896.5156 - val_mse: 6896.5156\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6828.9731 - mse: 6828.9731 - val_loss: 6768.5610 - val_mse: 6768.5610\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6799.9556 - mse: 6799.9556 - val_loss: 6704.2695 - val_mse: 6704.2695\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6770.5146 - mse: 6770.5146 - val_loss: 6230.3584 - val_mse: 6230.3584\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6739.0713 - mse: 6739.0713 - val_loss: 4086.7722 - val_mse: 4086.7722\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6705.6953 - mse: 6705.6953 - val_loss: 6656.1055 - val_mse: 6656.1055\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6672.1416 - mse: 6672.1416 - val_loss: 6632.3452 - val_mse: 6632.3452\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6636.0327 - mse: 6636.0327 - val_loss: 6588.0952 - val_mse: 6588.0952\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6598.2129 - mse: 6598.2129 - val_loss: 6281.3613 - val_mse: 6281.3613\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6557.5400 - mse: 6557.5400 - val_loss: 6482.5366 - val_mse: 6482.5366\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 6514.2422 - mse: 6514.2422 - val_loss: 6460.5459 - val_mse: 6460.5459\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6468.3940 - mse: 6468.3940 - val_loss: 6437.3154 - val_mse: 6437.3154\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 6420.3125 - mse: 6420.3125 - val_loss: 6334.0273 - val_mse: 6334.0273\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6367.2646 - mse: 6367.2646 - val_loss: 6355.7861 - val_mse: 6355.7861\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6310.8306 - mse: 6310.8306 - val_loss: 6232.7310 - val_mse: 6232.7310\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 8ms/step - loss: 1847.3517 - mse: 1847.3517 - val_loss: 62.4004 - val_mse: 62.4004\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 684.5429 - mse: 684.5429 - val_loss: 1831.7662 - val_mse: 1831.7662\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 855.2094 - mse: 855.2094 - val_loss: 352.9189 - val_mse: 352.9189\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 597.9127 - mse: 597.9127 - val_loss: 251.9468 - val_mse: 251.9468\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 540.6342 - mse: 540.6342 - val_loss: 211.0354 - val_mse: 211.0354\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 429.8633 - mse: 429.8633 - val_loss: 617.3519 - val_mse: 617.3519\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 315.1261 - mse: 315.1261 - val_loss: 172.6673 - val_mse: 172.6673\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 248.7194 - mse: 248.7194 - val_loss: 66.0133 - val_mse: 66.0133\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 185.2227 - mse: 185.2227 - val_loss: 189.7511 - val_mse: 189.7511\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 269.9770 - mse: 269.9770 - val_loss: 225.2889 - val_mse: 225.2889\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 251.8289 - mse: 251.8289 - val_loss: 221.3563 - val_mse: 221.3563\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 9ms/step - loss: 1407.1383 - mse: 1407.1383 - val_loss: 3012.5623 - val_mse: 3012.5623\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 872.0983 - mse: 872.0983 - val_loss: 485.2542 - val_mse: 485.2542\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 896.3737 - mse: 896.3737 - val_loss: 1024.6711 - val_mse: 1024.6711\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 763.4998 - mse: 763.4998 - val_loss: 465.8582 - val_mse: 465.8582\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 652.4811 - mse: 652.4811 - val_loss: 341.0002 - val_mse: 341.0002\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 529.9655 - mse: 529.9655 - val_loss: 259.2921 - val_mse: 259.2921\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 342.4723 - mse: 342.4723 - val_loss: 337.0532 - val_mse: 337.0532\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 236.8867 - mse: 236.8867 - val_loss: 166.1123 - val_mse: 166.1123\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 244.4234 - mse: 244.4234 - val_loss: 143.1201 - val_mse: 143.1201\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 225.5809 - mse: 225.5809 - val_loss: 303.5211 - val_mse: 303.5211\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 238.0388 - mse: 238.0388 - val_loss: 2435.8716 - val_mse: 2435.8716\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 121.4790 - mse: 121.4790 - val_loss: 176.8728 - val_mse: 176.8728\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 120.4994 - mse: 120.4994 - val_loss: 294.0710 - val_mse: 294.0710\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 144.3035 - mse: 144.3035 - val_loss: 161.8197 - val_mse: 161.8197\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 145.6797 - mse: 145.6797 - val_loss: 113.4572 - val_mse: 113.4572\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 186.2414 - mse: 186.2414 - val_loss: 214.6956 - val_mse: 214.6956\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 131.6928 - mse: 131.6928 - val_loss: 60.6139 - val_mse: 60.6139\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 100.9871 - mse: 100.9871 - val_loss: 87.5646 - val_mse: 87.5646\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 97.0203 - mse: 97.0203 - val_loss: 49.9162 - val_mse: 49.9162\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 82.3289 - mse: 82.3289 - val_loss: 46.7094 - val_mse: 46.7094\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 143.6832 - mse: 143.6832 - val_loss: 217.8429 - val_mse: 217.8429\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 88.4960 - mse: 88.4960 - val_loss: 44.4869 - val_mse: 44.4869\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 46.8028 - mse: 46.8028 - val_loss: 49.0101 - val_mse: 49.0101\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 40.6719 - mse: 40.6719 - val_loss: 134.0343 - val_mse: 134.0343\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 41.4634 - mse: 41.4634 - val_loss: 86.0457 - val_mse: 86.0457\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 147.4394 - mse: 147.4394 - val_loss: 262.1285 - val_mse: 262.1285\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 85.7949 - mse: 85.7949 - val_loss: 42.4588 - val_mse: 42.4588\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 77.0430 - mse: 77.0430 - val_loss: 106.7255 - val_mse: 106.7255\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 99.6285 - mse: 99.6285 - val_loss: 37.0050 - val_mse: 37.0050\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 88.3472 - mse: 88.3472 - val_loss: 540.6941 - val_mse: 540.6941\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 51.8705 - mse: 51.8705 - val_loss: 219.3380 - val_mse: 219.3380\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 50.0969 - mse: 50.0969 - val_loss: 6.5140 - val_mse: 6.5140\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 26.6457 - mse: 26.6457 - val_loss: 4.8027 - val_mse: 4.8027\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 24.8353 - mse: 24.8353 - val_loss: 3.2442 - val_mse: 3.2442\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 32.6776 - mse: 32.6776 - val_loss: 19.2649 - val_mse: 19.2649\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 65.6662 - mse: 65.6662 - val_loss: 44.1687 - val_mse: 44.1687\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 55.7529 - mse: 55.7529 - val_loss: 120.4401 - val_mse: 120.4401\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 28.2952 - mse: 28.2952 - val_loss: 401.9294 - val_mse: 401.9294\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 31.1654 - mse: 31.1654 - val_loss: 51.4189 - val_mse: 51.4189\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 11.1773 - mse: 11.1773 - val_loss: 22.2917 - val_mse: 22.2917\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 39.6328 - mse: 39.6328 - val_loss: 130.4505 - val_mse: 130.4505\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 22.2200 - mse: 22.2200 - val_loss: 14.1984 - val_mse: 14.1984\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 47.7695 - mse: 47.7695 - val_loss: 458.5815 - val_mse: 458.5815\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 60.8667 - mse: 60.8667 - val_loss: 40.0730 - val_mse: 40.0730\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 9ms/step - loss: 1920.1907 - mse: 1920.1907 - val_loss: 992.6155 - val_mse: 992.6155\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 941.7903 - mse: 941.7903 - val_loss: 23830.7070 - val_mse: 23830.7070\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 762.7815 - mse: 762.7815 - val_loss: 361.2757 - val_mse: 361.2757\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 648.0084 - mse: 648.0084 - val_loss: 328.2380 - val_mse: 328.2380\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 479.3761 - mse: 479.3761 - val_loss: 541.0002 - val_mse: 541.0002\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 426.3110 - mse: 426.3110 - val_loss: 403.2915 - val_mse: 403.2915\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 164.9832 - mse: 164.9832 - val_loss: 484.7141 - val_mse: 484.7141\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 267.0254 - mse: 267.0254 - val_loss: 168.5740 - val_mse: 168.5740\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 277.3093 - mse: 277.3093 - val_loss: 181.5774 - val_mse: 181.5774\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 266.6615 - mse: 266.6615 - val_loss: 53.3610 - val_mse: 53.3610\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 144.5236 - mse: 144.5236 - val_loss: 95.9961 - val_mse: 95.9961\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 176.3976 - mse: 176.3976 - val_loss: 89.3062 - val_mse: 89.3062\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 128.4524 - mse: 128.4524 - val_loss: 174.8275 - val_mse: 174.8275\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 193.7267 - mse: 193.7267 - val_loss: 156.7634 - val_mse: 156.7634\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 111.7145 - mse: 111.7145 - val_loss: 84.5161 - val_mse: 84.5161\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 81.2909 - mse: 81.2909 - val_loss: 159.5730 - val_mse: 159.5730\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 116.2060 - mse: 116.2060 - val_loss: 60.8187 - val_mse: 60.8187\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 91.1083 - mse: 91.1083 - val_loss: 60.7917 - val_mse: 60.7917\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 77.1772 - mse: 77.1772 - val_loss: 62.0210 - val_mse: 62.0210\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 66.5539 - mse: 66.5539 - val_loss: 134.2244 - val_mse: 134.2244\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [           nan  -102.27504817            nan -3792.48761451\n",
            "  -374.33578088]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 1s 7ms/step - loss: 6864.0732 - mse: 6864.0732 - val_loss: 6763.3647 - val_mse: 6763.3647\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 6685.3662 - mse: 6685.3662 - val_loss: 6525.1279 - val_mse: 6525.1279\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 6440.2329 - mse: 6440.2329 - val_loss: 6273.2148 - val_mse: 6273.2148\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 6066.2642 - mse: 6066.2642 - val_loss: 5813.6772 - val_mse: 5813.6772\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 5479.2422 - mse: 5479.2422 - val_loss: 5300.0024 - val_mse: 5300.0024\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 4609.7505 - mse: 4609.7505 - val_loss: 4053.5332 - val_mse: 4053.5332\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3467.9153 - mse: 3467.9153 - val_loss: 2893.6240 - val_mse: 2893.6240\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 2237.3987 - mse: 2237.3987 - val_loss: 18319.5039 - val_mse: 18319.5039\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 1206.0641 - mse: 1206.0641 - val_loss: 797.5638 - val_mse: 797.5638\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 554.0469 - mse: 554.0469 - val_loss: 356.3234 - val_mse: 356.3234\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 236.1486 - mse: 236.1486 - val_loss: 188.1619 - val_mse: 188.1619\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 110.8705 - mse: 110.8705 - val_loss: 93.1888 - val_mse: 93.1888\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 68.8108 - mse: 68.8108 - val_loss: 64.1388 - val_mse: 64.1388\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 55.7534 - mse: 55.7534 - val_loss: 59.4249 - val_mse: 59.4249\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 52.7510 - mse: 52.7510 - val_loss: 56.3890 - val_mse: 56.3890\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 50.2838 - mse: 50.2838 - val_loss: 66.1935 - val_mse: 66.1935\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 52.0418 - mse: 52.0418 - val_loss: 60.0227 - val_mse: 60.0227\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 50.1606 - mse: 50.1606 - val_loss: 58.5026 - val_mse: 58.5026\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 49.5089 - mse: 49.5089 - val_loss: 56.0033 - val_mse: 56.0033\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 50.3618 - mse: 50.3618 - val_loss: 54.2910 - val_mse: 54.2910\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 49.4265 - mse: 49.4265 - val_loss: 56.2127 - val_mse: 56.2127\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 49.4907 - mse: 49.4907 - val_loss: 52.5978 - val_mse: 52.5978\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 48.9735 - mse: 48.9735 - val_loss: 55.4560 - val_mse: 55.4560\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 49.8059 - mse: 49.8059 - val_loss: 59.0363 - val_mse: 59.0363\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 49.9515 - mse: 49.9515 - val_loss: 58.2465 - val_mse: 58.2465\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 49.3544 - mse: 49.3544 - val_loss: 62.3726 - val_mse: 62.3726\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 49.3712 - mse: 49.3712 - val_loss: 57.9054 - val_mse: 57.9054\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 49.6996 - mse: 49.6996 - val_loss: 64.9554 - val_mse: 64.9554\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 49.8342 - mse: 49.8342 - val_loss: 54.8493 - val_mse: 54.8493\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 49.3921 - mse: 49.3921 - val_loss: 57.8494 - val_mse: 57.8494\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 49.2692 - mse: 49.2692 - val_loss: 55.9701 - val_mse: 55.9701\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 48.8136 - mse: 48.8136 - val_loss: 61.1124 - val_mse: 61.1124\n",
            "================================\n",
            "-- Best Model Summary --\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_165 (Dense)           (None, 363)               7260      \n",
            "                                                                 \n",
            " batch_normalization_70 (Bat  (None, 363)              1452      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_166 (Dense)           (None, 1)                 364       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,076\n",
            "Trainable params: 8,350\n",
            "Non-trainable params: 726\n",
            "_________________________________________________________________\n",
            "-- Best params --\n",
            "{'p_learning_rate': 4.921603361463973e-05, 'p_n_hidden': 1, 'p_n_neurons': 363}\n",
            "-- Best score --\n",
            "-102.2750481703024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graph_3(histories):\n",
        "    # Iterate over each history and plot metrics\n",
        "    for history in histories:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        # Plot loss\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history['loss'])\n",
        "        plt.plot(history['val_loss'])\n",
        "        plt.legend(['train loss', 'test loss'], loc='upper right')\n",
        "        plt.title('Loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "\n",
        "        # Plot accuracy (if available)\n",
        "        if 'mae' in history:\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.plot(history['mae'])\n",
        "            plt.plot(history['val_mae'])\n",
        "            plt.legend(['train mae', 'test mae'], loc='upper right')\n",
        "            plt.title('MAE')\n",
        "            plt.ylabel('MAE')\n",
        "            plt.xlabel('Epoch')\n",
        "\n",
        "\n",
        "        if 'accuracy' in history:\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.plot(history['accuracy'])\n",
        "            plt.plot(history['val_accuracy'])\n",
        "            plt.legend(['train accuracy', 'test accuracy'], loc='upper right')\n",
        "            plt.title('Accuracy')\n",
        "            plt.ylabel('Accuracy')\n",
        "            plt.xlabel('Epoch')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4qOqBpT3ICbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the best model with all available data\n",
        "best_model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "\n",
        "# Get the history of the best model\n",
        "best_model_history = best_model.history.history\n",
        "\n",
        "# Plot the metrics of the best model\n",
        "plot_graph_3([best_model_history])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "8VIuuJ7bOFgr",
        "outputId": "5e29d88c-3b06-45ca-9a4b-1255b84d7047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "40/40 [==============================] - 0s 4ms/step - loss: nan - mae: nan - accuracy: 0.0000e+00 - val_loss: nan - val_mae: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "40/40 [==============================] - 0s 3ms/step - loss: nan - mae: nan - accuracy: 0.0000e+00 - val_loss: nan - val_mae: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "40/40 [==============================] - 0s 3ms/step - loss: nan - mae: nan - accuracy: 0.0000e+00 - val_loss: nan - val_mae: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "40/40 [==============================] - 0s 3ms/step - loss: nan - mae: nan - accuracy: 0.0000e+00 - val_loss: nan - val_mae: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "40/40 [==============================] - 0s 3ms/step - loss: nan - mae: nan - accuracy: 0.0000e+00 - val_loss: nan - val_mae: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "40/40 [==============================] - 0s 3ms/step - loss: nan - mae: nan - accuracy: 0.0000e+00 - val_loss: nan - val_mae: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "40/40 [==============================] - 0s 3ms/step - loss: nan - mae: nan - accuracy: 0.0000e+00 - val_loss: nan - val_mae: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "40/40 [==============================] - 0s 4ms/step - loss: nan - mae: nan - accuracy: 0.0000e+00 - val_loss: nan - val_mae: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "40/40 [==============================] - 0s 4ms/step - loss: nan - mae: nan - accuracy: 0.0000e+00 - val_loss: nan - val_mae: nan - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan - mae: nan - accuracy: 0.0000e+00 - val_loss: nan - val_mae: nan - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(best_model_history)\n",
        "for key in (best_model_history):\n",
        "  print('[key]: ', key)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "titrxPmHEZlV",
        "outputId": "94864260-f306-4cd2-80d0-bea1492d9e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[key]:  loss\n",
            "[key]:  val_loss\n"
          ]
        }
      ]
    }
  ]
}