{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**420-A58-SF - Algorithmes d'apprentissage non supervisé - Hiver 2023 - Spécialisation technique en Intelligence Artificielle**<br/>\n",
    "MIT License - Copyright (c) 2023 Mikaël Swawola\n",
    "<br/>\n",
    "![Travaux Pratiques - Recherche de documents](static/02-02-A1-banner.png)\n",
    "<br/>\n",
    "**Objectif: Lors de l'exploration d'un jeu de données constitué de documents textes - tels que des pages Wikipedia, des articles de presse, StackOverflow, etc., il est courant de chercher à trouver quels sont les documents similaires. L'objectif de cet exercice est de mettre en oeuvre les techniques de recherche adaptées (ici les plus proches voisins) à ce type de données. Les documents utilisés sont les pages Wikipedia de personnalités.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Le reste des modules sera importé au fur et à mesure des exercices ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'archive `people.zip` contient 4 fichiers:\n",
    "\n",
    "* **people_wiki.csv**: jeu de données consituté des pages Wikipedia de personnalités\n",
    "* **people_wiki_map_index_to_word.json**: mapping entre les mots et les indices\n",
    "* **people_wiki_word_count.npz**: vecteurs d'occurence des mots (word count / sacs de mot) pour chaque document\n",
    "* **people_wiki_tf_idf.npz**: vecteurs TF-IDF pour chaque document\n",
    "\n",
    "Dans l'énoncé de ce TP, les mots \"article\" et \"document\" sont interchangeables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Chargement du jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 1-1 - À l'aide de la librairie Pandas, lire le fichier de données `people/people_wiki.csv`. Afin de permettre les opérations de type `join` effectuées plus loin dans le TP, nommez l'index de la trame de donnée `id`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 2 lignes de code\n",
    "wiki = pd.read_csv(\"../../../Data/people_wiki.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 1-2 - Afficher les 5 premières lignes de la trame de données. Quelles informations contiennent les colonnes ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Digby_Morrell&gt;</td>\n",
       "      <td>Digby Morrell</td>\n",
       "      <td>digby morrell born 10 october 1979 is a former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Alfred_J._Lewy&gt;</td>\n",
       "      <td>Alfred J. Lewy</td>\n",
       "      <td>alfred j lewy aka sandy lewy graduated from un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Harpdog_Brown&gt;</td>\n",
       "      <td>Harpdog Brown</td>\n",
       "      <td>harpdog brown is a singer and harmonica player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Franz_Rottensteiner&gt;</td>\n",
       "      <td>Franz Rottensteiner</td>\n",
       "      <td>franz rottensteiner born in waidmannsfeld lowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/G-Enka&gt;</td>\n",
       "      <td>G-Enka</td>\n",
       "      <td>henry krvits born 30 december 1974 in tallinn ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URI                 name  \\\n",
       "0        <http://dbpedia.org/resource/Digby_Morrell>        Digby Morrell   \n",
       "1       <http://dbpedia.org/resource/Alfred_J._Lewy>       Alfred J. Lewy   \n",
       "2        <http://dbpedia.org/resource/Harpdog_Brown>        Harpdog Brown   \n",
       "3  <http://dbpedia.org/resource/Franz_Rottensteiner>  Franz Rottensteiner   \n",
       "4               <http://dbpedia.org/resource/G-Enka>               G-Enka   \n",
       "\n",
       "                                                text  \n",
       "0  digby morrell born 10 october 1979 is a former...  \n",
       "1  alfred j lewy aka sandy lewy graduated from un...  \n",
       "2  harpdog brown is a singer and harmonica player...  \n",
       "3  franz rottensteiner born in waidmannsfeld lowe...  \n",
       "4  henry krvits born 30 december 1974 in tallinn ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compléter cette cellule ~ 1 ligne de code\n",
    "wiki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Extraction du nombre de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les vecteurs d'occurence des mots (**word count**) du jeu de données ont été préalablement extrait dans le fichier `people/people_wiki_word_count.npz`. Ces vecteurs sont regroupés dans une matrice diluée (sparse), où la i-ème ligne donne le vecteur d'occurence des mots pour le i-ème document. Chaque colonne correspond à un mot unique apparaissant dans le jeu de données. Le mapping entre les mots et les indices est donné dans `people/people_wiki_map_index_to_word.json`\n",
    "\n",
    "La fonction suivante permet le chargement des vecteurs d'occurence des mots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    data = loader['data']\n",
    "    indices = loader['indices']\n",
    "    indptr = loader['indptr']\n",
    "    shape = loader['shape']\n",
    "    \n",
    "    return csr_matrix( (data, indices, indptr), shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction ci-dessus utilise `csr_matrix` de la bibliothèque SciPy:<br/>\n",
    "[class scipy.sparse.csr_matrix(arg1, shape=None, dtype=None, copy=False)](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-1 - À l'aide de la fonction ci-dessus, charger le ficher contenant les vecteurs d'occurence des mots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 1 ligne de code\n",
    "matrix = load_sparse_csr(\"../../../Data/people_wiki_word_count.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-2 - En vous référant à la documentation de la fonction `csr_matrix`, convertissez la matrice `word_count` en tableau NumPy. Que constatez-vous ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 241. GiB for an array with shape (59071, 547979) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Compléter cette cellule ~ 1 ligne de code\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tableau \u001b[39m=\u001b[39m matrix\u001b[39m.\u001b[39;49mtoarray(order\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/scipy/sparse/_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m order \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1050\u001b[0m     order \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swap(\u001b[39m'\u001b[39m\u001b[39mcf\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 1051\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_toarray_args(order, out)\n\u001b[1;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mc_contiguous \u001b[39mor\u001b[39;00m out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mf_contiguous):\n\u001b[1;32m   1053\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mOutput array must be C or F contiguous\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/scipy/sparse/_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1296\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m   1297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1298\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mzeros(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 241. GiB for an array with shape (59071, 547979) and data type int64"
     ]
    }
   ],
   "source": [
    "# Compléter cette cellule ~ 1 ligne de code\n",
    "tableau = matrix.toarray(order='C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-3 - À l'aide du module json ou de la librairie Pandas, charger le ficher contenant le mapping entre les mots et les indices. Combien y a-t-il de mots dans le dictionnaire ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547979"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compléter cette cellule ~ 2-3 lignes de code\n",
    "mapJson = pd.read_json(\"../../../Data/people_wiki_map_index_to_word.json\", typ='series')\n",
    "len(mapJson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2-4 (optionnel) - Extraire par vous-même les vecteurs d'occurence des mots. Un bon point de départ est la fonction `sklearn.CountVectorizer`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "word_count = vectorizer.fit_transform(wiki['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Recherche des plus proches voisins avec représentation word count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par trouver les voisins les plus proches de la page Wikipedia de **Barack Obama**. Les vecteurs d'occurence des mots (**word count**) seront utilisés pour représenter les articles et la **distance euclidienne** pour mesurer la similarité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[class sklearn.neighbors.NearestNeighbors(*, n_neighbors=5, radius=1.0, algorithm='auto', leaf_size=30, metric='minkowski', p=2, metric_params=None, n_jobs=None)](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 3-1 - Quel est l'id correspondant à la page Wikipedia de barack Obama ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Ricardo_Mangue_Ob...</td>\n",
       "      <td>Ricardo Mangue Obama Nfubea</td>\n",
       "      <td>ricardo mangue obama nfubea born c 1961 is a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35817</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Barack_Obama&gt;</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>barack hussein obama ii brk husen bm born augu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     URI  \\\n",
       "2936   <http://dbpedia.org/resource/Ricardo_Mangue_Ob...   \n",
       "35817         <http://dbpedia.org/resource/Barack_Obama>   \n",
       "\n",
       "                              name  \\\n",
       "2936   Ricardo Mangue Obama Nfubea   \n",
       "35817                 Barack Obama   \n",
       "\n",
       "                                                    text  \n",
       "2936   ricardo mangue obama nfubea born c 1961 is a p...  \n",
       "35817  barack hussein obama ii brk husen bm born augu...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compléter cette cellule ~ 1 ligne de code\n",
    "wiki[wiki['name'].str.contains('obama', case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 3-2 - À l'aide de scikit-learn, rechercher les 10 pages Wikipedia de personnalités les plus similaires à la page de Barack Obama. Affichez les distances et noms de personalités dans une même trame de données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35817</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24478</th>\n",
       "      <td>33.015148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28447</th>\n",
       "      <td>34.307434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14754</th>\n",
       "      <td>35.791060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35357</th>\n",
       "      <td>36.069378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       distances\n",
       "id              \n",
       "35817   0.000000\n",
       "24478  33.015148\n",
       "28447  34.307434\n",
       "14754  35.791060\n",
       "35357  36.069378"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Gabarito\n",
    "model = NearestNeighbors().fit(word_count)\n",
    "model.kneighbors(word_count[35817], n_neighbors=10)\n",
    "distances, indices = model.kneighbors(word_count[35817], n_neighbors=10+1)\n",
    "neighbors = pd.DataFrame({'distances':distances.flatten(), 'id': indices.flatten()}).set_index('id')\n",
    "neighbors.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35817</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Barack_Obama&gt;</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>barack hussein obama ii brk husen bm born augu...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24478</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Joe_Biden&gt;</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>joseph robinette joe biden jr dosf rbnt badn b...</td>\n",
       "      <td>33.015148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28447</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/George_W._Bush&gt;</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>george walker bush born july 6 1946 is an amer...</td>\n",
       "      <td>34.307434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14754</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Mitt_Romney&gt;</td>\n",
       "      <td>Mitt Romney</td>\n",
       "      <td>willard mitt romney born march 12 1947 is an a...</td>\n",
       "      <td>35.791060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35357</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Lawrence_Summers&gt;</td>\n",
       "      <td>Lawrence Summers</td>\n",
       "      <td>lawrence henry larry summers born november 30 ...</td>\n",
       "      <td>36.069378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31423</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Walter_Mondale&gt;</td>\n",
       "      <td>Walter Mondale</td>\n",
       "      <td>walter frederick fritz mondale born january 5 ...</td>\n",
       "      <td>36.249138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Francisco_Barrio&gt;</td>\n",
       "      <td>Francisco Barrio</td>\n",
       "      <td>francisco javier barrio terrazas born november...</td>\n",
       "      <td>36.276714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36364</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Don_Bonker&gt;</td>\n",
       "      <td>Don Bonker</td>\n",
       "      <td>don leroy bonker born march 7 1937 in denver c...</td>\n",
       "      <td>36.400549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22745</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Wynn_Normington_H...</td>\n",
       "      <td>Wynn Normington Hugh-Jones</td>\n",
       "      <td>sir wynn normington hughjones kb sometimes kno...</td>\n",
       "      <td>36.441734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7660</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Refael_(Rafi)_Ben...</td>\n",
       "      <td>Refael (Rafi) Benvenisti</td>\n",
       "      <td>refael rafi benvenisti hebrew born in 1937 was...</td>\n",
       "      <td>36.837481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9210</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Andy_Anstett&gt;</td>\n",
       "      <td>Andy Anstett</td>\n",
       "      <td>andrue john andy anstett born june 25 1946 is ...</td>\n",
       "      <td>36.945906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     URI  \\\n",
       "id                                                         \n",
       "35817         <http://dbpedia.org/resource/Barack_Obama>   \n",
       "24478            <http://dbpedia.org/resource/Joe_Biden>   \n",
       "28447       <http://dbpedia.org/resource/George_W._Bush>   \n",
       "14754          <http://dbpedia.org/resource/Mitt_Romney>   \n",
       "35357     <http://dbpedia.org/resource/Lawrence_Summers>   \n",
       "31423       <http://dbpedia.org/resource/Walter_Mondale>   \n",
       "13229     <http://dbpedia.org/resource/Francisco_Barrio>   \n",
       "36364           <http://dbpedia.org/resource/Don_Bonker>   \n",
       "22745  <http://dbpedia.org/resource/Wynn_Normington_H...   \n",
       "7660   <http://dbpedia.org/resource/Refael_(Rafi)_Ben...   \n",
       "9210          <http://dbpedia.org/resource/Andy_Anstett>   \n",
       "\n",
       "                             name  \\\n",
       "id                                  \n",
       "35817                Barack Obama   \n",
       "24478                   Joe Biden   \n",
       "28447              George W. Bush   \n",
       "14754                 Mitt Romney   \n",
       "35357            Lawrence Summers   \n",
       "31423              Walter Mondale   \n",
       "13229            Francisco Barrio   \n",
       "36364                  Don Bonker   \n",
       "22745  Wynn Normington Hugh-Jones   \n",
       "7660     Refael (Rafi) Benvenisti   \n",
       "9210                 Andy Anstett   \n",
       "\n",
       "                                                    text  distances  \n",
       "id                                                                   \n",
       "35817  barack hussein obama ii brk husen bm born augu...   0.000000  \n",
       "24478  joseph robinette joe biden jr dosf rbnt badn b...  33.015148  \n",
       "28447  george walker bush born july 6 1946 is an amer...  34.307434  \n",
       "14754  willard mitt romney born march 12 1947 is an a...  35.791060  \n",
       "35357  lawrence henry larry summers born november 30 ...  36.069378  \n",
       "31423  walter frederick fritz mondale born january 5 ...  36.249138  \n",
       "13229  francisco javier barrio terrazas born november...  36.276714  \n",
       "36364  don leroy bonker born march 7 1937 in denver c...  36.400549  \n",
       "22745  sir wynn normington hughjones kb sometimes kno...  36.441734  \n",
       "7660   refael rafi benvenisti hebrew born in 1937 was...  36.837481  \n",
       "9210   andrue john andy anstett born june 25 1946 is ...  36.945906  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wiki.head()\n",
    "print(wiki.index.name)\n",
    "wiki.index.name='id'\n",
    "wiki.join(neighbors, on='id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 26.0 GiB for an array with shape (3489324583,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m tfidf_matrix \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mfit_transform(df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[39m# Compute pairwise distances between all rows\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m dist_matrix \u001b[39m=\u001b[39m pairwise_distances(tfidf_matrix, metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcosine\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Convert the distance matrix into a pandas DataFrame\u001b[39;00m\n\u001b[1;32m     14\u001b[0m dist_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(dist_matrix, columns\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mindex, index\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:2022\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2019\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[1;32m   2020\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 2022\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1563\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1560\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1562\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1563\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1565\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:984\u001b[0m, in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39m\"\"\"Compute cosine distance between samples in X and Y.\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \n\u001b[1;32m    960\u001b[0m \u001b[39mCosine distance is defined as 1.0 minus the cosine similarity.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[39mscipy.spatial.distance.cosine : Dense matrices only.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[39m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[0;32m--> 984\u001b[0m S \u001b[39m=\u001b[39m cosine_similarity(X, Y)\n\u001b[1;32m    985\u001b[0m S \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    986\u001b[0m S \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1385\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1383\u001b[0m     Y_normalized \u001b[39m=\u001b[39m normalize(Y, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1385\u001b[0m K \u001b[39m=\u001b[39m safe_sparse_dot(X_normalized, Y_normalized\u001b[39m.\u001b[39;49mT, dense_output\u001b[39m=\u001b[39;49mdense_output)\n\u001b[1;32m   1387\u001b[0m \u001b[39mreturn\u001b[39;00m K\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/extmath.py:152\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m         ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(a, b)\n\u001b[1;32m    151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39;49m b\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    155\u001b[0m     sparse\u001b[39m.\u001b[39missparse(a)\n\u001b[1;32m    156\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[1;32m    157\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[1;32m    158\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m ):\n\u001b[1;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/scipy/sparse/_base.py:630\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    628\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mScalar operands are not allowed, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    629\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39muse \u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 630\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mul_dispatch(other)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/scipy/sparse/_base.py:541\u001b[0m, in \u001b[0;36mspmatrix._mul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m other\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    540\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mdimension mismatch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 541\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mul_sparse_matrix(other)\n\u001b[1;32m    543\u001b[0m \u001b[39m# If it's a list or whatever, treat it like a matrix\u001b[39;00m\n\u001b[1;32m    544\u001b[0m other_a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(other)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/scipy/sparse/_compressed.py:529\u001b[0m, in \u001b[0;36m_cs_matrix._mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    524\u001b[0m idx_dtype \u001b[39m=\u001b[39m get_index_dtype((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindptr, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices,\n\u001b[1;32m    525\u001b[0m                              other\u001b[39m.\u001b[39mindptr, other\u001b[39m.\u001b[39mindices),\n\u001b[1;32m    526\u001b[0m                             maxval\u001b[39m=\u001b[39mnnz)\n\u001b[1;32m    528\u001b[0m indptr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(major_axis \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[0;32m--> 529\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(nnz, dtype\u001b[39m=\u001b[39;49midx_dtype)\n\u001b[1;32m    530\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(nnz, dtype\u001b[39m=\u001b[39mupcast(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype, other\u001b[39m.\u001b[39mdtype))\n\u001b[1;32m    532\u001b[0m fn \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(_sparsetools, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_matmat\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 26.0 GiB for an array with shape (3489324583,) and data type int64"
     ]
    }
   ],
   "source": [
    "# Compléter cette cellule ~ 5-6 lignes de code\n",
    "\n",
    "df = wiki\n",
    "# Create a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform the text data into a matrix of TF-IDF features\n",
    "tfidf_matrix = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Compute pairwise distances between all rows\n",
    "dist_matrix = pairwise_distances(tfidf_matrix, metric='cosine')\n",
    "\n",
    "# Convert the distance matrix into a pandas DataFrame\n",
    "dist_df = pd.DataFrame(dist_matrix, columns=df.index, index=df.index)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(dist_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 3-3 - Interprétez les résultats ci-dessus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 3-4 - Affichez les mots les plus fréquents des pages de Barack Obama et Francisco Barrio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de pouvoir reconnaître rapidement les mots d'une grande importance, la fonction suivante permettant d'obtenir la colonne `word_count` est fournie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_dict(matrix, map_index_to_word):\n",
    "    table = sorted(map_index_to_word, key=map_index_to_word.get)\n",
    "   \n",
    "    data = matrix.data\n",
    "    indices = matrix.indices\n",
    "    indptr = matrix.indptr\n",
    "    \n",
    "    num_doc = matrix.shape[0]\n",
    "\n",
    "    return [{k:v for k,v in zip([table[word_id] for word_id in indices[indptr[i]:indptr[i+1]] ],\n",
    "                                 data[indptr[i]:indptr[i+1]].tolist())} for i in range(num_doc) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'map_index_to_word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Compléter cette cellule ~ 2 lignes de code\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m wiki[\u001b[39m'\u001b[39m\u001b[39mword_count\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m unpack \u001b[39m=\u001b[39m unpack_dict(word_count, map_index_to_word)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'map_index_to_word' is not defined"
     ]
    }
   ],
   "source": [
    "# Compléter cette cellule ~ 2 lignes de code\n",
    "wiki['word_count'] = unpack = unpack_dict(word_count, map_index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Francisco_Barrio&gt;</td>\n",
       "      <td>Francisco Barrio</td>\n",
       "      <td>francisco javier barrio terrazas born november...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35817</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Barack_Obama&gt;</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>barack hussein obama ii brk husen bm born augu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URI              name  \\\n",
       "id                                                                        \n",
       "13229  <http://dbpedia.org/resource/Francisco_Barrio>  Francisco Barrio   \n",
       "35817      <http://dbpedia.org/resource/Barack_Obama>      Barack Obama   \n",
       "\n",
       "                                                    text  \n",
       "id                                                        \n",
       "13229  francisco javier barrio terrazas born november...  \n",
       "35817  barack hussein obama ii brk husen bm born augu...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = wiki[wiki['name'].str.contains('Barack Obama') | wiki['name'].str.contains('Francisco Barrio')]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for row 13229:\n",
      "chihuahua    7\n",
      "governor     6\n",
      "state        4\n",
      "action       3\n",
      "first        3\n",
      "former       3\n",
      "national     3\n",
      "party        3\n",
      "years        3\n",
      "barrio       2\n",
      "dtype: int64\n",
      "Top 10 words for row 35817:\n",
      "obama         9\n",
      "act           8\n",
      "law           6\n",
      "us            6\n",
      "control       4\n",
      "democratic    4\n",
      "iraq          4\n",
      "military      4\n",
      "president     4\n",
      "2004          3\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.local/lib/python3.11/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/hadoop/.local/lib/python3.11/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Create a sample dataframe with a 'text' column\n",
    "#df = pd.DataFrame({'text': ['this is a sample text', 'this is another sample text', 'yet another text']})\n",
    "#df = wiki['text']\n",
    "\n",
    "# Create a CountVectorizer object with English stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Transform the 'text' column into a matrix of word counts\n",
    "word_counts = vectorizer.fit_transform(df2['text'])\n",
    "\n",
    "# Iterate over the rows\n",
    "for index, row in df2.iterrows():\n",
    "    # Transform the row into a matrix of word counts\n",
    "    word_counts = vectorizer.fit_transform([row['text']])\n",
    "    \n",
    "    # Get the vocabulary of words\n",
    "    vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "    # Sum the word counts across the row\n",
    "    word_count_totals = word_counts.sum(axis=0)\n",
    "\n",
    "    # Convert the word count totals to a pandas Series\n",
    "    word_count_series = pd.Series(word_count_totals.A1, index=vocabulary)\n",
    "\n",
    "    # Get the top 10 most frequent words\n",
    "    top_10_words = word_count_series.nlargest(10)\n",
    "\n",
    "    # Print the top 10 words for the row\n",
    "    print(f\"Top 10 words for row {index}:\")\n",
    "    print(top_10_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 3-5 - Créer une fonction `top_words`, permattant d'afficher les mots les plus fréquents d'une page donnée**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter cette cellule ~ 10 lignes de code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Recherche des plus proches voisins avec représentation TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 4 - Répétez les étapes des exercices de la partie 3 en utilisant cette fois-ci la représentation TF-IDF. Comparez avec les résultats obtenu par la représentation word count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.local/lib/python3.11/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "also          67731\n",
      "university    59644\n",
      "born          54633\n",
      "first         50279\n",
      "new           49604\n",
      "one           35127\n",
      "music         29888\n",
      "national      29758\n",
      "american      28804\n",
      "years         28802\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Compléter cette cellule ~ 14-20 lignes de code\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a sample dataframe with a 'text' column\n",
    "#df = pd.DataFrame({'text': ['this is a sample text', 'this is another sample text', 'yet another text']})\n",
    "df = wiki\n",
    "\n",
    "# Create a CountVectorizer object with English stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Fit the vectorizer on the 'text' column\n",
    "tfidf_matrix = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Get the feature names (i.e., the vocabulary of words)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Sum the tf-idf scores across each document (i.e., row)\n",
    "sum_scores = tfidf_matrix.sum(axis=0)\n",
    "\n",
    "# Convert the sums to a pandas Series\n",
    "sum_scores_series = pd.Series(sum_scores.A1, index=feature_names)\n",
    "\n",
    "# Get the top 10 most frequent words\n",
    "top_10_words = sum_scores_series.nlargest(10)\n",
    "\n",
    "# Print the top 10 words\n",
    "print(top_10_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fin de l'atelier 02-02-A1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
