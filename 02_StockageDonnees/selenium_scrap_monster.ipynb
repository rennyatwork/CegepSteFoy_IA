{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/hadoop/.local/lib/python3.8/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/hadoop/.local/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=6f5d99046f83e13a4ee39d56937388571abe8b854f5cd7b40a76024f21f5d0f0\n",
      "  Stored in directory: /home/hadoop/.cache/pip/wheels/75/78/21/68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install selenium\n",
    "#!{sys.executable} -m pip install beautifulsoup4\n",
    "#!{sys.executable} -m pip install Scrapy\n",
    "#!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install bs4\n",
    "# selenium va permettre d'ouvrir un navigateur et d'ouvrir le site qui va dynamiquement générer du htlm à partir du javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\1992572\\\\Desktop\\\\enseignement\\\\BD2-UBR4120-Bloc1-Hiver2021\\\\cours7\\\\monsterjson'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"C:/Users/1992572/Desktop/enseignement/BD2-UBR4120-Bloc1-Hiver2021/cours7/monsterjson/\")\n",
    "os. getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-7919b2ebafe4>:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Firefox(executable_path=DRIVER_PATH)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# download chrome correct package and put it in a specific folder on your harddrive https://www.scrapingbee.com/blog/selenium-python/\n",
    "DRIVER_PATH = '/usr/local/Downloads/WebDrivers/geckodriver'\n",
    "driver = webdriver.Firefox(executable_path=DRIVER_PATH)\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.monster.com/jobs/search?q=Data+Analyst&where=toronto%2C+on')\n",
    "#driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"window.scrollTo(100, document.body.scrollHeight -100);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2fb1d4d9e314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(results)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"results-list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mjob_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"title-company-location\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "#Après inspection de la page\n",
    "#results = soup.find(name = \"job-results-list\")\n",
    "#print(results)\n",
    "results = soup.find('div', class_ = \"results-list\")\n",
    "job_html = results.find_all('div', class_ = \"title-company-location\")\n",
    "\n",
    "rows = []\n",
    "for job_elem in results:\n",
    "    title_elem = job_elem.find(\"h2\", title =True)\n",
    "    company_elem = job_elem.find(\"h3\",attrs={\"name\":\"card_companyname\"})\n",
    "    location_elem = job_elem.find(class_ = \"meta-info-sm\",attrs={\"name\":\"card_location\"})\n",
    "    link_elem = job_elem.find(\"a\", href=True)\n",
    "    if None in (title_elem, company_elem, location_elem):\n",
    "        continue\n",
    "    #chaque ligne\n",
    "    row = [title_elem.text.strip(),\n",
    "    company_elem.text.strip(),\n",
    "    location_elem.text.strip(),       \n",
    "    \"https://www.monster.com\" + link_elem['href'].strip()]\n",
    "\n",
    "    #append dans ma liste\n",
    "    rows.append(row)\n",
    " \n",
    "print(head(rows),3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Titre  \\\n",
      "0                      Data Analyst (Microsoft BI)   \n",
      "1                                     Data Analyst   \n",
      "2                     Derivatives Business Analyst   \n",
      "3                                 Business Analyst   \n",
      "4                  Data Analyst - Asset Management   \n",
      "5   2 Business Analysts (Data - Diversity) (73043)   \n",
      "6                                  Data Specialist   \n",
      "7       Guidewire Business Analyst - Policy Center   \n",
      "8                    Intermediate Business Analyst   \n",
      "9                                 Business Analyst   \n",
      "10                                    Data Analyst   \n",
      "11                     Salesforce Business Analyst   \n",
      "12                             Senior Data Analyst   \n",
      "13           Intermediate/Senior Business Analysts   \n",
      "14                      Sr. Business Analyst - P&C   \n",
      "15                             Sr Business Analyst   \n",
      "16         Jr. Business Operations Support Analyst   \n",
      "17                        Business Analyst - Murex   \n",
      "18                 Business Analyst - Dynamics 365   \n",
      "19         IT Project Coordinator/Business Analyst   \n",
      "\n",
      "                                            Compagnie            Lieu  \\\n",
      "0                                              Procom  North York, ON   \n",
      "1                                            Randstad     Toronto, ON   \n",
      "2                                    The Select Group     Toronto, ON   \n",
      "3   CGI Information Systems and Management Consult...     Toronto, ON   \n",
      "4                                              Procom     Toronto, ON   \n",
      "5                    Eagle Professional Resources Inc     Toronto, ON   \n",
      "6                                      ISG Search Inc     Toronto, ON   \n",
      "7                             People Force Consulting     Toronto, ON   \n",
      "8                                  Comtech Group Inc.     Toronto, ON   \n",
      "9                                  The Delivery Group     Toronto, ON   \n",
      "10                                           Randstad     Toronto, ON   \n",
      "11                                   The Select Group     Toronto, ON   \n",
      "12                                             Procom     Toronto, ON   \n",
      "13                   Eagle Professional Resources Inc     Toronto, ON   \n",
      "14                            People Force Consulting     Toronto, ON   \n",
      "15  CGI Information Systems and Management Consult...     Toronto, ON   \n",
      "16                                             Procom     Toronto, ON   \n",
      "17                                      Mindlance Inc     Toronto, ON   \n",
      "18                                               Hays     Toronto, ON   \n",
      "19                                           Randstad     Toronto, ON   \n",
      "\n",
      "                                                 Lien date de la recherche  \n",
      "0   https://www.monster.com/job-openings/data-anal...           2021-07-06  \n",
      "1   https://www.monster.com/job-openings/data-anal...           2021-07-06  \n",
      "2   https://www.monster.com/job-openings/derivativ...           2021-07-06  \n",
      "3   https://www.monster.com/job-openings/business-...           2021-07-06  \n",
      "4   https://www.monster.com/job-openings/data-anal...           2021-07-06  \n",
      "5   https://www.monster.com/job-openings/2-busines...           2021-07-06  \n",
      "6   https://www.monster.com/job-openings/data-spec...           2021-07-06  \n",
      "7   https://www.monster.com/job-openings/guidewire...           2021-07-06  \n",
      "8   https://www.monster.com/job-openings/intermedi...           2021-07-06  \n",
      "9   https://www.monster.com/job-openings/business-...           2021-07-06  \n",
      "10  https://www.monster.com/job-openings/data-anal...           2021-07-06  \n",
      "11  https://www.monster.com/job-openings/salesforc...           2021-07-06  \n",
      "12  https://www.monster.com/job-openings/senior-da...           2021-07-06  \n",
      "13  https://www.monster.com/job-openings/intermedi...           2021-07-06  \n",
      "14  https://www.monster.com/job-openings/sr-busine...           2021-07-06  \n",
      "15  https://www.monster.com/job-openings/sr-busine...           2021-07-06  \n",
      "16  https://www.monster.com/job-openings/jr-busine...           2021-07-06  \n",
      "17  https://www.monster.com/job-openings/business-...           2021-07-06  \n",
      "18  https://www.monster.com/job-openings/business-...           2021-07-06  \n",
      "19  https://www.monster.com/job-openings/it-projec...           2021-07-06  \n"
     ]
    }
   ],
   "source": [
    "#Création des entetes et insertion dans mon dataframe, ajout des colonnes\n",
    "from datetime import date #ajoutdechamp\n",
    "columns = ['Titre','Compagnie','Lieu','Lien']\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "# df['offre'] = CONST_URL #ajoutdechamp\n",
    "df['date de la recherche'] = date.today() #ajoutdechamp\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarde en json\n",
    "jsonFile = df.to_json (orient='records')\n",
    "with open('scrapping_.json', 'w', encoding='UTF-8') as outfile:\n",
    "             json.dump(json.loads(jsonFile), outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Push des données dans MongoDB\n",
    "\n",
    "import pymongo\n",
    "import json\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"Monster1\"]\n",
    "mycol = mydb[\"import1\"]\n",
    "\n",
    "\n",
    "with open('scrapping_.json') as file: \n",
    "    file_data = json.load(file) \n",
    "\n",
    "if isinstance(file_data, list): \n",
    "    mycol.insert_many(file_data)   \n",
    "else: \n",
    "    mycol.insert_one(file_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
