{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sts\n",
    "import statsmodels.api as stm\n",
    "import statsmodels.stats.weightstats as ws\n",
    "import sklearn.linear_model as sk_lin_mod\n",
    "import math\n",
    "import seaborn as sns\n",
    "import os\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "from sklearn.feature_selection import RFE\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from scipy import stats\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import PyQt5 #works\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets #works for pyqt5\n",
    "%matplotlib qt\n",
    "\n",
    "## feature selection\n",
    "### https://www.youtube.com/watch?v=VCVhwjbI6h8\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()\n",
    "# print (os.getcwd())\n",
    "currDir = os.getcwd()\n",
    "fullPath = currDir + \"/CabaneASucrev0r3.csv\"\n",
    "type(currDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read csv\n",
    "donnee = pd.read_csv(fullPath)\n",
    "stats=donnee.describe()\n",
    "dimensions=donnee.shape\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\-----------------\\\n",
    "\n",
    "Pré traitement\n",
    "\n",
    "\\------------------\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnee.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heureusement, très peu de nulls.\n",
    "\n",
    "Quels sont les enregistrements contenant des nulls?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnee[(donnee['Temp max.(°C)'].isna()==True) | (donnee['Précip. tot. (mm)'].isna()==True)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnee.fillna(method='bfill', inplace=True)\n",
    "donnee.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les question 1 et 2, à fin de faciliter le traitement du detaframe:\n",
    "Supprimer les colonnes pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### obtenir colonne sans pixel\n",
    "donnee.filter(like='Pixel').columns\n",
    "dfSansPixel = donnee.drop(donnee.filter(like='Pixel').columns, axis=1)\n",
    "\n",
    "## enlever aussi Classe Sirop (utiliser dans la question 3)\n",
    "dfSansPixel = dfSansPixel.drop(dfSansPixel.filter(like='Classe Sirop').columns, axis=1)\n",
    "\n",
    "dfSansPixel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSansPixel.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSansPixel.describe().apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## obtenir un detaframe numérique\n",
    "dfNumerique = dfSansPixel.select_dtypes(exclude='object').copy()\n",
    "dfNumerique.describe().apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### !!! utiliser dans la question3\n",
    "### convertir Classe Sirop en var numérique et la raoujter au dfNumerique\n",
    "###\n",
    "# Creating numeric columns\n",
    "###\n",
    "#colsCategSirop = pd.get_dummies(dfSansPixel['Classe Sirop'], prefix='categSirop_', drop_first=True)\n",
    "\n",
    "## concatenate side by side\n",
    "#dfNumerique = pd.concat([dfNumerique, colsCategSirop], axis=1)\n",
    "#dfNumeriue.columns\n",
    "\n",
    "## Y-at-il des enregistrements ou toutes les variables catégoriques sont 0? \n",
    "## Il ne devraient pas en avoir\n",
    "\n",
    "#dfNumerique[ (dfNumerique['categSirop__Très Foncé']==0) \n",
    "#& (dfNumerique['categSirop__Foncé']==0)\n",
    "#& (dfNumerique['categSirop__Doré']==0)\n",
    "#& (dfNumerique['categSirop__Ambré']==0)\n",
    "#].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### enelever les données où débit nul de sève\n",
    "#dfNumerique = dfNumerique.loc[dfNumerique['Pression osmoseur (bar)'] !=0]\n",
    "dfNumerique = dfNumerique.loc[dfNumerique['Débit sève (L/j)'] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fonction pour obtenir un subset d'un dataset contenant seulement les variables indépendantes (x)\n",
    "def get_x_vars(pDf, pVarY):\n",
    "    return pDf.drop([pVarY], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### retourne un dictionnaire dont key=var dépendante (y) et valeur = dataframe de var x (indépenantes)\n",
    "def get_dict_y_x(pDf, pListY):\n",
    "    dict_y_x = {}\n",
    "    for key in pListY:        \n",
    "        dict_y_x.update({key: get_x_vars(pDf, key)})\n",
    "    return dict_y_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### liste de variables (colonnes) dépendantes\n",
    "list_cols_dependennt_vars = []\n",
    "col_debit_seve = dfSansPixel['Débit sève (L/j)'].name\n",
    "col_sucre_dans_seve = dfSansPixel['Sucre sève (%)'].name\n",
    "col_pct_transmittance = dfSansPixel['Transmittance produit (%)'].name\n",
    "col_productivite_seve_par_saison = dfSansPixel['Production moyenne par entaille (L)'].name\n",
    "list_cols_dependennt_vars = [col_debit_seve, col_sucre_dans_seve, col_pct_transmittance, col_productivite_seve_par_saison]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dictionnaire contenant les variables dépendantes (y) comme clé et les indépendantes comme df\n",
    "dict_y_x = get_dict_y_x(dfNumerique, list_cols_dependennt_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_y_x['Débit sève (L/j)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurewiz import featurewiz\n",
    "\n",
    "dict_y_x_featurewiz = {}\n",
    "for key in dict_y_x:\n",
    "    print(\"------------------\")\n",
    "    print(\"[key]: \", key)\n",
    "    \n",
    "    features = featurewiz(dfNumerique, target=key, corr_limit=0.70, \n",
    "                                verbose=0) ## verbose = 2 -> generates graph    \n",
    "    dict_y_x_featurewiz.update({key: features[1]}) ## features[1] = dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## book Practical Statiscs for Data Scientists, cahp 2\n",
    "## https://github.com/gedeck/practical-statistics-for-data-scientists/blob/master/python/notebooks/Chapter%202%20-%20Data%20and%20sampling%20distributions.ipynb\n",
    "def plot_prob_var_y(pDf):\n",
    "    for y in list_cols_dependennt_vars:\n",
    "        col_y = pDf[y][pDf[y]>0]\n",
    "        print(\"y\", y)\n",
    "        #print(\"col[y]\", dfNumerique[y][dfNumerique[y]>0])\n",
    "        np.diff(np.log(col_y))\n",
    "    \n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        ax.set_title( y)\n",
    "        sts.probplot(col_y, plot=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_prob_var_y(dfNumerique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNumerique.describe().apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardization\n",
    "## https://datagy.io/pandas-normalize-column/\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(dfNumerique)\n",
    "#scaled = scaler.fit_transform(dfNumerique)\n",
    "#dfNumeriqueStd = pd.DataFrame(scaled, columns=dfNumerique.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfNumeriqueStd.describe().apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box_plot_vars_y(pDf):\n",
    "    for y in list_cols_dependennt_vars:\n",
    "        col_y = pDf[y][pDf[y]>0]\n",
    "        print(\"y\", y)\n",
    "    \n",
    "        plt.figure()\n",
    "        sns.boxplot(y=col_y).set_title(y)\n",
    "        plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_box_plot_vars_y(dfNumerique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "\n",
    "\n",
    "https://www.geeksforgeeks.org/ml-multiple-linear-regression-using-python/\n",
    "\n",
    "Assumption of Regression Model : \n",
    "\n",
    "- Linearity: The relationship between dependent and independent variables should be linear.\n",
    "- Homoscedasticity: Constant variance of the errors should be maintained.\n",
    "- Multivariate normality: Multiple Regression assumes that the residuals are normally distributed.\n",
    "- Lack of Multicollinearity: It is assumed that there is little or no multicollinearity in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier = (dfNumerique['Osmoseur (heures opération/j)'].mean() +1.5*dfNumerique['Osmoseur (heures opération/j)'].std())\n",
    "#print(outlier)\n",
    "#dfNumerique['Osmoseur (heures opération/j)'][dfNumerique['Osmoseur (heures opération/j)']]>outlier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfNumerique = dfNumerique.loc[dfNumerique['Osmoseur (heures opération/j)']<outlier]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dfNumerique.corr()\n",
    "\n",
    "#sorted_pairs = corr.unstack().sort_values(kind=\"quicksort\", ascending=False).dropna(inplace=True)\n",
    "#corr.unstack().sort_values(kind=\"quicksort\", ascending=False).dropna(inplace=True)\n",
    "x = corr.unstack().sort_values(kind=\"quicksort\", ascending=False).apply(lambda  x: str(x).split())\n",
    "type(x)\n",
    "## reset column names\n",
    "x = pd.DataFrame(x).reset_index()\n",
    "x.columns = ['col1', 'col2', 'corr']\n",
    "## transform corr from [1] to 1\n",
    "x['corr'] = x['corr'].apply(lambda x: float(np.squeeze(x)))\n",
    "\n",
    "## paires de colonnes avec des corrélation élevées (> 0.6)\n",
    "x[(x['corr']>0.6) & (x['col1']!=x['col2'])].sort_values('col1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(corr, cbar=True, center=0, annot=True, fmt=\"0.2f\", cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation des variables dépendantes (Y) et indépendantes (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seulement les variables X\n",
    "dfNumerique_X_cols = dfNumerique.loc[:, ~dfNumerique.columns.isin(list_cols_dependennt_vars)].copy()\n",
    "\n",
    "lstColTemp = ['Temp max.(°C)', 'Temp min.(°C)']\n",
    "dfNumerique_X_cols = dfNumerique_X_cols.loc[:,~dfNumerique_X_cols.columns.isin(lstColTemp) ].copy()\n",
    "\n",
    "## seulement les variables Y\n",
    "dfNumerique_Y_cols = dfNumerique.loc[:, dfNumerique.columns.isin(list_cols_dependennt_vars)].copy()\n",
    "\n",
    "len(dfNumerique.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Après coup, on a appris que ces 2 variables causaient un prob de haute colinéarité.\n",
    "#### et si on les enlève plus tôt?\n",
    "\n",
    "lstColsExlude = ['Précip. Tot. Hiver (mm)', 'Temp moy.(°C)']\n",
    "dfNumerique_X_cols = dfNumerique_X_cols.loc[:, ~dfNumerique_X_cols.columns.isin([col for col in lstColsExlude])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============== Evaluating model ===========\n",
    "\n",
    "https://www.youtube.com/watch?v=VCVhwjbI6h8\n",
    "\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fonction qui imprime le sommaire du modèle\n",
    "def print_model_summary(pDfColsX, pDfColsY):\n",
    "    ## Add constant\n",
    "    pDfColsX = stm.add_constant(pDfColsX)\n",
    "    lst_models = []\n",
    "    for y in (pDfColsY.columns.values):\n",
    "    \n",
    "        col_y = dfNumerique_Y_cols[y]\n",
    "    \n",
    "        model = stm.OLS(col_y, pDfColsX.assign(const=1)).fit()\n",
    "        print(\"=========\")\n",
    "        print(\"var depend: \", y)\n",
    "    \n",
    "        #lst_models.append(model)\n",
    "        print(model.summary())\n",
    "        #sns.distplot(model.resid, fit=sts.norm)        \n",
    "        #p = sns.histplot(model.resid, kde=True, stat=\"density\").set(title = y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---- Sommaire dfNumerique ----\")\n",
    "print_model_summary(dfNumerique_X_cols, dfNumerique_Y_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model(pColsY, pDfDependentVars):\n",
    "    for y in (pColsY.columns.values):    \n",
    "        col_y = pColsY[y]\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(pDfDependentVars, col_y, test_size=0.25, random_state=0)\n",
    "\n",
    "\n",
    "        ## transforming data    \n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "\n",
    "        ## Fitting Multiple Linear Regression to the training set\n",
    "        regressor =  LinearRegression()\n",
    "        regressor.fit(X_train, y_train)\n",
    "        \n",
    "\n",
    "        y_pred = regressor.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        #r_sq = regressor.score(X_test, y_test)\n",
    "\n",
    "        ##adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "        ## Where n is the sample size and p is the number of independent variables.\n",
    "\n",
    "        #print (\"len(X_test): \", len(X_test))\n",
    "        #print (\"len(y_test): \", len(y_test))\n",
    "    \n",
    "        ### ajd_r2\n",
    "        ## https://stackoverflow.com/questions/51038820/how-to-calculated-the-adjusted-r2-value-using-scikit\n",
    "        ## https://www.dummies.com/article/business-careers-money/business/accounting/calculation-analysis/how-to-calculate-the-adjusted-coefficient-of-determination-146054/\n",
    "        #print (\"n: \", n)\n",
    "        #print (\"p: \", p)\n",
    "        #print (\"adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\")\n",
    "\n",
    "        n = len(X_test)\n",
    "        p = len(pDfDependentVars.columns)\n",
    "        adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    \n",
    "        print(\"--------\")\n",
    "        \n",
    "        print(\"[col_y]: \", col_y.name)\n",
    "        print(\"[mse]: \", mse)\n",
    "        print(\"[rmse]: \", rmse)\n",
    "        #print(\"[r2] - A value of 1 indicates that the response variable can be perfectly explained by the predictor variables.\")\n",
    "        print(\"[r2]: \", r2)\n",
    "        print(\"[adj_r2]: \", adj_r2)\n",
    "        print(\"[coef]: \", regressor.coef_)\n",
    "        print(\"[intercept_]: \", regressor.intercept_)\n",
    "        #print(\"[r_sq]: \", r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_model(dfNumerique_Y_cols, dfNumerique_X_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\---\n",
    "\n",
    "Sans rien faire, on a un modèle très précis (r2 et adj_r2 élevés).\n",
    "Mais pourrait-on avoir un bon résultat avec moins de colonnes?\n",
    "\n",
    "\\---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = LinearRegression()\n",
    "#dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://github.com/simaria22/prediction_heart_failure/blob/master/feature_select.py\n",
    "## Ajoute des colonnes au modèle pendant que la nouvelle colonne améliore\n",
    "## le modèle OU\n",
    "## jusqu'à qu'un certain niveau de précision soit atteint\n",
    "def get_reduced_df_X(pDfx, pY, pAccuracy=0.7):\n",
    "    print(\"------\")\n",
    "    print(\"dependent var y: \", pY.name)\n",
    "    \n",
    "    # new X df with fewer columns than pDfx\n",
    "    reducedDf = []\n",
    "\n",
    "    # column names to keep\n",
    "    dfKeeper = None\n",
    "\n",
    "    #no of features\n",
    "    nof_list=np.arange(1,len(pDfx.columns))            \n",
    "    high_score=0\n",
    "    #Variable to store the optimum features\n",
    "    nof=0           \n",
    "    score_list =[]\n",
    "    for n in range(len(nof_list)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(pDfx, pY, test_size = 0.3, random_state = 0)\n",
    "        model = LinearRegression()\n",
    "        rfe = RFE(model,n_features_to_select= nof_list[n])\n",
    "        X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "        X_test_rfe = rfe.transform(X_test)\n",
    "        model.fit(X_train_rfe,y_train)\n",
    "        score = model.score(X_test_rfe,y_test)\n",
    "        score_list.append(score)\n",
    "        \n",
    "        print(\"n: \", n)\n",
    "        print(\"score: \", score)\n",
    "        print(\"high_score: \", high_score)\n",
    "\n",
    "        # print summaries for the selection of attributes\n",
    "        print(\"rfe.support_: \",rfe.support_)\n",
    "        print(\"rfe.ranking_: \" ,rfe.ranking_)\n",
    "        \n",
    "        #dfKeeper = pd.DataFrame(rfe.support_,index=pDfx.columns,columns=['Rank'])\n",
    "        data= {'colName': pDfx.columns, 'keep': rfe.support_ }\n",
    "        dfKeeper = pd.DataFrame(data)\n",
    "        dfKeeper = dfKeeper[dfKeeper[\"keep\"]==True]\n",
    "        if(score>high_score):\n",
    "            high_score = score\n",
    "            nof = nof_list[n]\n",
    "        if (score > pAccuracy):\n",
    "            break\n",
    "\n",
    "    \n",
    "    print(\"Optimum number of features: %d\" %nof)\n",
    "    print(\"Score with %d features: %f\" % (nof, high_score))\n",
    "    print(\"df columns to keep: \")\n",
    "    #print(\"shape\")\n",
    "    #print(dfNumerique_X_cols[dfKeeper[\"colName\"]].shape)\n",
    "    print(dfKeeper)\n",
    "    \n",
    "    reducedDf = dfNumerique_X_cols[dfKeeper[\"colName\"]]\n",
    "    \n",
    "    #print(\"reducedDf: \", reducedDf.head())\n",
    "    #print(\"unique: \", reducedDf[dfKeeper[\"colName\"]].unique())\n",
    "    return reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### création d'un dictionnaire contenant la variable dépendantes et ses variables indépendantes\n",
    "### correspondantes\n",
    "### clé = colonne dépendante, valeur = dataframe des colonnes avec haute influence\n",
    "dict_y_colsX = {}\n",
    "\n",
    "for y in (dfNumerique_Y_cols.columns.values):    \n",
    "    col_y = dfNumerique_Y_cols[y]\n",
    "    reducedDf = get_reduced_df_X(dfNumerique_X_cols, col_y)\n",
    "    #print(\"reduceDf.columns.values: \",  reducedDf.columns.values)\n",
    "    #print(\"unique values: \", reducedDf[reducedDf.columns.values[0]].unique())\n",
    "    #print(\"len: \", len(reducedDf[reducedDf.columns.values[0]]))\n",
    "    #print(\"Nan: \", reducedDf[reducedDf.columns.values[0]].isnull().sum())\n",
    "    ## call to analyze_model\n",
    "    #analyze_model(dfNumerique_Y_cols, reducedDf)\n",
    "    #analyze_model(col_y.to_frame(), reducedDf)\n",
    "    dict_y_colsX.update({col_y.name: reducedDf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### analyse le modèle de nouveau avec un dataframe réduit\n",
    "#analyze_model(dfNumerique_Y_cols, dfNumerique_X_cols)\n",
    "for key in (dict_y_colsX.keys()):\n",
    "    print(\"key: \", key)\n",
    "    dfX = dict_y_colsX.get(key)\n",
    "    dfY = dfNumerique_Y_cols[key]\n",
    "    #print(type(dfX))\n",
    "    #print(type(dfY))\n",
    "    #dfX =pd.DataFrame(dict_y_colsX[key], columns=[key])\n",
    "    #print(\"shape: \", dfX.shape)\n",
    "    #print(\"nulls: \", dfX.isnull().sum())\n",
    "    analyze_model(dfY.to_frame(), dfX)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:  Production moyenne par entaille (L)\n",
      "=========\n",
      "var depend:  Production moyenne par entaille (L)\n",
      "                                     OLS Regression Results                                    \n",
      "===============================================================================================\n",
      "Dep. Variable:     Production moyenne par entaille (L)   R-squared:                       0.910\n",
      "Model:                                             OLS   Adj. R-squared:                  0.909\n",
      "Method:                                  Least Squares   F-statistic:                 1.602e+04\n",
      "Date:                                 Sat, 10 Dec 2022   Prob (F-statistic):               0.00\n",
      "Time:                                         19:44:03   Log-Likelihood:                -4029.1\n",
      "No. Observations:                                 1595   AIC:                             8062.\n",
      "Df Residuals:                                     1593   BIC:                             8073.\n",
      "Df Model:                                            1                                         \n",
      "Covariance Type:                             nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                       -11.8088      0.316    -37.395      0.000     -12.428     -11.189\n",
      "Nombre épisodes gel/dégel     1.8654      0.015    126.564      0.000       1.836       1.894\n",
      "==============================================================================\n",
      "Omnibus:                       34.465   Durbin-Watson:                   0.025\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               20.460\n",
      "Skew:                          -0.110   Prob(JB):                     3.61e-05\n",
      "Kurtosis:                       2.490   Cond. No.                         89.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "key:  Débit sève (L/j)\n",
      "=========\n",
      "var depend:  Débit sève (L/j)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       Débit sève (L/j)   R-squared:                       0.943\n",
      "Model:                            OLS   Adj. R-squared:                  0.943\n",
      "Method:                 Least Squares   F-statistic:                 2.623e+04\n",
      "Date:                Sat, 10 Dec 2022   Prob (F-statistic):               0.00\n",
      "Time:                        19:44:03   Log-Likelihood:                -13360.\n",
      "No. Observations:                1595   AIC:                         2.672e+04\n",
      "Df Residuals:                    1593   BIC:                         2.673e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                -3188.2215     46.670    -68.314      0.000   -3279.762   -3096.681\n",
      "Temps bouilloire (h)  2628.9377     16.232    161.961      0.000    2597.099    2660.776\n",
      "==============================================================================\n",
      "Omnibus:                      278.374   Durbin-Watson:                   1.681\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1396.289\n",
      "Skew:                           0.726   Prob(JB):                    6.30e-304\n",
      "Kurtosis:                       7.347   Cond. No.                         5.53\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "key:  Sucre sève (%)\n",
      "=========\n",
      "var depend:  Sucre sève (%)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         Sucre sève (%)   R-squared:                       0.925\n",
      "Model:                            OLS   Adj. R-squared:                  0.925\n",
      "Method:                 Least Squares   F-statistic:                     9764.\n",
      "Date:                Sat, 10 Dec 2022   Prob (F-statistic):               0.00\n",
      "Time:                        19:44:03   Log-Likelihood:                 1192.9\n",
      "No. Observations:                1595   AIC:                            -2380.\n",
      "Df Residuals:                    1592   BIC:                            -2364.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.4896      0.012    123.622      0.000       1.466       1.513\n",
      "Précip. tot. (mm)            -0.0508      0.000   -104.089      0.000      -0.052      -0.050\n",
      "Nombre épisodes gel/dégel     0.0517      0.001     92.563      0.000       0.051       0.053\n",
      "==============================================================================\n",
      "Omnibus:                       15.107   Durbin-Watson:                   1.148\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               10.823\n",
      "Skew:                           0.079   Prob(JB):                      0.00447\n",
      "Kurtosis:                       2.629   Cond. No.                         90.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "key:  Transmittance produit (%)\n",
      "=========\n",
      "var depend:  Transmittance produit (%)\n",
      "                                OLS Regression Results                               \n",
      "=====================================================================================\n",
      "Dep. Variable:     Transmittance produit (%)   R-squared:                       0.332\n",
      "Model:                                   OLS   Adj. R-squared:                  0.327\n",
      "Method:                        Least Squares   F-statistic:                     71.47\n",
      "Date:                       Sat, 10 Dec 2022   Prob (F-statistic):          3.77e-130\n",
      "Time:                               19:44:03   Log-Likelihood:                -5864.8\n",
      "No. Observations:                       1595   AIC:                         1.175e+04\n",
      "Df Residuals:                           1583   BIC:                         1.182e+04\n",
      "Df Model:                                 11                                         \n",
      "Covariance Type:                   nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "const                            -2.6436      1.477     -1.790      0.074      -5.540       0.253\n",
      "Jour Calendrier Saison           -0.1689      0.011    -15.621      0.000      -0.190      -0.148\n",
      "Diff Temp (°C)                   -0.1428      0.060     -2.374      0.018      -0.261      -0.025\n",
      "Précip. tot. (mm)                -0.1064      0.045     -2.365      0.018      -0.195      -0.018\n",
      "Nombre épisodes gel/dégel         0.2360      0.054      4.408      0.000       0.131       0.341\n",
      "Alimentation osmoseur (L/j)      -0.1952      0.187     -1.042      0.298      -0.563       0.172\n",
      "Osmoseur (heures opération/j)    90.9866     83.236      1.093      0.275     -72.279     254.252\n",
      "Pression osmoseur (bar)         -42.2951     23.629     -1.790      0.074     -88.642       4.052\n",
      "Sucre sortie osmoseur (%)        42.2987     23.627      1.790      0.074      -4.046      88.643\n",
      "Température Bouilloire (0C)      15.6984      8.350      1.880      0.060      -0.679      32.076\n",
      "Temps bouilloire (h)             -2.1145      0.707     -2.989      0.003      -3.502      -0.727\n",
      "Sucre du sirop obtenu (%)        -3.3751      1.678     -2.012      0.044      -6.666      -0.084\n",
      "Quantité de sirop obtenue (L)    -0.1017      0.013     -7.942      0.000      -0.127      -0.077\n",
      "==============================================================================\n",
      "Omnibus:                       17.971   Durbin-Watson:                   2.059\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               27.514\n",
      "Skew:                           0.076   Prob(JB):                     1.06e-06\n",
      "Kurtosis:                       3.625   Cond. No.                     1.99e+18\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.97e-27. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "### analyse le modèle de nouveau avec un dataframe réduit\n",
    "#analyze_model(dfNumerique_Y_cols, dfNumerique_X_cols)\n",
    "for key in (dict_y_colsX.keys()):\n",
    "    print(\"key: \", key)\n",
    "    dfX = dict_y_colsX.get(key)\n",
    "    dfY = dfNumerique_Y_cols[key]    \n",
    "    print_model_summary(dfX, dfY.to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "À ce point, on a un modèle avec une bonne précision (R-squared et Adj R-squared) pour \n",
    "toutes les variables dépendantes.\n",
    "\n",
    "Pour la variable Débit sève (L/j), le MSE est très élevé, possiblement il y a des outliers.\n",
    "\n",
    "Seuelement la variable 'Transmittance produit (%)' contient un advertissement de colinéarité\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### outliers\n",
    "### book: Practical statistcs for data scientists, pg 178\n",
    "## https://github.com/gedeck/practical-statistics-for-data-scientists\n",
    "dict_outliers = {}\n",
    "for key in (dict_y_colsX.keys()):\n",
    "    print(\"--------------------------\")\n",
    "    print(\"key: \", key)\n",
    "    dfX = dict_y_colsX.get(key)\n",
    "    dfY = dfNumerique_Y_cols[key]    \n",
    "    outlier = stm.OLS(dfY, dfX.assign(const=1))\n",
    "    result = outlier.fit()\n",
    "    influence = OLSInfluence(result)\n",
    "    sresiduals = influence.resid_studentized_internal\n",
    "    sresiduals.idxmin(), sresiduals.min()\n",
    "    outlier = dfNumerique.loc[sresiduals.idxmin(), :]\n",
    "    print(\"[outler[key]: \", outlier[key])\n",
    "    print(\"[outlier values]: \", outlier[dfX.columns.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pairplots\n",
    "#analyze_model(dfNumerique_Y_cols, dfNumerique_X_cols)\n",
    "i=0\n",
    "for key in (dict_y_colsX.keys()):\n",
    "    i+=1\n",
    "    print(\"key: \", key)\n",
    "    dfX = dict_y_colsX.get(key)\n",
    "    dfY = dfNumerique_Y_cols[key]    \n",
    "    #sns.pairplot(pd.concat([dfX, dfY], axis=0))\n",
    "    #plt.figure(i)\n",
    "    #print(dfX.columns.values)\n",
    "    #print(dfNumerique[key].head())\n",
    "    #plt.figure()\n",
    "    #plt.plot(pd.concat([dfX, dfY], axis=0))\n",
    "    #####sns.pairplot(data = dfNumerique, x_vars = dfX.columns.values , y_vars = [key], kind='reg', diag_kind=None)\n",
    "    \n",
    "    #sns.pairplot(data = reducedDf, x_vars = ['Nombre épisodes gel/dégel'], y_vars = ['Production moyenne par entaille (L)'], kind='reg', diag_kind='kde')\n",
    "    #plt.show(block=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot regressions\n",
    "#https://seaborn.pydata.org/tutorial/regression.html\n",
    "i=0\n",
    "for key in (dict_y_colsX.keys()):\n",
    "    \n",
    "    print(\"key: \", key)\n",
    "    dfX = dict_y_colsX.get(key)\n",
    "    dfY = dfNumerique_Y_cols[key]    \n",
    "    for col_x in dfX.columns.values:\n",
    "        i+=1\n",
    "        plt.figure(i)\n",
    "        print(\"col_x: \", col_x)\n",
    "        sns.regplot(data = dfNumerique, x = col_x, y = key)    \n",
    "        plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for key in (dict_y_colsX.keys()):\n",
    "    \n",
    "    print(\"key: \", key)\n",
    "    dfX = dict_y_colsX.get(key)\n",
    "    dfY = dfNumerique_Y_cols[key]    \n",
    "    for col_x in dfX.columns.values:\n",
    "        i+=1\n",
    "        plt.figure(i)\n",
    "        print(\"col_x: \", col_x)\n",
    "        #sns.boxplot(x=dfX[col_x])  \n",
    "        #sns.histplot(data=dfX, bins=10, x=col_x)\n",
    "        plt.show(block=False)\n",
    "\n",
    "#i=0    \n",
    "#for col_x in dfX.columns:\n",
    "#    i+=1\n",
    "#    plt.figure(i)\n",
    "    #print(\"col_x: \", col_x)\n",
    "    #print(type(col_x))\n",
    " #   sns.boxplot(x=col_x.to_frame())    \n",
    " #   plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### boxplot vars y\n",
    "#https://seaborn.pydata.org/tutorial/regression.html\n",
    "i=0\n",
    "for key in (dict_y_colsX.keys()):    \n",
    "    print(\"key: \", key)\n",
    "    dfX = dict_y_colsX.get(key)\n",
    "    dfY = dfNumerique_Y_cols[key]    \n",
    "    i+=1\n",
    "    plt.figure(i)    \n",
    "    #sns.histplot(data=dfY, bins=10)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "la var dépendante Transmittance produit (%) a un problème de multicolinearité \n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### END Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Vif - régler la colinéarité de la variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "### vif\n",
    "## https://www.kdnuggets.com/2019/07/check-quality-regression-model-python.html\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://www.geeksforgeeks.org/detecting-multicollinearity-with-vif-python/\n",
    "\n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = dfNumerique_X_cols.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pression osmoseur (bar)</td>\n",
       "      <td>1.576727e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alimentation osmoseur (L/j)</td>\n",
       "      <td>2.038589e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Osmoseur (heures opération/j)</td>\n",
       "      <td>2.038341e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sucre sortie osmoseur (%)</td>\n",
       "      <td>6.737523e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Température Bouilloire (0C)</td>\n",
       "      <td>5.057191e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sucre du sirop obtenu (%)</td>\n",
       "      <td>5.050148e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Quantité de sirop obtenue (L)</td>\n",
       "      <td>5.045686e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Temps bouilloire (h)</td>\n",
       "      <td>2.287041e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diff Temp (°C)</td>\n",
       "      <td>1.421709e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nombre épisodes gel/dégel</td>\n",
       "      <td>1.339062e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Précip. tot. (mm)</td>\n",
       "      <td>1.221094e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jour Calendrier Saison</td>\n",
       "      <td>1.162881e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Année</td>\n",
       "      <td>1.063115e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature           VIF\n",
       "7         Pression osmoseur (bar)  1.576727e+07\n",
       "5     Alimentation osmoseur (L/j)  2.038589e+06\n",
       "6   Osmoseur (heures opération/j)  2.038341e+06\n",
       "8       Sucre sortie osmoseur (%)  6.737523e+05\n",
       "9     Température Bouilloire (0C)  5.057191e+01\n",
       "11      Sucre du sirop obtenu (%)  5.050148e+01\n",
       "12  Quantité de sirop obtenue (L)  5.045686e+01\n",
       "10           Temps bouilloire (h)  2.287041e+01\n",
       "2                  Diff Temp (°C)  1.421709e+00\n",
       "4       Nombre épisodes gel/dégel  1.339062e+00\n",
       "3               Précip. tot. (mm)  1.221094e+00\n",
       "1          Jour Calendrier Saison  1.162881e+00\n",
       "0                           Année  1.063115e+00"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# calculating VIF for each feature\n",
    "\n",
    "vif_data[\"VIF\"] = [vif(dfNumerique_X_cols.values, i)\n",
    "                          for i in range(len(dfNumerique_X_cols.columns))]\n",
    "\n",
    "vif_data.sort_values(by=\"VIF\", axis=0, kind=\"quicksort\",  ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVifPlusGrand10 = vif_data[vif_data[\"VIF\"] >10]\n",
    "len(dfVifPlusGrand10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Année', 'Jour Calendrier Saison', 'Diff Temp (°C)',\n",
       "       'Précip. tot. (mm)', 'Nombre épisodes gel/dégel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### dfNumerique_X sans les vif >10\n",
    "dfNumerique_X_cols_vif =[]\n",
    "dfNumerique_X_cols_vif = dfNumerique_X_cols.loc[:, ~dfNumerique_X_cols.columns.isin(dfVifPlusGrand10[\"feature\"].values)].copy()\n",
    "#for x in (dfVifPlusGrand10[\"feature\"].values):\n",
    "#    print(\"col: \", x)\n",
    "dfNumerique_X_cols_vif.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dfNumerique_X_cols_vif.corr(), cbar=True, cmap=\"Blues\", center=0, annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\-------------------\\\n",
    "Est-ce que l'on obtien un résultat meilleur pour \n",
    "'Transmittance produit (%)' ?\\\n",
    "\\----------------\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "dependent var y:  Transmittance produit (%)\n",
      "n:  0\n",
      "score:  0.13777658691468575\n",
      "high_score:  0\n",
      "rfe.support_:  [False  True False False False]\n",
      "rfe.ranking_:  [4 1 5 3 2]\n",
      "n:  1\n",
      "score:  0.14154574972858958\n",
      "high_score:  0.13777658691468575\n",
      "rfe.support_:  [False  True False False  True]\n",
      "rfe.ranking_:  [3 1 4 2 1]\n",
      "n:  2\n",
      "score:  0.13904060899094783\n",
      "high_score:  0.14154574972858958\n",
      "rfe.support_:  [False  True False  True  True]\n",
      "rfe.ranking_:  [2 1 3 1 1]\n",
      "n:  3\n",
      "score:  0.13692715856210302\n",
      "high_score:  0.14154574972858958\n",
      "rfe.support_:  [ True  True False  True  True]\n",
      "rfe.ranking_:  [1 1 2 1 1]\n",
      "Optimum number of features: 2\n",
      "Score with 2 features: 0.141546\n",
      "df columns to keep: \n",
      "                     colName  keep\n",
      "0                      Année  True\n",
      "1     Jour Calendrier Saison  True\n",
      "3          Précip. tot. (mm)  True\n",
      "4  Nombre épisodes gel/dégel  True\n",
      "=========\n",
      "var depend:  Transmittance produit (%)\n",
      "                                OLS Regression Results                               \n",
      "=====================================================================================\n",
      "Dep. Variable:     Transmittance produit (%)   R-squared:                       0.116\n",
      "Model:                                   OLS   Adj. R-squared:                  0.114\n",
      "Method:                        Least Squares   F-statistic:                     52.02\n",
      "Date:                       Sat, 10 Dec 2022   Prob (F-statistic):           3.20e-41\n",
      "Time:                               19:47:00   Log-Likelihood:                -6088.3\n",
      "No. Observations:                       1595   AIC:                         1.219e+04\n",
      "Df Residuals:                           1590   BIC:                         1.221e+04\n",
      "Df Model:                                  4                                         \n",
      "Covariance Type:                   nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        36.4163     93.745      0.388      0.698    -147.461     220.294\n",
      "Année                         0.0066      0.047      0.142      0.887      -0.085       0.098\n",
      "Jour Calendrier Saison       -0.1640      0.012    -14.178      0.000      -0.187      -0.141\n",
      "Précip. tot. (mm)            -0.0013      0.047     -0.028      0.978      -0.094       0.091\n",
      "Nombre épisodes gel/dégel     0.1023      0.054      1.892      0.059      -0.004       0.208\n",
      "==============================================================================\n",
      "Omnibus:                        0.346   Durbin-Watson:                   2.128\n",
      "Prob(Omnibus):                  0.841   Jarque-Bera (JB):                0.259\n",
      "Skew:                          -0.000   Prob(JB):                        0.878\n",
      "Kurtosis:                       3.062   Cond. No.                     6.83e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.83e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "### appelle get_reduced_df_X avec \n",
    "### X =  dfNumerique_X_cols_vif et Y = dfNumerique_Y_cols['Transmittance produit (%)']\n",
    "newDfTransmittance = get_reduced_df_X(dfNumerique_X_cols_vif, dfNumerique_Y_cols['Transmittance produit (%)'])\n",
    "print_model_summary(newDfTransmittance, dfNumerique_Y_cols['Transmittance produit (%)'].to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_model( dfNumerique_Y_cols['Transmittance produit (%)'].to_frame(), newDfTransmittance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Le résultat n'est pas meilleur\n",
    "## éliminons 'Précip. Tot. Hiver (mm)' et Temp moy.(°C) à cause de leur haute correlation\n",
    "## ('Précip. Tot. Hiver (mm)', 'Année') = 0.78 et ('Temp moy.(°C)', 'Calendrier saison') = 0.73\n",
    "\n",
    "\n",
    "### appelle get_reduced_df_X avec \n",
    "### X =  dfNumerique_X_cols_vif et Y = dfNumerique_Y_cols['Transmittance produit (%)']\n",
    "#dfDependantVars= dfNumerique.loc[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])]\n",
    "lstColsExlude = ['Précip. Tot. Hiver (mm)', 'Temp moy.(°C)']\n",
    "dfNumerique_X_cols_vif = dfNumerique_X_cols_vif.loc[:, ~dfNumerique_X_cols_vif.columns.isin([col for col in lstColsExlude])]\n",
    "newDfTransmittance = get_reduced_df_X(dfNumerique_X_cols_vif, dfNumerique_Y_cols['Transmittance produit (%)'])\n",
    "print_model_summary(newDfTransmittance, dfNumerique_Y_cols['Transmittance produit (%)'].to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "###  Malheureusement, le problème de multicolinéarité reste\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Réponses aux questions 1\n",
    "### Les tableaux ci-bas donnent, entre autres les informations concernant le adj. r-squared\n",
    "###, t-value, p-value\n",
    "### et coefficients des modèles.\n",
    "### !!!NOTE!!! générer les graphiques et le sauvegarder à part!!!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=========\n",
    "var depend:  Production moyenne par entaille (L)\n",
    "                                     OLS Regression Results                                    \n",
    "===============================================================================================\n",
    "Dep. Variable:     Production moyenne par entaille (L)   R-squared:                       0.906\n",
    "Model:                                             OLS   Adj. R-squared:                  0.906\n",
    "Method:                                  Least Squares   F-statistic:                 1.387e+04\n",
    "Date:                                 Sat, 03 Dec 2022   Prob (F-statistic):               0.00\n",
    "Time:                                         14:24:24   Log-Likelihood:                -3644.4\n",
    "No. Observations:                                 1443   AIC:                             7293.\n",
    "Df Residuals:                                     1441   BIC:                             7303.\n",
    "Df Model:                                            1                                         \n",
    "Covariance Type:                             nonrobust                                         \n",
    "=============================================================================================\n",
    "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
    "---------------------------------------------------------------------------------------------\n",
    "const                       -11.9279      0.333    -35.775      0.000     -12.582     -11.274\n",
    "Nombre épisodes gel/dégel     1.8686      0.016    117.770      0.000       1.837       1.900\n",
    "==============================================================================\n",
    "Omnibus:                       24.538   Durbin-Watson:                   0.028\n",
    "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               15.002\n",
    "Skew:                          -0.079   Prob(JB):                     0.000553\n",
    "Kurtosis:                       2.526   Cond. No.                         88.1\n",
    "==============================================================================\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "key:  Débit sève (L/j)\n",
    "=========\n",
    "var depend:  Débit sève (L/j)\n",
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:       Débit sève (L/j)   R-squared:                       0.912\n",
    "Model:                            OLS   Adj. R-squared:                  0.912\n",
    "Method:                 Least Squares   F-statistic:                 1.501e+04\n",
    "Date:                Sat, 03 Dec 2022   Prob (F-statistic):               0.00\n",
    "Time:                        14:24:24   Log-Likelihood:                -11687.\n",
    "No. Observations:                1443   AIC:                         2.338e+04\n",
    "Df Residuals:                    1441   BIC:                         2.339e+04\n",
    "Df Model:                           1                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "========================================================================================\n",
    "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
    "----------------------------------------------------------------------------------------\n",
    "const                -4463.5239     56.280    -79.309      0.000   -4573.923   -4353.124\n",
    "Temps bouilloire (h)  3320.4604     27.107    122.497      0.000    3267.288    3373.633\n",
    "==============================================================================\n",
    "Omnibus:                      378.287   Durbin-Watson:                   1.825\n",
    "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1267.473\n",
    "Skew:                           1.273   Prob(JB):                    5.91e-276\n",
    "Kurtosis:                       6.820   Cond. No.                         6.71\n",
    "==============================================================================\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "key:  Sucre sève (%)\n",
    "=========\n",
    "var depend:  Sucre sève (%)\n",
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:         Sucre sève (%)   R-squared:                       0.924\n",
    "Model:                            OLS   Adj. R-squared:                  0.923\n",
    "Method:                 Least Squares   F-statistic:                     8698.\n",
    "Date:                Sat, 03 Dec 2022   Prob (F-statistic):               0.00\n",
    "Time:                        14:24:24   Log-Likelihood:                 1073.8\n",
    "No. Observations:                1443   AIC:                            -2142.\n",
    "Df Residuals:                    1440   BIC:                            -2126.\n",
    "Df Model:                           2                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "=============================================================================================\n",
    "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
    "---------------------------------------------------------------------------------------------\n",
    "const                         1.4861      0.013    116.608      0.000       1.461       1.511\n",
    "Précip. tot. (mm)            -0.0510      0.001   -101.776      0.000      -0.052      -0.050\n",
    "Nombre épisodes gel/dégel     0.0519      0.001     85.938      0.000       0.051       0.053\n",
    "==============================================================================\n",
    "Omnibus:                       16.642   Durbin-Watson:                   1.152\n",
    "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               11.406\n",
    "Skew:                           0.082   Prob(JB):                      0.00334\n",
    "Kurtosis:                       2.596   Cond. No.                         89.6\n",
    "==============================================================================\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "\n",
    "var depend:  Transmittance produit (%)\n",
    "                                OLS Regression Results                               \n",
    "=====================================================================================\n",
    "Dep. Variable:     Transmittance produit (%)   R-squared:                       0.671\n",
    "Model:                                   OLS   Adj. R-squared:                  0.670\n",
    "Method:                        Least Squares   F-statistic:                     585.2\n",
    "Date:                       Sat, 03 Dec 2022   Prob (F-statistic):               0.00\n",
    "Time:                               14:10:03   Log-Likelihood:                -4813.6\n",
    "No. Observations:                       1443   AIC:                             9639.\n",
    "Df Residuals:                           1437   BIC:                             9671.\n",
    "Df Model:                                  5                                         \n",
    "Covariance Type:                   nonrobust                                         \n",
    "=============================================================================================\n",
    "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
    "---------------------------------------------------------------------------------------------\n",
    "const                        69.6794      1.111     62.718      0.000      67.500      71.859\n",
    "Jour Calendrier Saison       -0.0572      0.008     -7.236      0.000      -0.073      -0.042\n",
    "Diff Temp (°C)               -0.0372      0.043     -0.871      0.384      -0.121       0.047\n",
    "Précip. tot. (mm)             0.0028      0.031      0.090      0.928      -0.058       0.063\n",
    "Nombre épisodes gel/dégel     0.0522      0.036      1.442      0.150      -0.019       0.123\n",
    "CategClasseSirop             -9.5708      0.194    -49.436      0.000      -9.951      -9.191\n",
    "==============================================================================\n",
    "Omnibus:                       83.787   Durbin-Watson:                   2.120\n",
    "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              138.994\n",
    "Skew:                           0.450   Prob(JB):                     6.57e-31\n",
    "Kurtosis:                       4.225   Cond. No.                         362.\n",
    "==============================================================================\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ou, si on prend seulement les coefficients de chaque var dépendante:\n",
    "\n",
    "\n",
    "\\========================================================\\\n",
    "\n",
    "var depend:  Production moyenne par entaille (L)\n",
    "\n",
    "                                coef\n",
    "------------------------------------\n",
    "const                       -11.9279\n",
    "Nombre épisodes gel/dégel     1.8686\n",
    "\n",
    "\n",
    "\n",
    "\\==========================================================\\\n",
    "\n",
    "var depend:  Débit sève (L/j)\n",
    "\n",
    "                           coef    \n",
    "-----------------------------------\n",
    "const                -4463.5239    \n",
    "Temps bouilloire (h)  3320.4604    \n",
    "\n",
    "\\==========================================================\\\n",
    "\n",
    "\n",
    "var depend:  Sucre sève (%)\n",
    "\n",
    "                                coef    \n",
    "----------------------------------------\n",
    "const                         1.4861    \n",
    "Précip. tot. (mm)            -0.0510    \n",
    "Nombre épisodes gel/dégel     0.0519    \n",
    "\n",
    "\n",
    "\\========================================================\\\n",
    "\n",
    "var depend:  Transmittance produit (%)\n",
    "\n",
    "                                coef    \n",
    "----------------------------------------\n",
    "const                        69.6794      \n",
    "Jour Calendrier Saison       -0.0572      \n",
    "Diff Temp (°C)               -0.0372      \n",
    "Précip. tot. (mm)             0.0028      \n",
    "Nombre épisodes gel/dégel     0.0522      \n",
    "CategClasseSirop             -9.5708\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\---------------\n",
    "\n",
    "Q2)\n",
    "Hypothesis testing\n",
    "\n",
    "\\------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\--------------\\\n",
    "\n",
    "Vars:\n",
    "'Transmittance produit (%)'\n",
    "'Sucre sève (%)'\n",
    "\n",
    "\n",
    "Y-at-il une variance significative entre les années 2014-2016?\n",
    "\n",
    "\n",
    "Obtenir la moyenne pour les année 2014 à 2016 e comparer les résultats\n",
    "\n",
    "\n",
    "\n",
    "\\---------------\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### obtenir moyenne d'une colonne\n",
    "def getMeanListExclusions(pColName, pData=dfNumerique, pListeExclusion=[2014, 2015, 2016]):\n",
    "    return pData[pColName][~pData['Année'].isin(pListeExclusion)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moyenne_transmit_toutes_annees = dfNumerique['Transmittance produit (%)'].mean()\n",
    "moyenne_transmit_toutes_annees = getMeanListExclusions('Transmittance produit (%)')\n",
    "moyenne_sucre_toutes_annees = getMeanListExclusions('Sucre sève (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moyenne_transmit_toutes_annees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moyenne_sucre_toutes_annees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\----------------\\\n",
    "\n",
    "Quelles sont les moyennes pour les années de 2014 à 2016?\n",
    "\n",
    "\\----------------\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### obtenir moyenne d'une colonne\n",
    "def getMeanListInclusions(pColName, pAnnee, pData=dfNumerique ):\n",
    "    return pData[pColName][pData['Année'] == pAnnee].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for these dictionnaries, key = year [2014-2016]\n",
    "lstAnnees = [2014, 2015, 2016]\n",
    "dictAnneeTransmittance = {}\n",
    "dictAnneeSucre = {}\n",
    "for annee in lstAnnees:    \n",
    "    dictAnneeTransmittance.update({annee: getMeanListInclusions('Transmittance produit (%)', annee)})\n",
    "    dictAnneeSucre.update({annee: getMeanListInclusions('Sucre sève (%)', annee)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictAnneeTransmittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictAnneeSucre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imnprime la différence entre la moyenne historique (excluant 2014-2016) versus [2014-2016]\n",
    "def compare_means(pMean1, pMean2, pAnnee, pCol):\n",
    "    diff = pMean1 - pMean2\n",
    "    print(\"-----\")\n",
    "    print(\"Différence entre moyennes pour \", pCol)\n",
    "    print(\"moyenne historique: \", pMean1)\n",
    "    print(\"moyenne \", pAnnee)\n",
    "    print(\"Différence absolue: \", abs(diff))\n",
    "    print(\"Différence %: \", abs(100*(diff/pMean1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transmittance\n",
    "for key in dictAnneeTransmittance.keys():\n",
    "    compare_means(moyenne_transmit_toutes_annees, dictAnneeTransmittance.get(key), key, 'Transmittance produit (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transmittance\n",
    "for key in dictAnneeSucre.keys():\n",
    "    compare_means(moyenne_sucre_toutes_annees, dictAnneeSucre.get(key), key, 'Sucre sève (%)')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\-------------------\\\n",
    "-- ref:Hands-On Exploratory Data Analysis with Python, pg 242\n",
    "-- Practical Statiscs for Data Science, pg 95\n",
    "\n",
    "Q2.1: Tests d'hypothèse\n",
    "\n",
    "[Transmittance produit (%)]\n",
    "population: dfNumerique\n",
    "\n",
    "Hypothèse null: moyenne historique = moyenne [2014-2016]\n",
    "Hypothèse alternative: moyenne historique != moyenne [2014-2016]\n",
    "\n",
    "Sucre sève (%)\n",
    "\n",
    "\\-------------------\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://towardsdatascience.com/demystifying-hypothesis-testing-with-simple-python-examples-4997ad3c5294\n",
    "def print_analyse_hypothese(pColYName, pMoyenneHistoriqueY, pDict, pDf=dfNumerique, pConf=0.05):\n",
    "    ## Transmittance produit (%)\n",
    "    n =len(pDf)\n",
    "    pnull = pMoyenneHistoriqueY ##0.43732148760330574 #moyenne hystorique\n",
    "    ### Transmittance\n",
    "    print(\"==================================\")\n",
    "    print(\"var [pColYName]: \", pColYName)\n",
    "    for key in pDict.keys():\n",
    "        phat = pDict.get(key) #moyenne de l'année\n",
    "        print(\"-------------------\")\n",
    "        print(\"année = \", key)\n",
    "        print(\"n = \", n)\n",
    "        print(\"moyenne historique [pnull] = \", pnull)\n",
    "        print(\"moyenne de l'année [phat] = \", phat)\n",
    "        #sm.stats.proportions_ztest(phat * n, n, pnull, alternative='larger')\n",
    "        zstat, p_value = stm.stats.ztest(pDf[pColYName][pDf['Année']==key], value = pnull ,alternative='two-sided')        \n",
    "        #zstat, p_value = stm.stats.proportions_ztest( nobs=n, pnull,  alternative='two-sided')\n",
    "        print(\"zstat: \", zstat)\n",
    "        print(\"p_value: \", p_value)\n",
    "        print(\"h0: moyenne historique = moyenne [2014-2016]\")\n",
    "        print(\"h1: moyenne historique != moyenne [2014-2016]\")\n",
    "        if (p_value < pConf):\n",
    "            print(\"p_value < confidence --> on REJÈTE l'hypothèse null \")\n",
    "        else:\n",
    "            print(\"p_value > confidence --> on accèpete l'hypothèse null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_analyse_hypothese('Transmittance produit (%)', moyenne_transmit_toutes_annees, dictAnneeTransmittance)\n",
    "print_analyse_hypothese('Sucre sève (%)', moyenne_sucre_toutes_annees, dictAnneeSucre)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##########\n",
    "RESP Q2.1 et Q2.2:\n",
    "\n",
    "\n",
    "- Pour la variable Transmittance produit (%), l'hypothèse null et rejettée seulement dans l'année 2015\n",
    "- Pour la variable 'Sucre sève (%)' l'hypothèse nule est rejettée dans toutes les années\n",
    "\n",
    "############"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###############\n",
    "\n",
    "Q3 modèle pour évaluer par caméra la transparence du sirop\n",
    "Estimer la transparence du sirop à partir des données RGB\n",
    "\n",
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### obtenir colonne  pixel\n",
    "donnee.filter(like='Pixel').columns\n",
    "dfPixel = donnee.drop(donnee.filter(like='Pixel').columns, axis=1)\n",
    "\n",
    "## enlever aussi Classe Sirop (utiliser dans la question 3)\n",
    "dfPixel = dfSansPixel.drop(dfSansPixel.filter(like='Classe Sirop').columns, axis=1)\n",
    "\n",
    "dfPixel = donnee.filter(like='Pixel', axis=1)\n",
    "dfPixel\n",
    "dfPixel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://towardsdatascience.com/demystifying-hypothesis-testing-with-simple-python-examples-4997ad3c5294\n",
    "## Transmittance produit (%)\n",
    "n =len(dfNumerique)\n",
    "pnull = moyenne_transmit_toutes_annees ##0.43732148760330574 #moyenne hystorique\n",
    "### Transmittance\n",
    "confidence = 0.05\n",
    "for key in dictAnneeTransmittance.keys():\n",
    "    phat = dictAnneeTransmittance.get(key)\n",
    "    print(\"année = \", key)\n",
    "    print(\"n = \", n)\n",
    "    print(\"pnull = \", pnull)\n",
    "    print(\"phat = \", phat)\n",
    "    #sm.stats.proportions_ztest(phat * n, n, pnull, alternative='larger')\n",
    "    zstat, p_value = stm.stats.ztest(dfNumerique['Transmittance produit (%)'][dfNumerique['Année']==key], value = pnull ,alternative='two-sided')\n",
    "    #zstat, p_value = stm.stats.proportions_ztest(44.41 * n, n, 44.036, alternative='larger')\n",
    "    #zstat, p_value = stm.stats.proportions_ztest( nobs=n, pnull,  alternative='two-sided')\n",
    "    print(\"zstat: \", zstat)\n",
    "    print(\"p_value: \", p_value)\n",
    "    if (p_value < confidence):\n",
    "        print(\"p_value < confidence --> on rejète l'hypothèse null \")\n",
    "    else:\n",
    "        print(\"p_value > confidence --> on accèpete l'hypothèse null\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe[dataframe['Percentage'] > 70]\n",
    "dfNumerique[dfNumerique['Année'] == 2014]\n",
    "#dfNumerique[dfNumerique['année']>2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "n = 1018\n",
    "pnull = 52\n",
    "phat = 56\n",
    "stm.stats.proportions_ztest(phat * n, n, pnull, alternative='larger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pColName = 'Année'\n",
    "pListeExclusion = [2014, 2015, 2016]\n",
    "pData = dfNumerique\n",
    "pData[pColName][~pData[pColName].isin(pListeExclusion)].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### moyenne transmittance\n",
    "\n",
    "### boxplot vars y\n",
    "#https://seaborn.pydata.org/tutorial/regression.html\n",
    "i=0\n",
    "for key in (dict_y_colsX.keys()):    \n",
    "    print(\"key: \", key)\n",
    "    #dfX = dict_y_colsX.get(key)\n",
    "    #dfY = dfNumerique_Y_cols[key]    \n",
    "    #i+=1\n",
    "    #plt.figure(i)    \n",
    "    #sns.histplot(data=dfY, bins=10)\n",
    "    #plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNumerique['Année'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = dfNumerique\n",
    "                , x = dfNumerique['Année']\n",
    "                , y = dfNumerique['Transmittance produit (%)']\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data = dfNumerique, x=\"Année\", y=\"Transmittance produit (%)\", hue=\"Année\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## boxenplot\n",
    "def plotBoxenplot(pColNameY, pColNameX = \"Année\", pData = dfNumerique):\n",
    "    i = random.randint(100)\n",
    "    plt.figure(i)\n",
    "    sns.boxenplot(data = pData, x=pColNameX, y=pColNameY)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data = dfNumerique, x=\"Année\", y=\"Transmittance produit (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data = dfNumerique, x=\"Année\", y=\"Sucre sève (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q2\n",
    "### plot kde graph\n",
    "def plotKde(pColNameX, pHue='Année', pData = dfNumerique):\n",
    "    plt.figure() \n",
    "    sns.kdeplot(data = pData, x=pColNameX, hue=pHue)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###kdeplot\n",
    "#sns.kdeplot(data = dfNumerique[dfNumerique['Année']>2012], x=\"Transmittance produit (%)\", hue=\"Année\")\n",
    "#sns.kdeplot(data = dfNumerique, x=\"Transmittance produit (%)\", hue=\"Année\")\n",
    "plotKde(pColNameX = \"Transmittance produit (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotKde(pColNameX = \"Sucre sève (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\------------\\\n",
    "En principe, un examen visuel ne montre pas une différence \"significative\"\n",
    "ni de la transmittance ni du sucre\n",
    "\\--------------\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNumerique.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### feature selection ####\n",
    "\n",
    "https://machinelearningmastery.com/feature-selection-for-regression-data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of correlation feature selection for numerical data\n",
    "# compare different numbers of features selected using mutual information\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define dataset\n",
    "X = dfNumerique_X_cols.copy()\n",
    "\n",
    "y = dfNumerique['Débit sève (L/j)']\n",
    "\n",
    "# define the evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "\n",
    "# define the pipeline to evaluate\n",
    "model = LinearRegression()\n",
    "fs = SelectKBest(score_func=mutual_info_regression)\n",
    "pipeline = Pipeline(steps=[('sel',fs), ('lr', model)])\n",
    "\n",
    "# define the grid\n",
    "grid = dict()\n",
    "grid['sel__k'] = [i for i in range(X.shape[1]-20, X.shape[1]+1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://www.youtube.com/watch?v=VCVhwjbI6h8\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(dfNumerique_X_cols_vif, dfNumerique_Y_cols, test_size=0.25, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfNumerique_X_cols_vif, dfNumerique_Y_cols['Production moyenne par entaille (L)'], test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transforming data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting Multiple Linear Regression to the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "regressor =  LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in lst_models:\n",
    "    print(\"==== SUMMARY ====\")\n",
    "    m.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfNumerique_X_cols_vif.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duncan_prestige = stm.datasets.get_rdataset(\"Duncan\", \"carData\")\n",
    "Y = duncan_prestige.data['income']\n",
    "X = duncan_prestige.data['education']\n",
    "X = stm.add_constant(X)\n",
    "print(\"type(Y)\", type(Y))\n",
    "print(\"type(X)\", type(X))\n",
    "print(\"len(Y): \", len(Y))\n",
    "print(\"len(X): \", len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Y.shape)\n",
    "X.head()\n",
    "#Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = stm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On voit qu'il y a certaines correlations parfaites\n",
    "## ex: (temp moyen, temp max), (temp moyen, temp min), (moyenne entaille, episode gel/degel)\n",
    "## (pression osmoseur bar, boullioire 0c), (pression osmoseur bar, quantité sirop obtenu %)\n",
    "## (osmoseur heures opération, alimentation osmoseur (L/j))\n",
    "## (Sucre sortie osmoseur (%), pression osmoseur)\n",
    "## (alimentation osmoseur, (L/j), temps boulloire) -> 0.89\n",
    "## (débit sève, heures opération/j)\n",
    "## Enlevons quelques unes de ces variables et revoyons la correlation\n",
    "list_col_redondantes = ['Temp min.(°C)', 'Temp max.(°C)', 'Température Bouilloire (0C)'\n",
    "                       , 'Quantité de sirop obtenue (L)', 'Sucre du sirop obtenu (%)'\n",
    "                       , 'Osmoseur (heures opération/j)', 'Sucre sortie osmoseur (%)'\n",
    "                       , 'Temps bouilloire (h)'\n",
    "                       ]\n",
    "\n",
    "## On repète l'opération antérieur avec moins de colonnes\n",
    "dfNumerique = dfNumerique.loc[:, ~dfNumerique.columns.isin(list_col_redondantes)]\n",
    "\n",
    "corr = dfNumerique.corr()\n",
    "\n",
    "## heatmap sans correlations parfaites ou presque parfaite:\n",
    "sns.heatmap(corr, cbar=True, cmap=\"Blues\", center=0, annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pandas.series condition https://www.youtube.com/watch?v=BgfvF6mu20c\n",
    "### pour chaque var Y, imprimer les variables les plus correlées\n",
    "### on applique la condition \n",
    "for col in list_cols_dependennt_vars:\n",
    "    print(\"===========================\")\n",
    "    print(\" y = \", col.name)\n",
    "    cond_correl_plus_grand_50 = ((corr[col.name] > 0.5) & (corr[col.name] <1)) \n",
    "    print(corr[col.name][cond_correl_plus_grand_50].sort_values(ascending=False))\n",
    "    \n",
    "#list_cols_dependennt_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dfNumerique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point, we have strong relationships:\n",
    "- Débit sève (L/j) --> Alimentation osmoseur (L/j) [0.97]\n",
    "- Sucre sève (%) --> Pression osmoseur (bar) [0.9]\n",
    "- Transmittance produit (%) --> Pression osmoseur (bar)[0.81], Sucre sortie osmoseur (%) [0.68]\n",
    "- Production moyenne par entaille (L) --> Nombre épisodes gel/dégel [0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transmitance\n",
    "### pression_osmoseur_vs_transmittance\n",
    "sns.lmplot(x='Pression osmoseur (bar)', y = 'Transmittance produit (%)', data = dfNumerique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Le graphique ression_osmoseur_vs_transmittance montre une concentration\n",
    "## dans x près de 40. Regardons s'il y a des outliers:\n",
    "sns.boxplot(x='Pression osmoseur (bar)',data = dfNumerique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## effectivement, le boxplot nous montre la présence des outliers\n",
    "stats = dfNumerique['Pression osmoseur (bar)'].describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='Alimentation osmoseur (L/j)' , y='Débit sève (L/j)', data=dfNumerique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### regardons combien de 0:\n",
    "sns.histplot(x='Pression osmoseur (bar)',data = dfNumerique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(dfNumerique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation seulement entre les variables indépendantes\n",
    "\n",
    "dfDependantVars= dfNumerique.loc[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])]\n",
    "type(dfDependantVars)\n",
    "\n",
    "corr2 = dfDependantVars.corr()\n",
    "sns.heatmap(corr2, cbar=True, annot=True, cmap=\"Blues\", fmt=\".02f\", center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Linear Regression - https://www.youtube.com/watch?v=J_LnPL3Qg70\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "## https://www.statology.org/pandas-exclude-column/\n",
    "#select all columns except 'rebounds' and 'assists'\n",
    "#df.loc[:, ~df.columns.isin(['rebounds', 'assists'])]\n",
    "list_reg = []\n",
    "for col in list_cols_dependennt_vars:\n",
    " #   print(col.name)\n",
    "    #result = reg.fit(dfNumerique[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])], dfNumerique[col.name])\n",
    "    result = reg.fit(dfNumerique.loc[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])], dfNumerique[col.name])\n",
    "    list_reg.append(result)\n",
    "\n",
    "\n",
    "#dfNumerique['Année'].name\n",
    "#list_cols_dependennt_vars[0].name\n",
    "#[col.name for col in list_cols_dependennt_vars]\n",
    "#reg.fit(dfNumerique.loc[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])], dfNumerique['Débit sève (L/j)'])\n",
    "#type(dfNumerique.loc[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])])\n",
    "#dfNumeriqueIndepVar = dfNumerique[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"coefs: \", list_reg[0].coef_.round(2))\n",
    "print(\"intercept: \", list_reg[0].intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fonction vérif distr normale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dist_norm(pCol, pXlabel, pYlabel=\"Fonction de densité f(x)\", pNbRuns=1000):\n",
    "    grille_x = np.linspace(pCol.min(), pCol.max(), pNbRuns)\n",
    "    dx=(pCol.max()-(pCol.min()))/(pNbRuns-1)\n",
    "    mu, sigma = sts.norm.fit(pCol.values)\n",
    "    param=sts.norm.fit(pCol.values)\n",
    "    pdf = sts.norm.pdf(grille_x, mu, sigma)\n",
    "    ax=pCol.plot.hist(density=True, bins = 10, color = 'blue', edgecolor = 'black')\n",
    "    ax.set_xlabel(pXlabel)\n",
    "    ax.plot(grille_x, pdf, linewidth=3, color = 'red')\n",
    "    ax.set_ylabel(pYlabel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca3ed784184f1b3bb7c3539bfb45e71710cd27667424f92c2d5bb4df9c107c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
