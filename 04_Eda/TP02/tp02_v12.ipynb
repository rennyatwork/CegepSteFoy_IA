{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sts\n",
    "import statsmodels.api as stm\n",
    "import statsmodels.stats.weightstats as ws\n",
    "import sklearn.linear_model as sk_lin_mod\n",
    "import math\n",
    "import seaborn as sns\n",
    "import os\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install --upgrade ipykernel\n",
    "#!{sys.executable} -m pip install --upgrade pandas\n",
    "#!{sys.executable} -m pip install --upgrade  sickit-learn \n",
    "#!{sys.executable} -m pip install featurewiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt5 #works\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets #works for pyqt5\n",
    "%matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (os.getcwd())\n",
    "currDir = os.getcwd()\n",
    "fullPath = currDir + \"/CabaneASucrev0r3.csv\"\n",
    "type(currDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnee = pd.read_csv(fullPath)\n",
    "stats=donnee.describe()\n",
    "dimensions=donnee.shape\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnee.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heureusement, très peu de nulls.\n",
    "\n",
    "Quels sont les enregistrements contenant des nulls?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnee[(donnee['Temp max.(°C)'].isna()==True) | (donnee['Précip. tot. (mm)'].isna()==True)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnee.fillna(method='bfill', inplace=True)\n",
    "donnee.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnee.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer les colonnes pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnee.filter(like='Pixel').columns\n",
    "dfSansPixel = donnee.drop(donnee.filter(like='Pixel').columns, axis=1)\n",
    "dfSansPixel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSansPixel.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### liste de variables (colonnes) dépendantes\n",
    "list_cols_dependennt_vars = []\n",
    "col_debit_seve = dfSansPixel['Débit sève (L/j)'].name\n",
    "col_sucre_dans_seve = dfSansPixel['Sucre sève (%)'].name\n",
    "col_pct_transmittance = dfSansPixel['Transmittance produit (%)'].name\n",
    "col_productivite_seve_par_saison = dfSansPixel['Production moyenne par entaille (L)'].name\n",
    "list_cols_dependennt_vars = [col_debit_seve, col_sucre_dans_seve, col_pct_transmittance, col_productivite_seve_par_saison]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convertir Classe Sirop en numérique - https://www.youtube.com/watch?v=wH_ezgftiy0&t=136s\n",
    "dfSansPixel['CategClasseSirop'] = dfSansPixel['Classe Sirop'].astype('category').cat.codes\n",
    "dfNumerique = dfSansPixel.select_dtypes(exclude='object').copy()\n",
    "dfNumerique.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "\n",
    "\n",
    "https://www.geeksforgeeks.org/ml-multiple-linear-regression-using-python/\n",
    "\n",
    "Assumption of Regression Model : \n",
    "\n",
    "- Linearity: The relationship between dependent and independent variables should be linear.\n",
    "- Homoscedasticity: Constant variance of the errors should be maintained.\n",
    "- Multivariate normality: Multiple Regression assumes that the residuals are normally distributed.\n",
    "- Lack of Multicollinearity: It is assumed that there is little or no multicollinearity in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = dfNumerique.describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfNumerique[dfNumerique['CategClasseSirop']==0 | dfNumerique['Pression osmoseur (bar)']==0].count()\n",
    "dfNumerique[dfNumerique['Pression osmoseur (bar)']==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNumerique = dfNumerique.loc[dfNumerique['Pression osmoseur (bar)'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dfNumerique.corr()\n",
    "#sns.heatmap(corr, cbar=True, cmap=\"Blues\", center=0, annot=True, fmt=\".1f\")\n",
    "\n",
    "## le résultat est une matric 22x22 pas facile à visualiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr['Année'].sort_values(ascending=False)\n",
    "corr[(corr['Année']<1) & (corr['Année']>0.2)]['Année'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pairs = corr.unstack().sort_values(kind=\"quicksort\", ascending=False).dropna()\n",
    "len(sorted_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sorted_pairs.where((sorted_pairs <1.0) & (sorted_pairs >0) ).dropna()\n",
    "list_corr = sorted_pairs.tolist()\n",
    "lst = [l for l in list_corr if (l < 1) & (l> 0) & (not(math.isnan(l)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(corr.unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(corr, cbar=True, center=0, annot=True, fmt=\"0.2f\", cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply model and check. Then, cut out variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seulement les variables X\n",
    "dfNumerique_X_cols = dfNumerique.loc[:, ~dfNumerique.columns.isin(list_cols_dependennt_vars)].copy()\n",
    "\n",
    "## seulement les variables Y\n",
    "dfNumerique_Y_cols = dfNumerique.loc[:, dfNumerique.columns.isin(list_cols_dependennt_vars)].copy()\n",
    "\n",
    "len(dfNumerique.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============== Evaluating model ===========\n",
    "\n",
    "https://www.youtube.com/watch?v=VCVhwjbI6h8\n",
    "\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fonction qui imprime le sommaire du modèle\n",
    "def print_model_summary(pDfColsX, pDfColsY):\n",
    "    ## Add constant\n",
    "    pDfColsX = stm.add_constant(pDfColsX)\n",
    "    lst_models = []\n",
    "    for y in (pDfColsY.columns.values):\n",
    "    \n",
    "        col_y = dfNumerique_Y_cols[y]\n",
    "    \n",
    "        model = stm.OLS(col_y, pDfColsX).fit()\n",
    "        print(\"=========\")\n",
    "        print(\"var depend: \", y)\n",
    "    \n",
    "        #lst_models.append(model)\n",
    "        print(model.summary())\n",
    "        #sns.distplot(model.resid, fit=sts.norm)\n",
    "        #sns.histplot(model.resid, kde=True, stat=\"density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---- Sommaire dfNumerique ----\")\n",
    "print_model_summary(dfNumerique_X_cols, dfNumerique_Y_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://www.youtube.com/watch?v=VCVhwjbI6h8\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model(pColsY, pDfDependentVars):\n",
    "    for y in (pColsY.columns.values):    \n",
    "        col_y = pColsY[y]\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(pDfDependentVars, col_y, test_size=0.25, random_state=0)\n",
    "\n",
    "\n",
    "        ## transforming data    \n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "\n",
    "        ## Fitting Multiple Linear Regression to the training set\n",
    "        regressor =  LinearRegression()\n",
    "        regressor.fit(X_train, y_train)\n",
    "        \n",
    "\n",
    "        y_pred = regressor.predict(X_test)\n",
    "        mse = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        #r_sq = regressor.score(X_test, y_test)\n",
    "\n",
    "        ##adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "        ## Where n is the sample size and p is the number of independent variables.\n",
    "\n",
    "        #print (\"len(X_test): \", len(X_test))\n",
    "        #print (\"len(y_test): \", len(y_test))\n",
    "    \n",
    "        ### ajd_r2\n",
    "        ## https://stackoverflow.com/questions/51038820/how-to-calculated-the-adjusted-r2-value-using-scikit\n",
    "        ## https://www.dummies.com/article/business-careers-money/business/accounting/calculation-analysis/how-to-calculate-the-adjusted-coefficient-of-determination-146054/\n",
    "        #print (\"n: \", n)\n",
    "        #print (\"p: \", p)\n",
    "        #print (\"adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\")\n",
    "\n",
    "        n = len(X_test)\n",
    "        p = len(pDfDependentVars.columns)\n",
    "        adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    \n",
    "        print(\"--------\")\n",
    "        \n",
    "        print(\"[col_y]: \", col_y.name)\n",
    "        print(\"[mse]: \", mse)\n",
    "        #print(\"[r2] - A value of 1 indicates that the response variable can be perfectly explained by the predictor variables.\")\n",
    "        print(\"[r2]: \", r2)\n",
    "        print(\"[adj_r2]: \", adj_r2)\n",
    "        print(\"[coef]: \", regressor.coef_)\n",
    "        print(\"[intercept_]: \", regressor.intercept_)\n",
    "        #print(\"[r_sq]: \", r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_model(dfNumerique_Y_cols, dfNumerique_X_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\---\n",
    " At this point, we have very high accuracy (r2 and adj_r2)\n",
    " can we find a smaller set of dependent vars?\n",
    "\\---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------before calc high score it says all true ----\n",
    "\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduced_df_X(pDfx, pY, pAccuracy=0.7):\n",
    "    print(\"------\")\n",
    "    print(\"dependent var y: \", pY.name)\n",
    "    \n",
    "    # new X df with fewer columns than pDfx\n",
    "    reducedDf = []\n",
    "\n",
    "    # column names to keep\n",
    "    dfKeeper = None\n",
    "\n",
    "    #no of features\n",
    "    nof_list=np.arange(1,len(pDfx.columns))            \n",
    "    high_score=0\n",
    "    #Variable to store the optimum features\n",
    "    nof=0           \n",
    "    score_list =[]\n",
    "    for n in range(len(nof_list)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(pDfx, pY, test_size = 0.3, random_state = 0)\n",
    "        model = LinearRegression()\n",
    "        rfe = RFE(model,n_features_to_select= nof_list[n])\n",
    "        X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "        X_test_rfe = rfe.transform(X_test)\n",
    "        model.fit(X_train_rfe,y_train)\n",
    "        score = model.score(X_test_rfe,y_test)\n",
    "        score_list.append(score)\n",
    "        \n",
    "        print(\"n: \", n)\n",
    "        print(\"score: \", score)\n",
    "        print(\"high_score: \", high_score)\n",
    "\n",
    "        # print summaries for the selection of attributes\n",
    "        print(\"rfe.support_: \",rfe.support_)\n",
    "        print(\"rfe.ranking_: \" ,rfe.ranking_)\n",
    "        \n",
    "        #dfKeeper = pd.DataFrame(rfe.support_,index=pDfx.columns,columns=['Rank'])\n",
    "        data= {'colName': pDfx.columns, 'keep': rfe.support_ }\n",
    "        dfKeeper = pd.DataFrame(data)\n",
    "        dfKeeper = dfKeeper[dfKeeper[\"keep\"]==True]\n",
    "        if(score>high_score):\n",
    "            high_score = score\n",
    "            nof = nof_list[n]\n",
    "        if (score > pAccuracy):\n",
    "            break\n",
    "\n",
    "    \n",
    "    print(\"Optimum number of features: %d\" %nof)\n",
    "    print(\"Score with %d features: %f\" % (nof, high_score))\n",
    "    print(\"df columns to keep: \")\n",
    "    print(\"shape\")\n",
    "    print(dfNumerique_X_cols[dfKeeper[\"colName\"]].shape)\n",
    "    print(dfKeeper)\n",
    "    \n",
    "    reducedDf = dfNumerique_X_cols[dfKeeper[\"colName\"]]\n",
    "    \n",
    "    print(\"reducedDf: \", reducedDf.head())\n",
    "    #print(\"unique: \", reducedDf[dfKeeper[\"colName\"]].unique())\n",
    "    return reducedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### clé = colonne dépendante, valeur = dataframe des colonnes avec haute influence\n",
    "dict_y_colsX = {}\n",
    "\n",
    "for y in (dfNumerique_Y_cols.columns.values):    \n",
    "    col_y = dfNumerique_Y_cols[y]\n",
    "    reducedDf = get_reduced_df_X(dfNumerique_X_cols, col_y)\n",
    "    print(\"reduceDf.columns.values: \",  reducedDf.columns.values)\n",
    "    print(\"unique values: \", reducedDf[reducedDf.columns.values[0]].unique())\n",
    "    print(\"len: \", len(reducedDf[reducedDf.columns.values[0]]))\n",
    "    print(\"Nan: \", reducedDf[reducedDf.columns.values[0]].isnull().sum())\n",
    "    ## call to analyze_model\n",
    "    #analyze_model(dfNumerique_Y_cols, reducedDf)\n",
    "    #analyze_model(col_y.to_frame(), reducedDf)\n",
    "    dict_y_colsX.update({col_y.name: reducedDf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### analyse le modèle de nouveau avec un dataframe réduit\n",
    "#analyze_model(dfNumerique_Y_cols, dfNumerique_X_cols)\n",
    "for key in (dict_y_colsX.keys()):\n",
    "    print(\"key: \", key)\n",
    "    dfX = dict_y_colsX.get(key)\n",
    "    dfY = dfNumerique_Y_cols[key]\n",
    "    #print(type(dfX))\n",
    "    #print(type(dfY))\n",
    "    #dfX =pd.DataFrame(dict_y_colsX[key], columns=[key])\n",
    "    #print(\"shape: \", dfX.shape)\n",
    "    #print(\"nulls: \", dfX.isnull().sum())\n",
    "    analyze_model(dfY.to_frame(), dfX)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:  Production moyenne par entaille (L)\n",
      "=========\n",
      "var depend:  Production moyenne par entaille (L)\n",
      "                                     OLS Regression Results                                    \n",
      "===============================================================================================\n",
      "Dep. Variable:     Production moyenne par entaille (L)   R-squared:                       0.910\n",
      "Model:                                             OLS   Adj. R-squared:                  0.909\n",
      "Method:                                  Least Squares   F-statistic:                 1.602e+04\n",
      "Date:                                 Thu, 24 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                                         18:39:08   Log-Likelihood:                -4029.1\n",
      "No. Observations:                                 1595   AIC:                             8062.\n",
      "Df Residuals:                                     1593   BIC:                             8073.\n",
      "Df Model:                                            1                                         \n",
      "Covariance Type:                             nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                       -11.8088      0.316    -37.395      0.000     -12.428     -11.189\n",
      "Nombre épisodes gel/dégel     1.8654      0.015    126.564      0.000       1.836       1.894\n",
      "==============================================================================\n",
      "Omnibus:                       34.465   Durbin-Watson:                   0.025\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               20.460\n",
      "Skew:                          -0.110   Prob(JB):                     3.61e-05\n",
      "Kurtosis:                       2.490   Cond. No.                         89.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "key:  Débit sève (L/j)\n",
      "=========\n",
      "var depend:  Débit sève (L/j)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       Débit sève (L/j)   R-squared:                       0.943\n",
      "Model:                            OLS   Adj. R-squared:                  0.943\n",
      "Method:                 Least Squares   F-statistic:                 2.623e+04\n",
      "Date:                Thu, 24 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        18:39:08   Log-Likelihood:                -13360.\n",
      "No. Observations:                1595   AIC:                         2.672e+04\n",
      "Df Residuals:                    1593   BIC:                         2.673e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                -3188.2215     46.670    -68.314      0.000   -3279.762   -3096.681\n",
      "Temps bouilloire (h)  2628.9377     16.232    161.961      0.000    2597.099    2660.776\n",
      "==============================================================================\n",
      "Omnibus:                      278.374   Durbin-Watson:                   1.681\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1396.289\n",
      "Skew:                           0.726   Prob(JB):                    6.30e-304\n",
      "Kurtosis:                       7.347   Cond. No.                         5.53\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "key:  Sucre sève (%)\n",
      "=========\n",
      "var depend:  Sucre sève (%)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         Sucre sève (%)   R-squared:                       0.925\n",
      "Model:                            OLS   Adj. R-squared:                  0.925\n",
      "Method:                 Least Squares   F-statistic:                     9764.\n",
      "Date:                Thu, 24 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        18:39:08   Log-Likelihood:                 1192.9\n",
      "No. Observations:                1595   AIC:                            -2380.\n",
      "Df Residuals:                    1592   BIC:                            -2364.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                         1.4896      0.012    123.622      0.000       1.466       1.513\n",
      "Précip. tot. (mm)            -0.0508      0.000   -104.089      0.000      -0.052      -0.050\n",
      "Nombre épisodes gel/dégel     0.0517      0.001     92.563      0.000       0.051       0.053\n",
      "==============================================================================\n",
      "Omnibus:                       15.107   Durbin-Watson:                   1.148\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               10.823\n",
      "Skew:                           0.079   Prob(JB):                      0.00447\n",
      "Kurtosis:                       2.629   Cond. No.                         90.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "key:  Transmittance produit (%)\n",
      "=========\n",
      "var depend:  Transmittance produit (%)\n",
      "                                OLS Regression Results                               \n",
      "=====================================================================================\n",
      "Dep. Variable:     Transmittance produit (%)   R-squared:                       0.683\n",
      "Model:                                   OLS   Adj. R-squared:                  0.682\n",
      "Method:                        Least Squares   F-statistic:                     683.8\n",
      "Date:                       Thu, 24 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                               18:39:08   Log-Likelihood:                -5270.9\n",
      "No. Observations:                       1595   AIC:                         1.055e+04\n",
      "Df Residuals:                           1589   BIC:                         1.059e+04\n",
      "Df Model:                                  5                                         \n",
      "Covariance Type:                   nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "const                          -795.2753    520.302     -1.528      0.127   -1815.826     225.276\n",
      "Osmoseur (heures opération/j)     1.1109      0.100     11.061      0.000       0.914       1.308\n",
      "Température Bouilloire (0C)       9.6813      5.734      1.688      0.092      -1.566      20.928\n",
      "Temps bouilloire (h)             -2.9453      0.257    -11.452      0.000      -3.450      -2.441\n",
      "Sucre du sirop obtenu (%)        -2.1108      1.153     -1.831      0.067      -4.372       0.150\n",
      "CategClasseSirop                 -9.2630      0.185    -49.946      0.000      -9.627      -8.899\n",
      "==============================================================================\n",
      "Omnibus:                      134.031   Durbin-Watson:                   1.981\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              278.568\n",
      "Skew:                           0.535   Prob(JB):                     3.23e-61\n",
      "Kurtosis:                       4.745   Cond. No.                     3.90e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.9e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "### analyse le modèle de nouveau avec un dataframe réduit\n",
    "#analyze_model(dfNumerique_Y_cols, dfNumerique_X_cols)\n",
    "for key in (dict_y_colsX.keys()):\n",
    "    print(\"key: \", key)\n",
    "    dfX = dict_y_colsX.get(key)\n",
    "    dfY = dfNumerique_Y_cols[key]    \n",
    "    print_model_summary(dfX, dfY.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "trans = RFE(clf, n_features_to_select=5)\n",
    "\n",
    "for y in (dfNumerique_Y_cols.columns.values):    \n",
    "    col_y = dfNumerique_Y_cols[y]\n",
    "    dfNumerique_X_cols_small = trans.fit_transform(dfNumerique_X_cols, col_y)\n",
    "columns_retained_RFE = kepler.iloc[:, 1:].columns[trans.get_support()].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_scaled =  StandardScaler().fit_transform(dfNumerique_X_cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfNumerique['Transmittance produit (%)']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled,y,test_size = 0.2,stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPenguins = sns.load_dataset(\"penguins\")\n",
    "sns.histplot(dfPenguins[\"flipper_length_mm\"], kde=True, stat=\"density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### END Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### vif\n",
    "## https://www.kdnuggets.com/2019/07/check-quality-regression-model-python.html\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://www.geeksforgeeks.org/detecting-multicollinearity-with-vif-python/\n",
    "\n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = dfNumerique_X_cols.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfNumerique_X_cols.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([vif(dfNumerique_X_cols.values, i)for i in range(len(dfNumerique_X_cols.columns))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculating VIF for each feature\n",
    "\n",
    "vif_data[\"VIF\"] = [vif(dfNumerique_X_cols.values, i)\n",
    "                          for i in range(len(dfNumerique_X_cols.columns))]\n",
    "\n",
    "vif_data.sort_values(by=\"VIF\", axis=0, kind=\"quicksort\",  ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfVifPlusGrand10 = vif_data[vif_data[\"VIF\"] >10]\n",
    "len(dfVifPlusGrand10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(dfVifPlusGrand10.columns.values.tolist())\n",
    "#type(list_cols_dependennt_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dfNumerique_X sans les vif >10\n",
    "dfNumerique_X_cols_vif =[]\n",
    "dfNumerique_X_cols_vif = dfNumerique_X_cols.loc[:, ~dfNumerique_X_cols.columns.isin(dfVifPlusGrand10[\"feature\"].values)].copy()\n",
    "#for x in (dfVifPlusGrand10[\"feature\"].values):\n",
    "#    print(\"col: \", x)\n",
    "len(dfNumerique_X_cols_vif.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(dfNumerique_Y_cols)\n",
    "dfNumerique_Y_cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNumerique_Y_cols.columns.values[0]\n",
    "dfNumerique_Y_cols['Production moyenne par entaille (L)']\n",
    "#dfNumerique_Y_cols[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "list_reg = []\n",
    "for col in list_cols_dependennt_vars:\n",
    " #   print(col.name)\n",
    "    #result = reg.fit(dfNumerique[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])], dfNumerique[col.name])\n",
    "    result = reg.fit(dfNumerique.loc[:, ~dfNumerique.columns.isin([col for col in list_cols_dependennt_vars])], dfNumerique[col])\n",
    "    list_reg.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"coefs: \", list_reg[0].coef_.round(2))\n",
    "print(\"intercept: \", list_reg[0].intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNumerique_X_cols_vif.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\#####\n",
    "======= Summaries ===========\n",
    "\\#####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_y = dfNumerique_Y_cols[y]\n",
    "model = stm.OLS(col_y, dfNumerique_X_cols).fit()\n",
    "dfNumerique_Y_cols['Production moyenne par entaille (L)']\n",
    "type(sts.norm)\n",
    "\n",
    "sns.histplot(model.resid, kde=True, stat=\"density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### feature selection ####\n",
    "\n",
    "https://machinelearningmastery.com/feature-selection-for-regression-data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of correlation feature selection for numerical data\n",
    "# compare different numbers of features selected using mutual information\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define dataset\n",
    "X = dfNumerique_X_cols.copy()\n",
    "\n",
    "y = dfNumerique['Débit sève (L/j)']\n",
    "\n",
    "# define the evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "\n",
    "# define the pipeline to evaluate\n",
    "model = LinearRegression()\n",
    "fs = SelectKBest(score_func=mutual_info_regression)\n",
    "pipeline = Pipeline(steps=[('sel',fs), ('lr', model)])\n",
    "\n",
    "# define the grid\n",
    "grid = dict()\n",
    "grid['sel__k'] = [i for i in range(X.shape[1]-20, X.shape[1]+1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the grid search\n",
    "search = GridSearchCV(pipeline, grid, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# summarize best\n",
    "print('Best MAE: %.3f' % results.best_score_)\n",
    "print('Best Config: %s' % results.best_params_)\n",
    "# summarize all\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://www.youtube.com/watch?v=VCVhwjbI6h8\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(dfNumerique_X_cols_vif, dfNumerique_Y_cols, test_size=0.25, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfNumerique_X_cols_vif, dfNumerique_Y_cols['Production moyenne par entaille (L)'], test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transforming data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting Multiple Linear Regression to the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "regressor =  LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in lst_models:\n",
    "    print(\"==== SUMMARY ====\")\n",
    "    m.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfNumerique_X_cols_vif.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duncan_prestige = stm.datasets.get_rdataset(\"Duncan\", \"carData\")\n",
    "Y = duncan_prestige.data['income']\n",
    "X = duncan_prestige.data['education']\n",
    "X = stm.add_constant(X)\n",
    "print(\"type(Y)\", type(Y))\n",
    "print(\"type(X)\", type(X))\n",
    "print(\"len(Y): \", len(Y))\n",
    "print(\"len(X): \", len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Y.shape)\n",
    "X.head()\n",
    "#Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = stm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On voit qu'il y a certaines correlations parfaites\n",
    "## ex: (temp moyen, temp max), (temp moyen, temp min), (moyenne entaille, episode gel/degel)\n",
    "## (pression osmoseur bar, boullioire 0c), (pression osmoseur bar, quantité sirop obtenu %)\n",
    "## (osmoseur heures opération, alimentation osmoseur (L/j))\n",
    "## (Sucre sortie osmoseur (%), pression osmoseur)\n",
    "## (alimentation osmoseur, (L/j), temps boulloire) -> 0.89\n",
    "## (débit sève, heures opération/j)\n",
    "## Enlevons quelques unes de ces variables et revoyons la correlation\n",
    "list_col_redondantes = ['Temp min.(°C)', 'Temp max.(°C)', 'Température Bouilloire (0C)'\n",
    "                       , 'Quantité de sirop obtenue (L)', 'Sucre du sirop obtenu (%)'\n",
    "                       , 'Osmoseur (heures opération/j)', 'Sucre sortie osmoseur (%)'\n",
    "                       , 'Temps bouilloire (h)'\n",
    "                       ]\n",
    "\n",
    "## On repète l'opération antérieur avec moins de colonnes\n",
    "dfNumerique = dfNumerique.loc[:, ~dfNumerique.columns.isin(list_col_redondantes)]\n",
    "\n",
    "corr = dfNumerique.corr()\n",
    "\n",
    "## heatmap sans correlations parfaites ou presque parfaite:\n",
    "sns.heatmap(corr, cbar=True, cmap=\"Blues\", center=0, annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pandas.series condition https://www.youtube.com/watch?v=BgfvF6mu20c\n",
    "### pour chaque var Y, imprimer les variables les plus correlées\n",
    "### on applique la condition \n",
    "for col in list_cols_dependennt_vars:\n",
    "    print(\"===========================\")\n",
    "    print(\" y = \", col.name)\n",
    "    cond_correl_plus_grand_50 = ((corr[col.name] > 0.5) & (corr[col.name] <1)) \n",
    "    print(corr[col.name][cond_correl_plus_grand_50].sort_values(ascending=False))\n",
    "    \n",
    "#list_cols_dependennt_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dfNumerique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point, we have strong relationships:\n",
    "- Débit sève (L/j) --> Alimentation osmoseur (L/j) [0.97]\n",
    "- Sucre sève (%) --> Pression osmoseur (bar) [0.9]\n",
    "- Transmittance produit (%) --> Pression osmoseur (bar)[0.81], Sucre sortie osmoseur (%) [0.68]\n",
    "- Production moyenne par entaille (L) --> Nombre épisodes gel/dégel [0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transmitance\n",
    "### pression_osmoseur_vs_transmittance\n",
    "sns.lmplot(x='Pression osmoseur (bar)', y = 'Transmittance produit (%)', data = dfNumerique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Le graphique ression_osmoseur_vs_transmittance montre une concentration\n",
    "## dans x près de 40. Regardons s'il y a des outliers:\n",
    "sns.boxplot(x='Pression osmoseur (bar)',data = dfNumerique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## effectivement, le boxplot nous montre la présence des outliers\n",
    "stats = dfNumerique['Pression osmoseur (bar)'].describe()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='Alimentation osmoseur (L/j)' , y='Débit sève (L/j)', data=dfNumerique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### regardons combien de 0:\n",
    "sns.histplot(x='Pression osmoseur (bar)',data = dfNumerique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(dfNumerique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation seulement entre les variables indépendantes\n",
    "\n",
    "dfDependantVars= dfNumerique.loc[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])]\n",
    "type(dfDependantVars)\n",
    "\n",
    "corr2 = dfDependantVars.corr()\n",
    "sns.heatmap(corr2, cbar=True, annot=True, cmap=\"Blues\", fmt=\".02f\", center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Linear Regression - https://www.youtube.com/watch?v=J_LnPL3Qg70\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "## https://www.statology.org/pandas-exclude-column/\n",
    "#select all columns except 'rebounds' and 'assists'\n",
    "#df.loc[:, ~df.columns.isin(['rebounds', 'assists'])]\n",
    "list_reg = []\n",
    "for col in list_cols_dependennt_vars:\n",
    " #   print(col.name)\n",
    "    #result = reg.fit(dfNumerique[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])], dfNumerique[col.name])\n",
    "    result = reg.fit(dfNumerique.loc[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])], dfNumerique[col.name])\n",
    "    list_reg.append(result)\n",
    "\n",
    "\n",
    "#dfNumerique['Année'].name\n",
    "#list_cols_dependennt_vars[0].name\n",
    "#[col.name for col in list_cols_dependennt_vars]\n",
    "#reg.fit(dfNumerique.loc[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])], dfNumerique['Débit sève (L/j)'])\n",
    "#type(dfNumerique.loc[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])])\n",
    "#dfNumeriqueIndepVar = dfNumerique[:, ~dfNumerique.columns.isin([col.name for col in list_cols_dependennt_vars])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"coefs: \", list_reg[0].coef_.round(2))\n",
    "print(\"intercept: \", list_reg[0].intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fonction vérif distr normale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dist_norm(pCol, pXlabel, pYlabel=\"Fonction de densité f(x)\", pNbRuns=1000):\n",
    "    grille_x = np.linspace(pCol.min(), pCol.max(), pNbRuns)\n",
    "    dx=(pCol.max()-(pCol.min()))/(pNbRuns-1)\n",
    "    mu, sigma = sts.norm.fit(pCol.values)\n",
    "    param=sts.norm.fit(pCol.values)\n",
    "    pdf = sts.norm.pdf(grille_x, mu, sigma)\n",
    "    ax=pCol.plot.hist(density=True, bins = 10, color = 'blue', edgecolor = 'black')\n",
    "    ax.set_xlabel(pXlabel)\n",
    "    ax.plot(grille_x, pdf, linewidth=3, color = 'red')\n",
    "    ax.set_ylabel(pYlabel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca3ed784184f1b3bb7c3539bfb45e71710cd27667424f92c2d5bb4df9c107c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
