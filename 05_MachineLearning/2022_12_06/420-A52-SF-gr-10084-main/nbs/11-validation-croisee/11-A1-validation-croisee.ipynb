{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**420-A52-SF - Algorithmes d'apprentissage supervisé - Automne 2022 - Spécialisation technique en Intelligence Artificielle**<br/>\n",
    "MIT License - Copyright (c) 2022 Mikaël Swawola\n",
    "<br/>\n",
    "![Travaux Pratiques - Validation croisée](static/11-A1-banner.png)\n",
    "<br/>\n",
    "**Objectif:** cette séance de travaux pratiques a pour objectif la mise en oeuvre de la validation croisée à k plis à l'aide de la librairie **scikit-learn**. Les modèles et algorithmes utilisés seront la régression logistique et la classification KNN Le jeu de données sera de nouveau **Heart**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Chargement des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation de données\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation de données\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Helpers\n",
    "from helpers import polynomial\n",
    "\n",
    "# Outils divers\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Machine Learning\n",
    "# Compléter au fur et à mesure du TP l'importation des modules scikit-learn requis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de la visualisation\n",
    "sns.set(style=\"darkgrid\", rc={'figure.figsize':(12,6)})\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Lecture du jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 1-1: lire le fichier `Heart.csv`<strong/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter le code ci-dessous ~ 1-2 lignes\n",
    "HRT = pd.read_csv(\"../../data/Heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime tout de suite les données manquantes. Ceci sera vu plus en détail plus tard dans le cours\n",
    "HRT = HRT.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 1-2: afficher les dix premières lignes de la trame de données HRT</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  \\\n",
       "0           1   63    1       typical     145   233    1        2    150   \n",
       "1           2   67    1  asymptomatic     160   286    0        2    108   \n",
       "2           3   67    1  asymptomatic     120   229    0        2    129   \n",
       "3           4   37    1    nonanginal     130   250    0        0    187   \n",
       "4           5   41    0    nontypical     130   204    0        2    172   \n",
       "\n",
       "   ExAng  Oldpeak  Slope   Ca        Thal  AHD  \n",
       "0      0      2.3      3  0.0       fixed   No  \n",
       "1      1      1.5      2  3.0      normal  Yes  \n",
       "2      1      2.6      2  2.0  reversable  Yes  \n",
       "3      0      3.5      3  0.0      normal   No  \n",
       "4      0      1.4      1  0.0      normal   No  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compléter le code ci-dessous ~ 1 ligne\n",
    "HRT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Préparation de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "Age           0\n",
       "Sex           0\n",
       "ChestPain     0\n",
       "RestBP        0\n",
       "Chol          0\n",
       "Fbs           0\n",
       "RestECG       0\n",
       "MaxHR         0\n",
       "ExAng         0\n",
       "Oldpeak       0\n",
       "Slope         0\n",
       "Ca            0\n",
       "Thal          0\n",
       "AHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HRT.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons considérer l'ensemble des variables explicatives du jeu de données **Heart**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 2-1: Encoder les variables explicatives catégorielles. Utiliser le numpy array `X` pour stocker les variables explicatives et le vecteur `y` pour la variable réponse. Indice: utilisez pandas ;-)</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed' 'normal' 'reversable']\n",
      "['typical' 'asymptomatic' 'nonanginal' 'nontypical']\n"
     ]
    }
   ],
   "source": [
    "# Compléter le code ci-dessous ~ 2-3 lignes\n",
    "lstCol = ['ChestPain', 'Thal']\n",
    "col_y = 'AHD'\n",
    "\n",
    "HRT = HRT.loc[:, ~HRT.columns.str.contains('^Unnamed')]\n",
    "X = HRT.drop(col_y, axis=1).copy()\n",
    "y = HRT[col_y].copy()\n",
    "\n",
    "HRT_numerique = pd.get_dummies(data=HRT, columns = lstCol, drop_first=True, prefix=lstCol).copy()\n",
    "print(HRT.Thal.unique())\n",
    "print(HRT.ChestPain.unique())\n",
    "\n",
    "HRT_numerique = HRT_numerique.loc[:, ~HRT_numerique.columns.str.contains('^Unnamed')]\n",
    "dfX = HRT_numerique.copy();\n",
    "dfY = dfX[col_y]\n",
    "dfX.drop(col_y, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 2-1: Quel est le nombre de variables explicatives contenues dans `X` ?</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compléter le code ci-dessous ~ 1 ligne  ---> 16\n",
    "len(dfX.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 2-2: Quel est le nombre d'observations ?</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compléter le code ci-dessous ~ 1 ligne ---> 297\n",
    "len(dfX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Validation croisée à 5 plis - Régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - 1 - Mélange des données et séparation en jeu d’entraînement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 3-1: à l'aide de scikit-learn, sépararer les données en jeu d'entraînement et jeu de test. La taille du jeu de test doit représenter 30% de la taille du jeu de données et l'état du générateur aléatoire sera fixé à 2020 afin de permettre la reproductibilité</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3 - 1 - Mélange des données et séparation en jeu d’entraînement et de test](static/fig1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter le code ci-dessous ~ 1 ligne\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfX,dfY, shuffle=True, test_size=0.30, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification des dimensions de `X_train` et `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 16)\n",
      "(90, 16)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - 2 - Entraînement de plusieurs modèles de flexibilités différentes sur 5 plis de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 3-2: réaliser une validation croisée à 5-plis sur une régression logistique polynomiale (sans variables d'interaction) en faisant varier l'ordre `n` du polynôme de 1 à 5. Vous pouvez utiliser la fonction `polynomial` disponible dans `helpers.py`. Enregistrez dans le dictionnaire `history` les scores (accuracy) sur les jeux d'entraînement et de validation pour chaque valeurs de `n`</strong><br/><br/>\n",
    "\n",
    "<strong style=\"color: green\">Afin de faciliter l'écriture du code, cet exercice sera réalisé en deux étapes\n",
    "<ul>\n",
    "    <li>Etape 1: effectuer une validation croisée à 5 plis sur une régression logistique d'ordre 1 seulement</li>\n",
    "    <li>Etape 2: inclure le code précédent dans une boucle for en faisant varier l'ordre de 1 à 5</li>\n",
    "</ul>\n",
    "<strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciation de `scaler` pour la standardisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 1 : effectuer une validation croisée à 5 plis sur une régression logistique d'ordre 1 seulement\n",
    "\n",
    "![3 - 2 - Entraînement de plusieurs modèles de flexibilités différentes sur k plis de validation](static/fig2.png)\n",
    "\n",
    "[sklearn.model_selection.KFold(n_splits=5, shuffle=False, random_state=None)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "train_index:  [ 42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59\n",
      "  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77\n",
      "  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95\n",
      "  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n",
      " 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149\n",
      " 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
      " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n",
      " 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203\n",
      " 204 205 206]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[43, 50, 51, 52, 57, 58, 60, 61, 70, 72, 75, 77, 81, 83, 85, 87, 89, 93, 96, 101, 106, 107, 109, 110, 111, 114, 125, 129, 152, 153, 159, 164, 166, 172, 174, 175, 176, 182, 183, 184, 187, 191, 192, 193, 194, 200, 202, 204, 205] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[39m#print(\"val_index: \", val_index)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     x_cv_train, X_cv_val \u001b[39m=\u001b[39m X_train_scaled[train_index,:], X_train_scaled[val_index,:]\n\u001b[0;32m---> 22\u001b[0m     y_cv_train, y_cv_val \u001b[39m=\u001b[39m y_train[train_index], y_train[val_index]\n\u001b[1;32m     23\u001b[0m     \u001b[39m#y_cv_train, y_cv_val = y_train[0], y_train[0]\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \n\u001b[1;32m     25\u001b[0m     \u001b[39m#clf = LogisticRegression(penalty=\"none\", fit_intercept=True).fit(x_cv_train, y_cv_train)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m#print(f\"Accuracy de validation = {np.mean(history['val'])}\")\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m#print(f\"Accuracy d'entraînement = {np.mean(history['train'])}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m   1005\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_values(key)\n\u001b[0;32m-> 1007\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_with(key)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/series.py:1042\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[39mif\u001b[39;00m key_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minteger\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1039\u001b[0m     \u001b[39m# We need to decide whether to treat this as a positional indexer\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_should_fallback_to_positional:\n\u001b[0;32m-> 1042\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc[key]\n\u001b[1;32m   1043\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[key]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1299\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1303\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1238\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1430\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1432\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1434\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:6111\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6109\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6111\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6113\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6115\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:6174\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6171\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6173\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6174\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[43, 50, 51, 52, 57, 58, 60, 61, 70, 72, 75, 77, 81, 83, 85, 87, 89, 93, 96, 101, 106, 107, 109, 110, 111, 114, 125, 129, 152, 153, 159, 164, 166, 172, 174, 175, 176, 182, 183, 184, 187, 191, 192, 193, 194, 200, 202, 204, 205] not in index'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "history = defaultdict(list)\n",
    "# Pseudo code:\n",
    "# ------------\n",
    "#kf = KFold(n_splits = n_fold, shuffle=False)\n",
    "n_fold=5\n",
    "kf = KFold(n_splits = n_fold)\n",
    "\n",
    "X_temp = polynomial(X_train, degree=1)[:,1:]\n",
    "print(type(X_temp))\n",
    "#Standardisation\n",
    "scaler.fit(X_temp)\n",
    "X_train_scaled = scaler.transform(X_temp)\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    print(\"train_index: \", train_index)\n",
    "    #print(\"val_index: \", val_index)\n",
    "    x_cv_train, X_cv_val = X_train_scaled[train_index,:], X_train_scaled[val_index,:]\n",
    "    y_cv_train, y_cv_val = y_train[train_index], y_train[val_index]\n",
    "    #y_cv_train, y_cv_val = y_train[0], y_train[0]\n",
    "    \n",
    "    #clf = LogisticRegression(penalty=\"none\", fit_intercept=True).fit(x_cv_train, y_cv_train)\n",
    "    \n",
    "    #history[\"train\"].append(clf.score(x_cv_train, y_cv_train))\n",
    "    #history[\"val\"].append(clf.score(x_cv_index, y_cv_index))\n",
    "    \n",
    "#print(f\"Accuracy de validation = {np.mean(history['val'])}\")\n",
    "#print(f\"Accuracy d'entraînement = {np.mean(history['train'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### repetindo exemplo c/ reg linear em vez de logística\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dfY_numerique = pd.DataFrame( LabelEncoder().fit_transform(dfY), columns = ['AHD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de validation = 0.25056431397946644\n",
      "Accuracy d'entraînement = 0.5880713089425353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compléter le code ci-dessous ~ 10-20 lignes ...\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfX, dfY_numerique, test_size=0.3, random_state=2020)\n",
    "\n",
    "\n",
    "history = defaultdict(list)\n",
    "\n",
    "n_fold = 5\n",
    "kf = KFold(n_splits = n_fold, shuffle=False)\n",
    "\n",
    "#X1_train_poly = polynomial(Xtrain,1)\n",
    "\n",
    "X_temp = dfX.copy()\n",
    "scaler = StandardScaler()\n",
    "sm.add_constant(X_temp)\n",
    "scaler.fit(X_temp)\n",
    "X_scaled = scaler.transform(X_temp)\n",
    "\n",
    "\n",
    "for n in tqdm(range(1,n_fold)):\n",
    "    # Compléter le code ci-dessous ~ quelques lignes ...\n",
    "    X_temp = polynomial(X_train, degree=n)[:, 1:]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_temp)\n",
    "    X_scaled = scaler.transform(X_temp)    \n",
    "    \n",
    "    clf_ordre = LinearRegression( fit_intercept=True).fit(X_scaled, y_train)\n",
    "        \n",
    "    \n",
    "    Xn_test = polynomial(X_test, degree=n)[:, 1:]\n",
    "    X_test_scaled = scaler.transform(Xn_test)\n",
    "    \n",
    "    \n",
    "    score_train = clf_ordre.score(X_scaled, y_train)\n",
    "    score_val = clf_ordre.score(X_test_scaled, y_test)\n",
    "    \n",
    "    \n",
    "    history['train'].append(score_train)\n",
    "    history['val'].append(score_val)\n",
    "    \n",
    "# Pseudo code:\n",
    "# ------------\n",
    "#\n",
    "# Instancier KFold (sklearn)\n",
    "#\n",
    "# Ajouter x0 sur X\n",
    "#\n",
    "# Standardiser X\n",
    "#\n",
    "# Itérer sur les k plis:\n",
    "#     Effectuer la classification sur le plis courant (jeu d'entraînement)\n",
    "#     Évaluer les performances sur le plis de validation\n",
    "    \n",
    "print(f\"Accuracy de validation = {np.mean(history['val'])}\")\n",
    "print(f\"Accuracy d'entraînement = {np.mean(history['train'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.04s/it]/home/hadoop/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/hadoop/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 75%|███████▌  | 3/4 [00:01<00:00,  3.27it/s]/home/hadoop/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de validation = 0.8388888888888889\n",
      "Accuracy d'entraînement = 0.8864734299516909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compléter le code ci-dessous ~ 10-20 lignes ...\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "history = defaultdict(list)\n",
    "\n",
    "n_fold = 5\n",
    "kf = KFold(n_splits = n_fold, shuffle=False)\n",
    "\n",
    "#X1_train_poly = polynomial(Xtrain,1)\n",
    "\n",
    "X_temp = dfX.copy()\n",
    "scaler = StandardScaler()\n",
    "sm.add_constant(X_temp)\n",
    "scaler.fit(X_temp)\n",
    "X_scaled = scaler.transform(X_temp)\n",
    "\n",
    "\n",
    "for n in tqdm(range(1,n_fold)):\n",
    "    # Compléter le code ci-dessous ~ quelques lignes ...\n",
    "    X_temp = polynomial(X_train, degree=n)[:, 1:]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_temp)\n",
    "    X_scaled = scaler.transform(X_temp)    \n",
    "    \n",
    "    clf_ordre = LogisticRegression(penalty=\"none\", random_state=2020, fit_intercept=True, max_iter=30).fit(X_scaled, y_train)\n",
    "        \n",
    "    \n",
    "    Xn_test = polynomial(X_test, degree=n)[:, 1:]\n",
    "    X_test_scaled = scaler.transform(Xn_test)\n",
    "    \n",
    "    \n",
    "    score_train = clf_ordre.score(X_scaled, y_train)\n",
    "    score_val = clf_ordre.score(X_test_scaled, y_test)\n",
    "    \n",
    "    \n",
    "    history['train'].append(score_train)\n",
    "    history['val'].append(score_val)\n",
    "    \n",
    "# Pseudo code:\n",
    "# ------------\n",
    "#\n",
    "# Instancier KFold (sklearn)\n",
    "#\n",
    "# Ajouter x0 sur X\n",
    "#\n",
    "# Standardiser X\n",
    "#\n",
    "# Itérer sur les k plis:\n",
    "#     Effectuer la classification sur le plis courant (jeu d'entraînement)\n",
    "#     Évaluer les performances sur le plis de validation\n",
    "    \n",
    "print(f\"Accuracy de validation = {np.mean(history['val'])}\")\n",
    "print(f\"Accuracy d'entraînement = {np.mean(history['train'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 2 - inclure le code précédent dans une boucle for en faisant varier l'ordre de 1 à 5\n",
    "\n",
    "![3 - 2 - Entraînement de plusieurs modèles de flexibilités différentes sur k plis de validation](static/fig3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[43, 50, 51, 52, 57, 58, 60, 61, 70, 72, 75, 77, 81, 83, 85, 87, 89, 93, 96, 101, 106, 107, 109, 110, 111, 114, 125, 129, 152, 153, 159, 164, 166, 172, 174, 175, 176, 182, 183, 184, 187, 191, 192, 193, 194, 200, 202, 204, 205] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [74], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m scaler\u001b[38;5;241m.\u001b[39mfit(X_temp)\n\u001b[1;32m     22\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_temp)\n\u001b[0;32m---> 24\u001b[0m tr, val \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegressionCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [74], line 9\u001b[0m, in \u001b[0;36mLogisticRegressionCV\u001b[0;34m(X_train_scaled, y_train, n_splits)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, val_index \u001b[38;5;129;01min\u001b[39;00m kf\u001b[38;5;241m.\u001b[39msplit(X_train_scaled):\n\u001b[1;32m      8\u001b[0m     x_cv_train, x_cv_val \u001b[38;5;241m=\u001b[39m X_train_scaled[train_index,:], X_train_scaled[val_index,:]\n\u001b[0;32m----> 9\u001b[0m     y_cv_train, y_cv_val \u001b[38;5;241m=\u001b[39m \u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m, y_train[val_index]\n\u001b[1;32m     11\u001b[0m     clf \u001b[38;5;241m=\u001b[39m LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mfit(x_cv_train, y_cv_train)\n\u001b[1;32m     13\u001b[0m     history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(clf\u001b[38;5;241m.\u001b[39mscore(x_cv_train, y_cv_train))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values(key)\n\u001b[0;32m-> 1007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/series.py:1042\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;66;03m# We need to decide whether to treat this as a positional indexer\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;66;03m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n\u001b[0;32m-> 1042\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[key]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1430\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1432\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:6111\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6109\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6113\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6115\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:6174\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6173\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6174\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[43, 50, 51, 52, 57, 58, 60, 61, 70, 72, 75, 77, 81, 83, 85, 87, 89, 93, 96, 101, 106, 107, 109, 110, 111, 114, 125, 129, 152, 153, 159, 164, 166, 172, 174, 175, 176, 182, 183, 184, 187, 191, 192, 193, 194, 200, 202, 204, 205] not in index'"
     ]
    }
   ],
   "source": [
    "# Compléter le code ci-dessous ~ quelques lignes ...\n",
    "\n",
    "def LogisticRegressionCV(X_train_scaled, y_train, n_splits=5):\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    kf = KFold(n_splits)\n",
    "    for train_index, val_index in kf.split(X_train_scaled):\n",
    "        x_cv_train, x_cv_val = X_train_scaled[train_index,:], X_train_scaled[val_index,:]\n",
    "        y_cv_train, y_cv_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "        clf = LogisticRegression(solver=\"sag\", max_iter=100, fit_intercept=True).fit(x_cv_train, y_cv_train)\n",
    "    \n",
    "        history[\"train\"].append(clf.score(x_cv_train, y_cv_train))\n",
    "        history[\"val\"].append(clf.score(x_cv_val, y_cv_val))\n",
    "    \n",
    "\n",
    "history = defaultdict(list)\n",
    "for n in range(1, 10):\n",
    "    X_temp = polynomial(X_train, degree=n)[:, 1:]\n",
    "    \n",
    "    scaler.fit(X_temp)\n",
    "    X_train_scaled = scaler.transform(X_temp)\n",
    "    \n",
    "    tr, val = LogisticRegressionCV(X_train_scaled, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - 3 - Choix du meilleur modèle en fonction des performances sur les plis de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3 - 3 - Choix du meilleur modèle en fonction des performances sur les plis de validation](static/fig4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1)\n",
    "ax.plot(range(1,10), history['train'], label=\"train\")\n",
    "ax.plot(range(1,10), history['val'], label=\"test\")\n",
    "ax.set_xlabel('n', fontsize=14)\n",
    "ax.set_ylabel('accuracy', fontsize=14)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - 4 - Entrainement du meilleur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 3-4 : utiliser les résultas précédents pour sélectionner le meilleur modèle, et réentrainer ce modèle sur l'ensemble des données d'entraînement</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3 - 4 - Entrainement du meilleur modèle](static/fig5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter la fonction ci-dessous ~ quelques lignes ...\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - 5 - Performances du meilleur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 3-5 : Évaluer les performances du meilleur modèle sur le jeu de test</strong>\n",
    "![3 - 5 - Performances du modèle final](static/fig6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter la fonction ci-dessous ~ quelques lignes ...\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfX,dfY, shuffle=True, test_size=0.30, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Validation croisée à 5 plis - Algorithme des k plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - 1 - Mélange des données et séparation en jeu d’entraînement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez reprendre `X_train`, `X_test`, `y_train` et `y_test` obtenus au **3-1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - 2 - Entraînement de plusieurs modèles de flexibilités différentes sur 5 plis de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 4-2: réaliser une validation croisée à k-plis sur une classification KNN en faisant varier le nombre de voisins `k` de 1 à 20. Enregistrez les scores (accuracy) sur les jeux d'entraînement et de validation pour chaque valeur de `k` dans le dictionnaire `history`</strong><br/><br/>\n",
    "<strong style=\"color: green\">Comme pour l'exercice 3, afin de faciliter l'écriture du code, cette question sera faite en deux étapes\n",
    "<ul>\n",
    "    <li>Etape 1: effectuer une validation croisée à 5 plis sur une classification KNN avec k=10 voisins seulement</li>\n",
    "    <li>Etape 2: inclure le code précédent dans une boucle for en faisant varier le nombre de voisins de 1 à 20</li>\n",
    "</ul>\n",
    "<strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 1 - effectuer une validation croisée à 5 plis sur une classification KNN avec k=10 voisins seulement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [ 42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59\n",
      "  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77\n",
      "  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95\n",
      "  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n",
      " 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149\n",
      " 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
      " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n",
      " 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203\n",
      " 204 205 206], test: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41]\n",
      "train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  84  85  86  87  88  89  90  91  92  93  94  95\n",
      "  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n",
      " 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149\n",
      " 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
      " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n",
      " 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203\n",
      " 204 205 206], test: [42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65\n",
      " 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83]\n",
      "train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83 125 126 127 128 129 130\n",
      " 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184\n",
      " 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202\n",
      " 203 204 205 206], test: [ 84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124]\n",
      "train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 166\n",
      " 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184\n",
      " 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202\n",
      " 203 204 205 206], test: [125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165]\n",
      "train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165], test: [166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183\n",
      " 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201\n",
      " 202 203 204 205 206]\n"
     ]
    }
   ],
   "source": [
    "# Compléter le code ci-dessous ~ 10-15 lignes ...\n",
    "\n",
    "history = defaultdict(list) \n",
    "kf = KFold(5)\n",
    "kf.get=n_splits(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"Accuracy de validation = {np.mean(history['val'])}\")\n",
    "#print(f\"Accuracy d'entraînement = {np.mean(history['train'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 2 -  inclure le code précédent dans une boucle for en faisant varier le nombre de voisins de 1 à 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter le code ci-dessous ~ quelques lignes ...\n",
    "\n",
    "def KNeighborsClassifierCV(k):\n",
    "    history = defaultdict(list)\n",
    "    None\n",
    "    \n",
    "history = defaultdict(list)\n",
    "for k in range(1, 20):\n",
    "    None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - 3 - Choix du meilleur modèle en fonction des performances sur les plis de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1)\n",
    "ax.plot(range(1, 20), history['train'], label=\"train\")\n",
    "ax.plot(range(1, 20), history['val'], label=\"test\")\n",
    "ax.set_xlabel('k', fontsize=14)\n",
    "ax.set_ylabel('accuracy', fontsize=14)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - 4 - Entraînement du meilleur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 4-4: utiliser les résultas précédents pour sélectionner le meilleur modèle, et réentrainer ce modèle sur l'ensemble des données d'entraînement</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter la fonction ci-dessous ~ quelques lignes ...\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - 5 - Performances du meilleur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 4-5: Évaluer les performances du meilleur modèle sur le jeu de test</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compléter la fonction ci-dessous ~ quelques lignes ...\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 4-6: Expliquer ces performances</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Choix du modèle final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: #4a86e8\">Exercice 5: Quel modèle choisissez-vous ? Quels sont les valeurs des hyperparamètres ?</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fin du TP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
